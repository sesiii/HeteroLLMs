{
  "model": "llama3.2_1B",
  "iterations": [
    {
      "file": "llama3.2_1B_test_science_results_iter_3.json",
      "total": 6,
      "correct": 6,
      "accuracy": 100.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 8515.567779541016,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.280333333333333,
      "avg_total_duration_ms": 8509.533449666667,
      "avg_load_duration_ms": 21.589079833333333,
      "avg_prompt_eval_count": 44.166666666666664,
      "avg_prompt_eval_duration_ms": 338.6905248333333,
      "avg_eval_count": 168.0,
      "avg_eval_duration_ms": 8149.253844999999
    },
    {
      "file": "llama3.2_1B_test_science_results_iter_4.json",
      "total": 6,
      "correct": 4,
      "accuracy": 66.66666666666666,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 12389.919400215149,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 2.390333333333334,
      "avg_total_duration_ms": 12384.212765999999,
      "avg_load_duration_ms": 25.194560499999998,
      "avg_prompt_eval_count": 44.166666666666664,
      "avg_prompt_eval_duration_ms": 411.4157806666667,
      "avg_eval_count": 177.5,
      "avg_eval_duration_ms": 11947.602424833334
    },
    {
      "file": "llama3.2_1B_test_science_results_iter_5.json",
      "total": 6,
      "correct": 4,
      "accuracy": 66.66666666666666,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 8917.266925175985,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.0846666666666664,
      "avg_total_duration_ms": 8912.759966833333,
      "avg_load_duration_ms": 26.934613833333334,
      "avg_prompt_eval_count": 44.166666666666664,
      "avg_prompt_eval_duration_ms": 381.43339583333335,
      "avg_eval_count": 160.5,
      "avg_eval_duration_ms": 8504.391957166667
    },
    {
      "file": "llama3.2_1B_test_science_results_iter_2.json",
      "total": 6,
      "correct": 5,
      "accuracy": 83.33333333333334,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7544.835448265076,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.6043333333333338,
      "avg_total_duration_ms": 7541.4779481666665,
      "avg_load_duration_ms": 23.318865666666667,
      "avg_prompt_eval_count": 44.166666666666664,
      "avg_prompt_eval_duration_ms": 364.06789699999996,
      "avg_eval_count": 137.66666666666666,
      "avg_eval_duration_ms": 7154.0911855
    },
    {
      "file": "llama3.2_1B_test_science_results_iter_1.json",
      "total": 6,
      "correct": 5,
      "accuracy": 83.33333333333334,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 8357.963999112448,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.943,
      "avg_total_duration_ms": 8352.286547,
      "avg_load_duration_ms": 592.9407425,
      "avg_prompt_eval_count": 44.166666666666664,
      "avg_prompt_eval_duration_ms": 345.25848633333334,
      "avg_eval_count": 159.0,
      "avg_eval_duration_ms": 7414.0873181666675
    }
  ],
  "summary": {
    "total_iterations": 5,
    "avg_accuracy": 80.0,
    "std_accuracy": 13.944333775567932,
    "avg_math_accuracy": 0,
    "std_math_accuracy": 0.0,
    "avg_fact_accuracy": 0,
    "std_fact_accuracy": 0.0,
    "avg_latency_ms": 9145.110710461935,
    "avg_memory_mb": 0.0,
    "avg_cpu_time_ms": 1.4605333333333335,
    "avg_total_duration_ms": 9140.054135533333,
    "avg_load_duration_ms": 137.9955724666667,
    "avg_prompt_eval_count": 44.166666666666664,
    "avg_prompt_eval_duration_ms": 368.1732169333333,
    "avg_eval_count": 160.53333333333333,
    "avg_eval_duration_ms": 8633.885346133333
  }
}