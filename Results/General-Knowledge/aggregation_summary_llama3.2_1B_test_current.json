{
  "model": "llama3.2_1B",
  "iterations": [
    {
      "file": "llama3.2_1B_test_current_results_iter_1.json",
      "total": 10,
      "correct": 10,
      "accuracy": 100.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7712.301516532898,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.9712999999999998,
      "avg_total_duration_ms": 7706.001658300001,
      "avg_load_duration_ms": 21.678119900000002,
      "avg_prompt_eval_count": 46.6,
      "avg_prompt_eval_duration_ms": 397.3380654,
      "avg_eval_count": 146.2,
      "avg_eval_duration_ms": 7286.985472999999
    },
    {
      "file": "llama3.2_1B_test_current_results_iter_2.json",
      "total": 10,
      "correct": 9,
      "accuracy": 90.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 8301.275753974915,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.9889999999999999,
      "avg_total_duration_ms": 8293.6514667,
      "avg_load_duration_ms": 25.3506603,
      "avg_prompt_eval_count": 46.6,
      "avg_prompt_eval_duration_ms": 421.4850195,
      "avg_eval_count": 135.6,
      "avg_eval_duration_ms": 7846.815786900001
    },
    {
      "file": "llama3.2_1B_test_current_results_iter_3.json",
      "total": 10,
      "correct": 7,
      "accuracy": 70.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7225.251364707947,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.7884,
      "avg_total_duration_ms": 7220.6190104,
      "avg_load_duration_ms": 25.8036566,
      "avg_prompt_eval_count": 46.6,
      "avg_prompt_eval_duration_ms": 422.48597099999995,
      "avg_eval_count": 133.7,
      "avg_eval_duration_ms": 6772.3293828
    },
    {
      "file": "llama3.2_1B_test_current_results_iter_4.json",
      "total": 10,
      "correct": 10,
      "accuracy": 100.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7677.581238746643,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 2.0740000000000003,
      "avg_total_duration_ms": 7672.6366302,
      "avg_load_duration_ms": 26.442203499999998,
      "avg_prompt_eval_count": 46.6,
      "avg_prompt_eval_duration_ms": 427.7278515,
      "avg_eval_count": 142.4,
      "avg_eval_duration_ms": 7218.4665752
    },
    {
      "file": "llama3.2_1B_test_current_results_iter_5.json",
      "total": 10,
      "correct": 9,
      "accuracy": 90.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7618.025016784668,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.8555000000000004,
      "avg_total_duration_ms": 7614.5710237,
      "avg_load_duration_ms": 26.588482699999997,
      "avg_prompt_eval_count": 46.6,
      "avg_prompt_eval_duration_ms": 416.4769311,
      "avg_eval_count": 138.1,
      "avg_eval_duration_ms": 7171.505609899999
    }
  ],
  "summary": {
    "total_iterations": 5,
    "avg_accuracy": 90.0,
    "std_accuracy": 12.24744871391589,
    "avg_math_accuracy": 0,
    "std_math_accuracy": 0.0,
    "avg_fact_accuracy": 0,
    "std_fact_accuracy": 0.0,
    "avg_latency_ms": 7706.886978149414,
    "avg_memory_mb": 0.0,
    "avg_cpu_time_ms": 1.73564,
    "avg_total_duration_ms": 7701.49595786,
    "avg_load_duration_ms": 25.1726246,
    "avg_prompt_eval_count": 46.6,
    "avg_prompt_eval_duration_ms": 417.1027677,
    "avg_eval_count": 139.2,
    "avg_eval_duration_ms": 7259.22056556
  }
}