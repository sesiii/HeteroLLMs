{
  "model": "llama3.2_1B",
  "iterations": [
    {
      "file": "llama3.2_1B_test_chemistry_results_iter_1.json",
      "total": 6,
      "correct": 5,
      "accuracy": 83.33333333333334,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7622.61438369751,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.0476666666666665,
      "avg_total_duration_ms": 7618.4516815,
      "avg_load_duration_ms": 632.5184323333333,
      "avg_prompt_eval_count": 44.5,
      "avg_prompt_eval_duration_ms": 346.2148548333333,
      "avg_eval_count": 144.33333333333334,
      "avg_eval_duration_ms": 6639.718394333333
    },
    {
      "file": "llama3.2_1B_test_chemistry_results_iter_5.json",
      "total": 6,
      "correct": 3,
      "accuracy": 50.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7923.211375872294,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 2.133166666666667,
      "avg_total_duration_ms": 7916.215159666666,
      "avg_load_duration_ms": 20.2991955,
      "avg_prompt_eval_count": 44.5,
      "avg_prompt_eval_duration_ms": 338.4647596666667,
      "avg_eval_count": 157.66666666666666,
      "avg_eval_duration_ms": 7557.4512045
    },
    {
      "file": "llama3.2_1B_test_chemistry_results_iter_4.json",
      "total": 6,
      "correct": 4,
      "accuracy": 66.66666666666666,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 4694.171071052551,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.0613333333333332,
      "avg_total_duration_ms": 4689.049895833334,
      "avg_load_duration_ms": 17.857494666666668,
      "avg_prompt_eval_count": 44.5,
      "avg_prompt_eval_duration_ms": 324.675555,
      "avg_eval_count": 94.5,
      "avg_eval_duration_ms": 4346.516846166666
    },
    {
      "file": "llama3.2_1B_test_chemistry_results_iter_3.json",
      "total": 6,
      "correct": 5,
      "accuracy": 83.33333333333334,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 8259.249130884806,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.7155,
      "avg_total_duration_ms": 8254.8993885,
      "avg_load_duration_ms": 19.753612333333333,
      "avg_prompt_eval_count": 44.5,
      "avg_prompt_eval_duration_ms": 335.250702,
      "avg_eval_count": 153.5,
      "avg_eval_duration_ms": 7899.895074166667
    },
    {
      "file": "llama3.2_1B_test_chemistry_results_iter_2.json",
      "total": 6,
      "correct": 5,
      "accuracy": 83.33333333333334,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7410.984834035237,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.1476666666666664,
      "avg_total_duration_ms": 7407.817464666667,
      "avg_load_duration_ms": 21.195376,
      "avg_prompt_eval_count": 44.5,
      "avg_prompt_eval_duration_ms": 338.2046236666667,
      "avg_eval_count": 150.66666666666666,
      "avg_eval_duration_ms": 7048.4174649999995
    }
  ],
  "summary": {
    "total_iterations": 5,
    "avg_accuracy": 73.33333333333334,
    "std_accuracy": 14.907119849998605,
    "avg_math_accuracy": 0,
    "std_math_accuracy": 0.0,
    "avg_fact_accuracy": 0,
    "std_fact_accuracy": 0.0,
    "avg_latency_ms": 7182.0461591084795,
    "avg_memory_mb": 0.0,
    "avg_cpu_time_ms": 1.2210666666666665,
    "avg_total_duration_ms": 7177.286718033333,
    "avg_load_duration_ms": 142.32482216666665,
    "avg_prompt_eval_count": 44.5,
    "avg_prompt_eval_duration_ms": 336.5620990333333,
    "avg_eval_count": 140.13333333333333,
    "avg_eval_duration_ms": 6698.399796833333
  }
}