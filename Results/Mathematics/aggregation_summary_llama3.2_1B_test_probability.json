{
  "model": "llama3.2_1B",
  "iterations": [
    {
      "file": "llama3.2_1B_test_probability_results_iter_4.json",
      "total": 8,
      "correct": 1,
      "accuracy": 12.5,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 7351.0609567165375,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.1141249999999998,
      "avg_total_duration_ms": 7347.9519439999995,
      "avg_load_duration_ms": 19.830996375,
      "avg_prompt_eval_count": 54.375,
      "avg_prompt_eval_duration_ms": 425.4935155,
      "avg_eval_count": 157.625,
      "avg_eval_duration_ms": 6902.627432125
    },
    {
      "file": "llama3.2_1B_test_probability_results_iter_5.json",
      "total": 8,
      "correct": 2,
      "accuracy": 25.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 10549.664437770844,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 1.240625,
      "avg_total_duration_ms": 10546.519429875,
      "avg_load_duration_ms": 19.718976125,
      "avg_prompt_eval_count": 54.375,
      "avg_prompt_eval_duration_ms": 408.02535975,
      "avg_eval_count": 226.0,
      "avg_eval_duration_ms": 10118.775094
    },
    {
      "file": "llama3.2_1B_test_probability_results_iter_2.json",
      "total": 8,
      "correct": 1,
      "accuracy": 12.5,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 9248.426645994186,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.9195,
      "avg_total_duration_ms": 9245.323433,
      "avg_load_duration_ms": 20.6057825,
      "avg_prompt_eval_count": 54.375,
      "avg_prompt_eval_duration_ms": 408.32315875,
      "avg_eval_count": 189.875,
      "avg_eval_duration_ms": 8816.39449175
    },
    {
      "file": "llama3.2_1B_test_probability_results_iter_3.json",
      "total": 8,
      "correct": 3,
      "accuracy": 37.5,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 11926.160097122192,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.7145000000000001,
      "avg_total_duration_ms": 11922.594711125,
      "avg_load_duration_ms": 21.336948125,
      "avg_prompt_eval_count": 54.375,
      "avg_prompt_eval_duration_ms": 434.514806625,
      "avg_eval_count": 244.625,
      "avg_eval_duration_ms": 11466.742956375
    },
    {
      "file": "llama3.2_1B_test_probability_results_iter_1.json",
      "total": 8,
      "correct": 4,
      "accuracy": 50.0,
      "math_accuracy": 0,
      "fact_accuracy": 0,
      "avg_latency_ms": 9084.07923579216,
      "avg_memory_mb": 0.0,
      "avg_cpu_time_ms": 0.58175,
      "avg_total_duration_ms": 9081.335678875,
      "avg_load_duration_ms": 370.2411845,
      "avg_prompt_eval_count": 54.375,
      "avg_prompt_eval_duration_ms": 411.10173287500004,
      "avg_eval_count": 198.75,
      "avg_eval_duration_ms": 8299.9927615
    }
  ],
  "summary": {
    "total_iterations": 5,
    "avg_accuracy": 27.5,
    "std_accuracy": 16.29800601300662,
    "avg_math_accuracy": 0,
    "std_math_accuracy": 0.0,
    "avg_fact_accuracy": 0,
    "std_fact_accuracy": 0.0,
    "avg_latency_ms": 9631.878274679184,
    "avg_memory_mb": 0.0,
    "avg_cpu_time_ms": 0.9141,
    "avg_total_duration_ms": 9628.745039375,
    "avg_load_duration_ms": 90.346777525,
    "avg_prompt_eval_count": 54.375,
    "avg_prompt_eval_duration_ms": 417.4917147,
    "avg_eval_count": 203.375,
    "avg_eval_duration_ms": 9120.90654715
  }
}