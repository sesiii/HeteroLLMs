[
  {
    "query": "Answer the question based on the following context: This study evaluated supply and demand trends for orthopedic postgraduate year 1 (PGY1) positions from 1984 to 2011 for the purpose of estimating national intercandidate competition over time. National Resident Matching Program (NRMP) data for orthopedic surgery from 1984 to 2011 were collected. Proxy variables including (total number of orthopedic applicants/number of orthopedic PGY1 positions), (number of US senior applicants to orthopedics/number of orthopedic PGY1 positions), (number of US seniors matching into orthopedics/number of US senior orthopedic applicants), (total number of matched orthopedic applicants/total number of orthopedic applicants), and (total number of US applicants who fail to match into orthopedics/total number of US senior applicants into orthopedics) as well as average United States Medical Licensing Examination Step 1 scores were used to gauge the level of competition between candidates and were compared over time. Academic medical center in the Midwestern United States. Medical professors and medical students. The NRMP data suggested that the number of positions per applicant decreased or remained stable since 1984 and that the percentage of applicants who did not match was no higher now than in the past. This finding was primarily because of the relative decrease in the ratio of applicants to available PGY1 positions, which stems from the number of positions increasing more rapidly than the number of applicants.\nQuestion: Is orthopedics more competitive today than when my attending matched?",
    "gt": "The NRMP data from 1984 to 2011 supported our hypothesis that intercandidate competition intensity for orthopedic PGY1 positions has not increased over time. The misconception that orthopedics is becoming more competitive likely arises from the increased number of applications submitted per candidate and the resulting relative importance placed on objective criteria such as United States Medical Licensing Examination Step 1 scores when programs select interview cohorts.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Portal vein embolization is used in the treatment of hepatocellular cancer, with the purpose of enhancing resectability. However, regeneration is restricted due to hepatocellular injury following chemotherapeutics (e.g. doxorubicin). The aim of this study was to investigate whether hyperbaric oxygenation (HBO) can alleviate the hepatotoxicity of chemotherapy and improve regeneration in the injured liver. Rats were allocated to four experimental groups. Group I rats were subjected to right portal vein ligation (RPVL); rats in groups II and III were administered doxorubicin prior to RPVL, with group III rats being additionally exposed to HBO sessions postoperatively; group IV rats was sham-operated. All rats were sacrificed on postoperative day 7, and liver injury was assessed by measuring alanine aminotransferase (ALT) and aspartate aminotransferase (AST) levels. Protein synthetic ability was determined based albumin levels and liver regeneration by the mitotic index (MI). The AST and ALT values of group II rats were significantly higher than those of group I, but not those of group III. Rats treated with doxorubicin and HBO (groups II and III) showed slightly but not significant differences in albumin levels than those subjected to only RPVL or sham-operated. The MI was significantly increased in groups I, II, and III, with the MI of group III rats significantly higher than those of group I rats.\nQuestion: Can hyperbaric oxygenation decrease doxorubicin hepatotoxicity and improve regeneration in the injured liver?",
    "gt": "Based on our results, we conclude that HBO treatment has the potential to diminish doxorubicin-related hepatotoxicity and improve regeneration in the injured liver.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A Danish population based matched case-control study of perinatal risk factors in children with infantile autism has provided some interesting and surprising observations regarding infantile autism and children born after assisted conception. The cases (461) consisted of all children born between 1990 and 1999 and diagnosed with infantile autism in the Danish Psychiatric Central Register before February 2001. Matched controls were identified in the Danish Civil Registration System. The main exposure measures included obstetric risk factors for infantile autism. We found a 59% decreased risk for developing infantile autism among children conceived after assisted conception (odds ratio [OR]0.41, 95% [0.19-0.89]) and a 63% decreased risk after adjusting for known risk factors for assisted conception and infantile autism (OR 0.37, 95% [0.14-0.98]).\nQuestion: Do children born after assisted conception have less risk of developing infantile autism?",
    "gt": "We found that children born after assisted conception had a lower risk of developing infantile autism then their matched controls. Our observations could possibly be explained by the mother's health status before and during early pregnancy. Our findings require further investigation in larger studies.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Stigmatizing attitudes toward people with disabilities can jeopardize such individuals' well-being and recovery through denial of employment and community isolation. By shaping social norms that define group membership, the construct of individualism may partially explain differences in stigmatizing attitudes across cultures. Further, widespread globalization has brought intensely individualistic social practices to certain segments of non-Western cultures. This paper examines whether the construct of individualism can help to explain cross-cultural differences in stigmatizing attitudes observed between American and Chinese employers. Employers (N = 879) from Beijing, Hong Kong, and Chicago provided information on their attitudes toward hiring people with disabilities, and path analyses were conducted to examine potential mediating relationships. Path analyses indicated that vertical individualism, along with perceived responsibility for acquiring a condition, partially mediated the relationship between culture and employers' negative attitudes about job candidates with disabilities.\nQuestion: Does individualism help explain differences in employers' stigmatizing attitudes toward disability across Chinese and American cities?",
    "gt": "These results suggested that greater espousal of competitive and individualist values may drive stigmatizing attitudes across cultures.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We report the radiographic and clinical response rate of stereotactic body radiation therapy (SBRT) compared with conventional fractionated external beam radiation therapy (CF-EBRT) for renal cell carcinoma (RCC) bone lesions treated at our institution. Forty-six consecutive patients were included in the study, with 95 total lesions treated (50 SBRT, 45 CF-EBRT). We included patients who had histologic confirmation of primary RCC and radiographic evidence of metastatic bone lesions. The most common SBRT regimen used was 27 Gy in 3 fractions. Median follow-up was 10 months (range, 1-64 months). Median time to symptom control between SBRT and CF-EBRT were 2 (range, 0-6 weeks) and 4 weeks (range, 0-7 weeks), respectively. Symptom control rates with SBRT and CF-EBRT were significantly different (P = .020) with control rates at 10, 12, and 24 months of 74.9% versus 44.1%, 74.9% versus 39.9%, and 74.9% versus 35.7%, respectively. The median time to radiographic failure and unadjusted pain progression was 7 months in both groups. When controlling for gross tumor volume, dose per fraction, smoking, and the use of systemic therapy, biologically effective dose ≥80 Gy was significant for clinical response (hazard ratio [HR], 0.204; 95% confidence interval [CI], 0.043-0.963; P = .046) and radiographic (HR, 0.075; 95% CI, 0.013-0.430; P = .004). When controlling for gross tumor volume and total dose, biologically effective dose ≥80 Gy was again predictive of clinical local control (HR, 0.140; 95% CI, 0.025-0.787; P = .026). Toxicity rates were low and equivalent in both groups, with no grade 4 or 5 toxicity reported.\nQuestion: Local control rates of metastatic renal cell carcinoma (RCC) to the bone using stereotactic body radiation therapy: Is RCC truly radioresistant?",
    "gt": "SBRT is both safe and effective for treating RCC bone metastases, with rapid improvement in symptoms after treatment and more durable clinical and radiographic response rate. Future prospective trials are needed to further define efficacy and toxicity of treatment, especially in the setting of targeted agents.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Our objective was to clarify the clinical outcome of renal transplantation based on residual daily urine output (RDUO). We retrospectively analyzed a prospective database of 276 patients who underwent renal transplantation (Tx) between January 2008 and December 2012. Patients had pre-transplantation daily urine output measurement of 24-h proteinuria and were clinically re-evaluated the day before transplantation. We included patients with no daily urine output and those with residual daily urine output. Real bladder capacity was not measured. We excluded patients with a history of lower urinary tract malformation, those treated by trans-ileal conduit or enterocystoplasty, and those with early graft thrombosis or graft primary non-function. Sex ratio, age at Tx, pre-Tx MHC antibodies levels, donor age, and cold ischemia duration were not significantly different between the 2 groups. Dialysis duration was longer in group I (p<0.001). The dialysis duration was correlated with the volume of residual urine output (r=0.12, p<0.0001). We found 14 (19.4%) urological complications in Group I (11 urinary leaks and 3 urethral stenosis) and 13 (6.4%) in Group II (5 urinary leaks and 8 stenosis). This difference was significant (p=0.0013 and relative risk [RR]=2.2). Absence of residual daily urine output was a risk factor of post-transplantation urinary leak (p<0.0001: RR=2.95). At 3 years, graft survival was 74.7% and 94.6%, respectively, in Group I and II (p=0.003).\nQuestion: Does daily urine output really matter in renal transplantation?",
    "gt": "The absence of residual daily urine output seems to be a major risk factor for urological complications. Taking into account recipient residual daily urine output should modify surgical strategy during renal transplantation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We present a four-membered Greek family. The father was diagnosed with familial NF1 and the mother with generalized epilepsy, being under hydantoin treatment since the age of 18 years. Their two male children exhibited NFNS characteristics. The father and his sons shared R1947X mutation in the NF1 gene. The two children with NFNS phenotype presented with NF1 signs inherited from their father and fetal hydantoin syndrome-like phenotype due to exposure to that anticonvulsant during fetal development.\nQuestion: Is Neurofibromatosis Type 1-Noonan Syndrome a Phenotypic Result of Combined Genetic and Epigenetic Factors?",
    "gt": "The NFNS phenotype may be the result of both a genetic factor (mutation in the NF1 gene) and an epigenetic/environmental factor (e.g. hydantoin).",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Description of the three-year course of mental illness after supplying permanent housing to homeless individuals. 109-male and 20 female homeless individuals were assessed at the assignment of permanent housing and at one and three year follow-up using the Structured Clinical Interview for DSM-IV. A high percentage (86 %) was able to maintain or even improve the index housing situation. Only minor changes were observed in mental illness severity and global functioning. Symptoms improved slightly over the three year period. High degrees of alcohol consumption and mental illness severity increased the risk of deterioration of the housing arrangement.\nQuestion: Is supplying homeless individuals with permanent housing effective?",
    "gt": "Supplying homeless individuals with permanent housing is an effective measure but insufficient for improving mental illness. Combined measures of social and medical interventions from one provider are suggested for effective support of homeless people.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The purpose of this study was to determine, on the basis of the late fate of the intact aortic arch with abnormal tissue after aortic root replacement, whether the intact aortic arch should be replaced prophylactically at the time of aortic root replacement for annuloaortic ectasia in Marfan syndrome. A retrospective review was performed in 85 patients with Marfan syndrome who underwent aortic root replacement for annuloaortic ectasia with or without aortic dissection (mean age 37 years, range 19-61 years). These 85 patients were divided into four groups according to the postoperative condition of the residual aorta. In group I (n = 47), the patients underwent aortic root replacement for annuloaortic ectasia with or without localized dissection in the ascending aorta. In these patients the residual aorta, including the aortic arch, was therefore intact. In group II (n = 10), the aortic arch was intact, although the descending thoracic aorta was dissected because of the preoperative type B dissection. In groups III and IV, the patients had type A dissection involving the transverse arch associated with annuloaortic ectasia. In group III (n = 13), residual dissection existed in the descending thoracic aorta after concomitant total arch replacement. In group IV (n = 15), the aortic arch and the descending thoracic aorta were dissected. There were 5 early deaths (3 in group I, 1 in group II, and 1 in group III). Subsequent operations were required in 10, 5, 6, and 7 cases in groups I, II, III, and IV, respectively. Regarding the aortic arch, only 2 of 53 survivors of the initial hospitalization with an intact aortic arch (groups I and II) underwent subsequent total arch replacement for the onset of dissection in the aortic arch, and 4 of 14 survivors of the initial hospitalization with a residual dissecting arch (group III) needed subsequent total arch replacement. Actuarial freedom from arch repair among patients with an intact aortic arch (91% at 15 years) was significantly higher than that among patients with a residual dissecting arch (49% at 15 years, P =.0078).\nQuestion: Should the transverse aortic arch be replaced simultaneously with aortic root replacement for annuloaortic ectasia in Marfan syndrome?",
    "gt": "The incidence of new dissection in the residual intact arch after aortic root replacement was extremely low. Therefore prophylactic replacement of the intact arch does not appear to be necessary at aortic root replacement for annuloaortic ectasia in Marfan syndrome.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the functional and cosmetic results and patient satisfaction after triple incision plasty for phimosis in children. The study included 197 boys who had a triple incision for phimosis (mean age 5.8 years, range 0.25-18). The indications for preputial surgery were recurrent balanoposthitis, ballooning during micturition and severe phimotic stenosis. The results after surgery were assessed using a questionnaire about the child's/parent's satisfaction, and an outpatient follow-up examination for functional and cosmetic preputial appearance. Of 128 parents/children responding, 108 (84%) were satisfied with the function and 102 (80%) reported a good cosmetic outcome. Triple incision as preputioplasty would be recommended to other parents by 119 (93%) respondents. Ninety-one (71%) of the parents feared disadvantages in their son's later life if the child had been circumcised. The outpatient examination showed an excellent functional and cosmetic outcome in 71 (77%) of the children.\nQuestion: Triple incision to treat phimosis in children: an alternative to circumcision?",
    "gt": "Triple incision is a simple, fast and safe technique for preputial relief, with good functional and cosmetic results, and was well accepted by the patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Rib fractures are a frequent traumatic injury associated with a relatively high morbidity. Currently, the treatment of rib fractures is symptomatic. Since it has been reported that pulsed ultrasounds accelerates repair of limb fractures, we hypothesized that the application of pulsed ultrasounds will modify the course of healing in an animal model of rib fracture. We studied 136 male Sprague-Dawley rats. Animals were randomly assigned to different groups of doses (none, 50, 100, and 250 mW/cm(2) of intensity for 3 minutes per day) and durations (2, 10, 20, and 28 days) of treatment with pulsed ultrasounds. In every subgroup, we analyzed radiologic and histologic changes in the bone callus. In addition, we examined changes in gene expression of relevant genes involved in wound repair in both control and treated animals. Histologic and radiologic consolidation was significantly increased by pulsed ultrasound treatment when applied for more than 10 days. The application of 50 mW/cm(2) was the most effective dose. Only the 100 and 250 mW/cm(2) doses were able to significantly increase messenger RNA expression of insulin-like growth factor 1, suppressor of cytokine signaling-2 and -3, and vascular endothelial growth factor and decrease monocyte chemoattractant protein-1 and collagen type II-alpha 1.\nQuestion: Pulsed ultrasounds accelerate healing of rib fractures in an experimental animal model: an effective new thoracic therapy?",
    "gt": "Our findings indicate that pulsed ultrasound accelerates the consolidation of rib fractures. This study is the first to show that pulsed ultrasound promotes the healing of rib fractures. From a translational point of view, this easy, cheap technique could serve as an effective new therapeutic modality in patients with rib fractures.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Congenital diaphragmatic hernia (CDH) remains a significant cause of death in newborns and, despite improved outcomes with multimodality therapies, optimal timing of repair remains undefined. We sought to evaluate the influence of surgical timing on patient outcomes and hypothesized that delayed repair does not improve survival in CDH. Prospectively collected data from 1,385 CDH Registry infants without preoperative extracorporeal membrane oxygen therapy (ECMO) were evaluated. Patients were stratified by timing of repair: Day of life (DOL) 0-3 (group 1), 4-7 (group 2), or>8 (group 3), and the effect of surgical timing on mortality was determined by logistic regression and risk-adjusted for severity of illness. The unadjusted odds ratio (OR) for mortality increased significantly with delayed repair (group 2, 1.73 [95% CI, 1.00-2.98; group 3, 3.42 [95% CI, 1.97-5.96]). However, when adjusted for severity of illness, delay in repair did not predict increased mortality (group 2, 1.2 [95% CI, 0.7-2.2]; group 3, 1.4 [95% CI, 0.8-2.6]), nor did it portend an increased need for postoperative ECMO (group 2, 1.1 [95% CI, 0.5-2.4]; group 3, 0.5 [95% CI, 0.2-1.4]).\nQuestion: A risk-stratified analysis of delayed congenital diaphragmatic hernia repair: does timing of operation matter?",
    "gt": "After adjustment for known risk factors, the timing of CDH repair in low-risk infants does not seem to influence mortality. However, specific clinical parameters guiding timing of elective CDH repair remain unknown.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Long-term lamivudine therapy is required for patients with chronic hepatitis B, because hepatitis reappears frequently after it has withdrawn. However, hepatitis B virus (HBV) mutants resistant to lamivudine emerge frequently accompanied by breakthrough hepatitis. Effects of entecavir were evaluated in 19 patients who had developed breakthrough hepatitis during lamivudine therapy for longer than 5 years. This study is a subgroup analysis of a previously reported study. Entecavir, in either 0.5 or 1.0 mg/day doses, was given to 10 and nine patients for 52 weeks, respectively, and then all received 1.0 mg/day entecavir for an additional 68-92 weeks. There were no differences in biochemical and virological responses in the two groups of patients with respect to the two different initial doses of entecavir. Serum levels of alanine aminotransferase were normalized in 17 (90%) patients, and hepatitis B e antigen (HBeAg) disappeared from the serum in two (14%) of the 14 patients who were HBeAg-positive before. Furthermore, a decrease in histological activity index score greater than 2 points was achieved in nine of the 11 (82%) patients in whom annual liver biopsies were performed during 3 years while they received entecavir. HBV mutants resistant to entecavir emerged in five of the 19 (26%) patients, and hepatitis flare occurred in two of them (40%).\nQuestion: Efficacy of entecavir treatment for lamivudine-resistant hepatitis B over 3 years: histological improvement or entecavir resistance?",
    "gt": "Entecavir in the long term would be useful for histological improvement of breakthrough hepatitis induced by lamivudine-resistant HBV mutants in patients with chronic hepatitis B. However, the relatively high rate of entecavir resistance is a concern, and other strategies need to be considered when available.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Seeds of annual halophytes such as Suaeda maritima experience fluctuating salinity, hydration, hypoxia and temperature during dormancy. Germination then occurs in one flush of 2-3 weeks after about 5 months of winter dormancy during which time the seeds can remain in saline, often waterlogged soil. The aim of this study was to investigate the effect of simulated natural conditions during dormancy on germination and to compare this with germination following the usual conditions of storing seeds dry. The effects of hydration, salinity, hypoxia and temperature regimes imposed during dormancy on germination were investigated. Also looked at were the effects of seed size on germination and the interaction between salinity during dormancy and salinity at the time of germination. Various pre-treatments were imposed on samples of seeds that had been stored dry or wet for different periods of time during the 5 months of natural dormancy. Subsequent germination tests were carried out in conditions that simulated those found in the spring when germination occurs naturally. Various salinities were imposed at germination for a test of interaction between storage salinity and salinity at germination. A temperature of about 15 degrees C was needed for germination and large seeds germinated earlier and better than small seeds. Cold seawater pre-treatment was necessary for good germination; the longer the saline pre-treatment during the natural dormancy period the better the germination. There appeared to be no effect of any specific ion of the seawater pre-treatment on germination and severe hypoxia did not prevent good germination. A short period of freezing stimulated early germination in dry-stored seed. Storage in cold saline or equivalent osmotic medium appeared to inhibit germination during the natural dormancy period and predispose the seed to germinate when the temperature rose and the salinity fell. Seeds that were stored in cold wet conditions germinated better in saline conditions than those stored dry.\nQuestion: Do conditions during dormancy influence germination of Suaeda maritima?",
    "gt": "The conditions under which seeds of S. maritima are stored affect their subsequent germination. Under natural conditions seeds remain dormant in highly saline, anoxic mud and then germinate when the temperature rises above about 15 degrees C and the salinity is reduced.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To test the reproducibility of the finding that early intensive care for whiplash injuries is associated with delayed recovery. We analyzed data from a cohort study of 1,693 Saskatchewan adults who sustained whiplash injuries between July 1, 1994 and December 31, 1994. We investigated 8 initial patterns of care that integrated type of provider (general practitioners, chiropractors, and specialists) and number of visits (low versus high utilization). Cox models were used to estimate the association between patterns of care and time to recovery while controlling for injury severity and other confounders. Patients in the low-utilization general practitioner group and those in the general medical group had the fastest recovery even after controlling for important prognostic factors. Compared with the low-utilization general practitioner group, the 1-year rate of recovery in the high-utilization chiropractic group was 25% slower (adjusted hazard rate ratio [HRR] 0.75, 95% confidence interval [95% CI]0.54-1.04), in the low-utilization general practitioner plus chiropractic group the rate was 26% slower (HRR 0.74, 95% CI 0.60-0.93), and in the high-utilization general practitioner plus chiropractic combined group the rate was 36% slower (HRR 0.64, 95% CI 0.50-0.83).\nQuestion: Early aggressive care and delayed recovery from whiplash: isolated finding or reproducible result?",
    "gt": "The observation that intensive health care utilization early after a whiplash injury is associated with slower recovery was reproduced in an independent cohort of patients. The results add to the body of evidence suggesting that early aggressive treatment of whiplash injuries does not promote faster recovery. In particular, the combination of chiropractic and general practitioner care significantly reduces the rate of recovery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Individuals referred to cardiac rehabilitation programs (CRPs) after stroke have demonstrated postprogram improvements in cardiovascular fitness (VO2peak). However, the effect of CRPs on other physiological/quality-of-life outcomes and effect of time from stroke on these results has not been investigated. The objectives of the present study are (1) to evaluate the effects of a CRP in participants with motor impairment after stroke and (2) to explore the effects of elapsed time from stroke on physiological/quality-of-life outcomes. The CRP included 24 weeks of resistance and aerobic training. Primary outcomes in 120 participants, 25.4±42.3 (mean±standard deviation) months after stroke, included 6-minute walk distance (6MWD), VO2peak, timed repeated sit-to-stand performance, and affected-side isometric knee extensor strength (IKES). Secondary measures included gait characteristics (cadence, step lengths, and symmetry), walking speed, balance (Berg Balance Scale), affected-side range of motion (ROM), elbow flexor and grip strength, anaerobic threshold, and perceptions of participation/social reintegration. After adjusting for multiple comparisons, participants demonstrated significant improvements (all P<.001) in 6MWD (283.2±126.6 to 320.7±141.8 m), sit-to-stand performance (16.3±9.5 to 13.3±7.1 seconds), affected-side IKES (25.9±10.1 to 30.2±11 kg as a percentage of body mass), and VO2peak (15.2±4.5 to 17.2±4.9 mL·kg·min(-1)). Participants also demonstrated post-CRP improvements in secondary outcomes: anaerobic threshold, balance, affected-side hip/shoulder ROM, grip and isometric elbow flexor strength, participation, walking speed, cadence (all P<.001), and bilateral step lengths (P<.04). In a linear regression model, there was a negative association between the change in 6MWD and time from stroke (β=-42.1; P=.002) independent of baseline factors.\nQuestion: Outcomes in people after stroke attending an adapted cardiac rehabilitation exercise program: does time from stroke make a difference?",
    "gt": "A CRP yields improvements over multiple domains of recovery; however, those who start earlier demonstrate greater improvement in functional ambulation independent of baseline factors. These data support the use of adapted CRPs as a standard of care practice after conventional stroke rehabilitation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study was to investigate whether the relation between responsibility for domestic work and psychological distress was influenced by perception of gender inequality in the couple relationship and relative socioeconomic position. In the Northern Swedish Cohort, all pupils who studied in the last year of compulsory school in a northern Swedish town in 1981 have been followed regularly until 2007. In this study, participants living with children were selected (n = 371 women, 352 men). The importance of relative socioeconomic position and perception of gender inequality in the couple relationship in combination with domestic work for psychological distress was examined through logistic regression analysis. Two combinations of variables including socioeconomic position ('having less than half of the responsibility for domestic work and partner higher socioeconomic position' and 'having more than half the responsibility for domestic work and equal socioeconomic position') were related to psychological distress. There were also higher ORs for psychological distress for the combinations of having 'less than half of the responsibility for domestic work and gender-unequal couple relationship' and 'more than half the responsibility for domestic work and gender-unequal couple relationship'. Having a lower socioeconomic position than the partner was associated with higher ORs for psychological distress among men.\nQuestion: Domestic work and psychological distress--what is the importance of relative socioeconomic position and gender inequality in the couple relationship?",
    "gt": "This study showed that domestic work is a highly gendered activity as women tend to have a greater and men a smaller responsibility. Both these directions of inequality in domestic work, in combination with experiencing the couple relationship as gender-unequal, were associated with psychological distress There is a need for more research with a relational approach on inequalities in health in order to capture the power relations within couples in various settings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Selective serotonin reuptake inhibitors (SSRIs) have been suspected of cardiac teratogenicity, but reports have been inconsistent. Our aim was to investigate the rate of nonsyndromic congenital heart defects in newborns exposed in utero to SSRIs compared with unexposed controls. This prospective study of women who gave birth at our tertiary center from 2000 to 2007 yielded 235 women who reported first-trimester SSRI use during pregnancy. All newborns born during the study period and found to have a persistent cardiac murmur on day 2 or 3 of life were referred for examination by a pediatric cardiologist and by echocardiography. The findings were compared between the newborns who were exposed to SSRIs and those who were not. Nonsyndromic congenital heart defects were identified by echocardiography in 8 of 235 (3.40%) newborns exposed in utero to SSRIs and in 1083 of 67,636 (1.60%) non-exposed newborns. The difference in prevalence between the two groups was significant (relative risk, 2.17; 95% confidence interval, 1.07-4.39). The prevalence rates for paroxetine and fluoxetine exposure were 4.3% and 3.0%, respectively. All cardiac defects in the study group were mild: ventricular septal defect (6), bicuspid aortic valve (1) and right superior vena cava to coronary sinus (1).\nQuestion: Are selective serotonin reuptake inhibitors cardiac teratogens?",
    "gt": "Newborns exposed in utero to SSRIs, have a twofold higher risk of mild nonsyndromic heart defects than unexposed infants. The data suggest that women who require SSRI treatment during pregnancy can be reassured that the fetal risk is low and possible cardiac malformations will probably be mild. Late-targeted ultrasound and fetal echocardiography at 22 to 23 weeks' gestation are recommended in this patient group.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patient notes are used for a variety of purposes in health care. Medical students are taught the structure of patient notes early in training. Review of patient notes are then used to assess synthesis and integration of patient information. It is critical that the information in the note accurately and completely represents the student-patient encounter. The authors reviewed videotapes of students in three standardized-patient based scenarios and compared what occurred during the physical examination with the subsequent documentation in the patient note. In all, 207 encounter-note pairs were reviewed. Only 8 (4%) of the notes completely and accurately represented what occurred during the encounter. Problems with underdocumentation, overdocumentation, and inaccurate documentation of physical findings were seen for all three patient scenarios.\nQuestion: Do students do what they write and write what they do?",
    "gt": "These findings highlight the need to teach and assess both data gathering skills and written documentation of findings in medical training.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine reciprocal associations between substance use (cigarette smoking, use of alcohol, marijuana, and other illegal drugs) and suicidal ideation among adolescents and young adults (aged 11-21 at wave 1; aged 24-32 at wave 4). Four waves public-use Add Health data were used in the analysis (N=3342). Respondents were surveyed in 1995, 1996, 2001-2002, and 2008-2009. Current regular smoking, past-year alcohol use, past-year marijuana use, and ever use of other illegal drugs as well as past-year suicidal ideation were measured at the four waves (1995, 1996, 2001-2002, and 2008-2009). Fixed effects models with lagged dependent variables were modeled to test unidirectional associations between substance use and suicidal ideation, and nonrecursive models with feedback loops combining correlated fixed factors were conducted to examine reciprocal relations between each substance use and suicidal ideation, respectively. After adjusting for the latent time-invariant effects and lagged effects of dependent variables, the unidirectional associations from substance use to suicidal ideation were consistently significant, and vice versa. Nonrecursive model results showed that use of cigarette or alcohol increased risk of suicidal ideation, while suicidal ideation was not associated with cigarette or alcohol use. Reversely, drug use (marijuana and other drugs) did not increase risk of suicidal ideation, but suicidal ideation increased risk of illicit drug use.\nQuestion: Suicidal ideation and substance use among adolescents and young adults: a bidirectional relation?",
    "gt": "The results suggest that relations between substance use and suicidal ideation are unidirectional, with cigarette or alcohol use increasing risk of suicidal ideation and suicidal ideation increasing risk of illicit drug use.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We report our 5-year experience of continuous flow left ventricular assist device (LVAD) implantation without the use of anti-platelet therapy. Between February 2006 and September 2011, 27 patients (26 men; 1 woman) were implanted with a continuous flow LVAD (HeartMate II, Thoratec Corporation, Pleasanton, CA, USA). The mean age was 55.7 ± 9.9 years. The mean duration of support was 479 ± 436 (1-1555) days with 35.4 patient-years on support. Twenty-one patients were implanted as a bridge to transplantation and 6 for destination therapy. The anticoagulation regimen was fluindione for all patients, with aspirin for only 4 patients. At the beginning of our experience, aspirin was administered to 4 patients for 6, 15, 60 and 460 days. Due to gastrointestinal (GI) bleeding and epistaxis, aspirin was discontinued, and since August 2006, no patients have received anti-platelet therapy. At 3 years, the survival rate during support was 76%. The most common postoperative adverse event was GI bleeding (19%) and epistaxis (30%) (median time: 26 days) for patients receiving fluindione and aspirin. The mean International Normalized Ratio (INR) was 2.58 ± 0.74 during support. Fifteen patients have been tested for acquired Von Willebrand disease. A diminished ratio of collagen-binding capacity and ristocetin cofactor activity to Von Willebrand factor antigen was observed in 7 patients. In the postoperative period, 2 patients presented with ischaemic stroke at 1 and 8 months. One of these 2 patients had a previous history of carotid stenosis with ischaemic stroke. There were no patients with haemorrhagic stroke, transient ischaemic attack or pump thrombosis. The event rate of stroke (ischaemic and haemorrhagic) per patient-year was 0.059 among the patients without aspirin with fluindione regimen only.\nQuestion: Is anti-platelet therapy needed in continuous flow left ventricular assist device patients?",
    "gt": "A fluindione regimen without aspirin in long-duration LVAD support appears to not increase thromboembolic events and could lead to a diminished risk of haemorrhagic stroke.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: YKL-40 (human cartilage glycoprotein-39, or 38-kDa heparin-binding glycoprotein) is a mammalian member of a protein family that includes bacterial chitinases. YKL-40 mRNA is expressed by human liver and may play a role in tissue remodelling. The aims were to assess whether circulating YKL-40 is released or extracted in the hepatosplanchnic system and to localize YKL-40 in liver tissue. Plasma YKL-40 was determined by radioimmunoassay in 25 patients with liver diseases (alcoholic cirrhosis (n = 20), chronic active hepatitis (n = 2), cirrhosis of unknown aetiology (n = 2), and fatty liver (n = 1) and in 18 subjects with normal liver function during a haemodynamic investigation with catheterization of liver vein and the femoral artery. Immunohistochemical studies of the localization of YKL-40 in cryostal liver biopsy specimens were obtained from eight other patients with alcoholic liver disease. Plasma YKL-40 was significantly increased in patients with alcoholic cirrhosis (median, 523 micrograms/l; P<0.001) compared with controls (106 micrograms/l), and plasma YKL-40 in the hepatic vein was higher (P<0.01) than that of the artery in both the patients and controls, showing release of YKL-40 from the hepatosplanchnic area. The release rate of YKL-40 from the hepatosplanchnic area was higher in patients with liver disease than in controls (11.0 versus 2.1 micrograms/min, P<0.05). Furthermore, the highest plasma YKL-40 levels were found in patients with a moderate or severe degree of liver fibrosis, and immunohistochemical studies showed positive staining for YKL-40 antigen in areas of the liver biopsy with fibrosis.\nQuestion: Plasma YKL-40: a new potential marker of fibrosis in patients with alcoholic cirrhosis?",
    "gt": "The increased plasma YKL-40 in patients with alcoholic cirrhosis may reflect the remodelling of liver fibrosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess the importance of intraoperative management of recipient hemodynamics for immediate versus delayed graft function. The retrospective study of 1966 consecutive renal transplants performed in our department between June 1980 and December 2009 analyzed several perioperative hemodynamic factors: central venous pressure (CVP), mean arterial pressure (MAP) as well as volumes of fluids, fresh frozen plasma (FFP), albumin, and whole blood transfusions. We examined their influence on renal graft function parameters: immediate diuresis, serum creatinine levels, acute rejection, chronic transplant dysfunction, and graft survival. Mean CVP was 9.23 ± 2.65 mm Hg and its variations showed no impact on graft function. We verified a twofold greater risk of chronic allograft dysfunction among patients with CVP ≥ 11 mm Hg (P<.001). Mean MAP was 93.74 ± 13.6 mm Hg; graft survivals among subjects with MAP ≥ 93 mm Hg were greater than those of patients with MAP<93 mm Hg (P = .04). On average, 2303.6 ± 957.4 mL of saline solutions were infused during surgery. Patients who received whole blood transfusions (48%) showed a greater incidence of acute rejection episodes (ARE) (P = .049) and chronic graft dysfunction (P<.001). Patients who received FFP (55.7%), showed a higher incidence of ARE (P<.001). Only 4.6% of patients (n = 91) received human albumin with a lower incidence of ARE (P = .045) and chronic graft dysfunction (P = .024). Logistic binary regression analysis revealed that plasma administration was an independent risk factor for ARE (P<.001) and chronic dysfunction (P = .028). Volume administration (≥ 2500 mL) was also an independent risk factor for chronic allograft dysfunction (P = .016). Using Cox regression, we verified volume administration ≥ 2500 mL to be the only independent risk factor for graft failure (P<.001).\nQuestion: Do intraoperative hemodynamic factors of the recipient influence renal graft function?",
    "gt": "MAP ≥ 93 mm Hg and perioperative fluid administration<2500 mL were associated with greater graft survival. Albumin infusion seemed to be a protective factor, while CVP ≥ 11 mm Hg, whole blood, and FFP transfusions were associated with higher rates of ARE and chronic graft dysfunction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The aim of this study is to evaluate the risk of accepting cardiac donors after an episode of cardiopulmonary resuscitation. Since 1997, 13 resuscitated donor hearts (10 M, 3 F, age 15-54 years) after sudden cardiac arrest have been transplanted. The retrospective analysis was used. Allografts after resuscitation episode were implanted in 13 patients (6 M, 7 F, age 31-65 years). 11 patients were on the urgency list and two of them required periodically intravenous inotropic therapy. Two patients (P.A, B.J) died in the first 24 hours after procedure (cause of death: pulmonary embolism, extensive cardiac ischemia). During follow up (6-48 months, avg. 25.1 +/- 15.9 months) none of the 11 patients died. All patients are NYHA functional class I or I/II. Total time of cardiopulmonary resuscitation did not influence the time of reperfusion (p>0.05). Analysis of cardiac index Cl (l/min/m2) at 2, 4, 6, 8, 12, 24, 72 hours after heart transplantation showed correct values during following days. Echocardiographic and invasive examinations (8 patients) do not show any abnormalities.\nQuestion: Does the episode of cardiopulmonary resuscitation in cardiac donors increase the risk of heart transplantation?",
    "gt": "These results suggest that acceptance of cardiac donors after cardiopulmonary resuscitation may not increase the risk of heart transplantation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Pneumothorax is defined as air in pleural space. The etiology of spontaneous pneumothorax (SP) is still under investigation and, despite many studies, remains uncertain. The aim of this study was to investigate the effects of the lunar cycle and daily weather changes on SP development. The data of patients admitted to our clinic with SP were analysed retrospectively. The daily atmospheric pressure, relative ratio of humidity and temperature in degrees Celsius of each day were obtained. The mean values for each day, from the first to the 29th day, of the synodic lunar cycle (SLC) were calculated for the five-year study period. The attacks were allocated to the appropriate day of an ideal 29-day SLC, irrespective of the calendar date. A total of 131 patients who were admitted to our hospital with SP (130 males and 1 female with an average age of 32.4±12.2) were included in this study. The number of patients with SP showed a statistically significant correlation with mean atmospheric pressure (p=0.005), relative humidity (p=0.007) and outdoor temperature (p=0.02) but not with the SLC.\nQuestion: Do Atmospheric Changes and the Synodic Lunar Cycle Affect the Development of Spontaneous Pneumothorax?",
    "gt": "SP is significantly influenced by weather-related factors. Changes in atmospheric pressure, humidity and outdoor temperature had obvious effects on the development of SP. However, the SLC had no effect on SP.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The role of combined endobronchial ultrasound-guided transbronchial needle aspiration (EBUS-TBNA) and endoscopic ultrasound-guided fine needle aspiration (EUS-FNA) with a single bronchoscope is poorly understood. The purpose of the present study was to elucidate the roles of EBUS-TBNA and EUS-FNA with a single bronchoscope in the preoperative hilar and mediastinal staging of non-small cell lung cancer (NSCLC). A total of 150 patients with potentially resectable known or suspected NSCLC were enrolled in our prospective study. EBUS-TBNA was performed, followed by EUS-FNA, with an EBUS bronchoscope for N2 and N3 nodes≥5 mm in the shortest diameter on ultrasound images, in a single session. EBUS-TBNA was performed for 257 lymph nodes and EUS-FNA for 176 lymph nodes. Of the 150 patients, 146 had a final diagnosis of NSCLC. Of these 146 patients, 33 (23%) had N2 and/or N3 nodal metastases. The sensitivity of EBUS-TBNA, EUS-FNA, and the combined approach per patient was 52%, 45%, and 73%, respectively (EBUS-TBNA vs the combined approach, P=.016, McNemar's test). The corresponding negative predictive value was 88%, 86%, and 93%. Two patients (1%) developed severe cough from EBUS-TBNA.\nQuestion: Endoscopic ultrasound-guided fine needle aspiration and endobronchial ultrasound-guided transbronchial needle aspiration: Are two better than one in mediastinal staging of non-small cell lung cancer?",
    "gt": "The combined endoscopic approach with EBUS-TBNA and EUS-FNA is a safe and accurate method for preoperative hilar and mediastinal staging of NSCLC, with better results than with each technique by itself.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess the relationship between leg length and glucose tolerance in pregnancy. The leg length and leg-to-height percentage were prospectively determined on 161 glucose-tolerant women during pregnancy and 61 women with gestational diabetes mellitus (GDM). Women with GDM were a mean of 2.8 cm shorter than women who were glucose tolerant, due entirely to their leg lengths being a mean of 3.2 cm shorter. With respect to the 2-h result on the glucose tolerance test (GTT), there were negative correlations for height (r = -0.161, P = 0.017), leg length (r = -0.266, P<0.0005), and the leg-to-height percentage (r = -0.294, P<0.0005). The correlation between the leg-to-height percentage and the 2-h result on the GTT remained significant after adjustment for age (r = -0.252, P<0.0005) and for age and BMI (r = -0.224, P = 0.001).\nQuestion: Gestational diabetes: Is there a relationship between leg length and glucose tolerance?",
    "gt": "Women with GDM are shorter than glucose-tolerant women and have a lower leg-to-height percentage. Consideration of short stature as a risk factor for GDM is not valid without taking into account the leg-to-height percentage.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study examined whether heightened cardiovascular reactivity and low socioeconomic status had synergistic effects on the progression of carotid atherosclerosis in a population of eastern Finnish men. Data from the Kuopio Ischemic Heart Disease Risk Factor Study were used to measure 4-year progression of intima-media thickness in 882 men according to cardiovascular reactivity and socioeconomic status. Associations were examined in relation to risk factors and were stratified by baseline levels of atherosclerosis and prevalent ischemic heart disease. The effect of reactivity on atherosclerotic progression depended on socioeconomic status. Men who had heightened cardiovascular responsiveness to stress and were born into poor families, received little education, or had low incomes had the greatest atherosclerotic progression.\nQuestion: Does low socioeconomic status potentiate the effects of heightened cardiovascular responses to stress on the progression of carotid atherosclerosis?",
    "gt": "An understanding of associations between individual risk factors and disease should be based on etiologic hypotheses that are conceived at the population level and involve fundamental social and economic causes of disease. This study demonstrates how examining the interaction of an individual biological predisposition will low socioeconomic status over the life course is etiologically informative for understanding the progression of atherosclerotic vascular disease.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare the diagnostic accuracy of standard (st) and long-term video (lt) EEG in elderly patients with suspected non-convulsive seizures. Over a 12-month period, we prospectively included all elderly (over-65) hospitalized patients having undergone lt-EEG for suspected non-convulsive seizures (n=43). st-EEG was defined as the first 20min of each lt-EEG. We recorded the patients' clinical and imaging characteristics and final diagnosis and assessed the respective diagnostic values of st-EEG and lt-EEG. Epileptiform discharges were detected on standard EEG in only 7% of patients and in 28% of patients on Lt-EEG (p=0.004). Non-convulsive seizures were recorded in 1 case vs. 4, respectively. Nine of 40 negative standard EEG showed later epileptiform activities. The median time to occurrence of the first epileptiform activities was 46.5min (interquartile range: 36.5-239.75min). Epileptiform activity occurred during sleep only in 33% patients with a negative st-EEG. Dementia was associated with a positive lt-EEG (p:0.047).\nQuestion: Is long-term electroencephalogram more appropriate than standard electroencephalogram in the elderly?",
    "gt": "Lt-EEG was clearly superior to standard EEG for detecting epileptiform activity in elderly when suspecting non convulsive seizures.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It is still unclear whether the inlay thickness is an important factor influencing the fracture risk of ceramic inlays. As high tensile stresses increase the fracture risk of ceramic inlays, the objective of the present finite element method (FEM) study was to biomechanically analyze the correlation between inlay thickness (T) and the induced first principal stress. Fourteen ceramic inlay models with varying thickness (0.7-2.0 mm) were generated. All inlays were combined with a CAD model of a first mandibular molar (tooth 46), including the PDL and a mandibular segment which was created by means of the CT data of an anatomical specimen. Two materials were defined for the ceramic inlays (e.max(®) or empress(®)) and an occlusal force of 100 N was applied. The first principal stress was measured within each inlay and the peak values were considered and statistically analyzed. The stress medians ranged from 20.7 to 22.1 MPa in e.max(®) and from 27.6 to 29.2 MPa in empress(®) inlays. A relevant correlation between the first principal stress and thickness (T) could not be detected, neither for e.max(®) (Spearman: r=0.028, p=0.001), nor for empress(®) (Spearman: r=0.010, p=0.221). In contrast, a very significant difference (p<0.001) between the two inlay materials (M) was verified.\nQuestion: Ceramic inlays: is the inlay thickness an important factor influencing the fracture risk?",
    "gt": "Under the conditions of the present FEM study, the inlay thickness does not seem to be an important factor influencing the fracture risk of ceramic inlays. However, further studies are necessary to confirm this.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Fibromyalgia (FM) is a form of non-articular rheumatism characterised by chronic widespread musculoskeletal aching. Although some works have investigated the possible role of oxidative stress in the pathophysiology of FM, none has analysed a significant number of oxidative markers in the same patients. Consequently, we have performed an exhaustive study of the oxidative/antioxidative status in FM patients and healthy controls, as well as the relationship with FM clinical parameters. In 45 female patients and 25 age-matched controls, we investigated the oxidative (lipid and protein peroxidation, and oxidative DNA damage) and antioxidative status (total antioxidant capacity (TAC), and antioxidant enzyme activities and compounds). Functional capacity and musculoskeletal pain were assessed by Fibromyalgia Impact Questionnaire (FIQ) and Visual Analogue Scale (VAS), respectively. The physical (PCS-12) and mental (MCS-12) health status was evaluated by SF-12. A significant increase in oxidative DNA damage and protein carbonyl content was found in FM patients vs. controls, as well as in antioxidant compounds such as copper and ceruloplasmin. Patients had diminished levels of TAC and zinc. Enzyme activities of superoxide dismutase, glutathione peroxidase, and catalase were lower in FM patients. Significant correlations were observed in patients between oxidative DNA damage and MCS-12, and zinc and PCS-12.\nQuestion: Is fibromyalgia-related oxidative stress implicated in the decline of physical and mental health status?",
    "gt": "These findings reveal an imbalance between oxidants and antioxidants in FM patients. The lower antioxidant enzyme activities may lead to oxidative stress through the oxidation of DNA and proteins, which may affect the health status of FM patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was designed to determine whether digital intubation is a valid option for definitive airway control by emergency physicians. Digital intubation was performed by 18 emergency medicine residents and 4 staff emergency medicine physicians on 6 different cadavers. Placement was confirmed by direct laryngoscopy. The total time for all attempts used, as well as the number of attempts, was recorded. Each participant attempted intubation on all 6 cadavers. For 5 of the 6 cadavers, successful intubation occurred 90.9% of the time (confidence interval [CI], 85.5%-96.3%) for all participants. The average number of attempts for these 5 cadavers was 1.5 (CI, 1.4-1.7), and the average time required for success or failure was 20.8 seconds (CI, 16.9-24.8). The sixth cadaver developed soft tissue damage and a false passage near the vocal cords resulting in multiple failed attempts.\nQuestion: Is digital intubation an option for emergency physicians in definitive airway management?",
    "gt": "Although the gold standard for routine endotracheal intubation remains to be direct laryngoscopy, its effectiveness in certain situations may be limited. We believe that digital intubation provides emergency physicians with another option in securing the unprotected airway.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patient recruitment into clinical trials is a major challenge, and the elderly, socially deprived and those with multiple comorbidities are often underrepresented. The idea of paying patients an incentive to participate in research is controversial, and evidence is needed to evaluate this as a recruitment strategy. In this study, we sought to assess the impact on clinical trial recruitment of a £100 incentive payment and whether the offer of this payment attracted more elderly and socially deprived patients. A total of 1,015 potential patients for five clinical trials (SCOT, FAST and PATHWAY 1, 2 and 3) were randomised to receive either a standard trial invitation letter or a trial invitation letter containing an incentive offer of £100. To receive payment, patients had to attend a screening visit and consent to be screened (that is, sign a consent form). To maintain equality, eventually all patients who signed a consent form were paid £100. The £100 incentive offer increased positive response to the first invitation letter from 24.7% to 31.6%, an increase of 6.9% (P < 0.05). The incentive offer increased the number of patients signing a consent form by 5.1% (P < 0.05). The mean age of patients who responded positively to the invitation letter was 66.5 ± 8.7 years, whereas those who responded negatively were significantly older, with a mean age of 68.9 ± 9.0 years. The incentive offer did not influence the age of patients responding. The incentive offer did not improve response in the most socially deprived areas, and the response from patients in these areas was significantly lower overall.\nQuestion: Does offering an incentive payment improve recruitment to clinical trials and increase the proportion of socially deprived and elderly participants?",
    "gt": "A £100 incentive payment offer led to small but significant improvements in both patient response to a clinical trial invitation letter and in the number of patients who consented to be screened. The incentive payment did not attract elderly or more socially deprived patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Using administrative data (Truven MarketScan® Research Databases), patients diagnosed with T2DM between 2007 and 2014 with ⩾6months continuous enrolment pre- and post-diagnosis were evaluated. Pretreatment was defined as OAD use at least 3months prior to T2DM diagnosis. Time-to-insulin initiation and healthcare costs were compared by OAD pretreatment status. Of the 866,605 patients studied, 241,856 (27.9%) were pretreated prior to T2DM diagnosis. Mean follow-up was 2.9years for pretreatment and 3.1years for those without pretreatment. Monthly diabetes-related pharmacy costs were significantly higher among pretreated patients ($66 versus $36, p<0.0001), as were overall monthly pharmacy costs ($255 versus $198, p<0.0001). Pretreated patients had lower mean monthly costs, both total ($625 versus $671, p<0.0001) and diabetes-related ($207 versus $214, p=0.0012). After multivariable adjustment, mean monthly diabetes-related total healthcare costs were higher among pretreated patients (+$60) but total all-cause monthly healthcare costs were significantly lower (-$354) (both p<0.05). Pretreatment was associated with a lower insulin initiation probability for 2years, after which probability was similar; the adjusted hazard ratio for pretreatment in a time-to-insulin model was 0.96 (95% CI, 0.94-0.97).\nQuestion: Evaluation of patients with type 2 diabetes mellitus receiving treatment during the pre-diabetes period: Is early treatment associated with improved outcomes?",
    "gt": "Pretreatment with OADs is associated with a modest delay in initiating insulin therapy and lower total healthcare costs. The clinical and pharmacoeconomic benefits of pretreatment should be elucidated in a prospective study.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was to compare the types of therapeutic neck dissection in patients with differentiated thyroid carcinoma. Sixty-one patients with lymph node metastasis in the neck, treated between 1997 and 2001, were studied retrospectively. A comparative study was made of a selective lateral neck dissection group and a radical or modified radical neck dissection group for recurrence, disease free survival (DFS), and overall survival (OS). Type of dissection was not related to DFS (P=0.92), OS (P=0.33), and local recurrence ratio (P=0.56). The factors affecting local recurrence were the age over 45 years (P=0.02), tumor size (0.005), and the presence of distant metastasis (P=0.04). The factors affecting DFS and OS were tumor size (0.003), thyroid capsule invasion (0.004).\nQuestion: Is the type of dissection in lateral neck metastasis for differentiated thyroid carcinoma important?",
    "gt": "Determination of the type of therapeutic neck dissection depends on patient and tumor characteristics. Selective lateral neck dissection can be applied safely in selected cases.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The lean phenotype of cystathionine beta-synthase-deficient homocystinuria and the positive association of plasma total cysteine (tCys) with body mass index (BMI) suggest that total homocysteine (tHcy) and tCys are associated with body composition. We aimed to study associations of tCys and tHcy with body composition in the general population. Using data from 7038 Hordaland Homocysteine Study participants, we fitted regression models and dose-response curves of tCys and tHcy with BMI. In 5179 participants, we investigated associations of tCys and tHcy with fat mass and lean mass and examined whether changes in these aminothiols predicted body composition 6 y later. tCys showed positive associations with BMI (partial r = 0.28, P<0.001), and fat mass (partial r = 0.25, P<0.001), independent of diet, exercise, and plasma lipids. Women in the highest tCys quintile had fat mass 9 kg (95% CI: 8, 10 kg; P<0.001) greater than that of women in the lowest quintile. The corresponding values for men were 6 kg (95% CI: 5, 7 kg; P<0.001; P<0.001 in both sexes, ANOVA across quintiles). The rise in tCys over 6 y was associated with greater fat mass at follow-up (P<0.001), but there was no effect on lean mass. tHcy was not associated with lean mass, and it became significantly inversely associated with BMI and fat mass only after adjustment for tCys. The association between tHcy and lean mass was not significant.\nQuestion: Homocysteine, cysteine, and body composition in the Hordaland Homocysteine Study: does cysteine link amino acid and lipid metabolism?",
    "gt": "tCys concentrations show a strong positive association with BMI, mediated through fat mass. The link between cysteine and lipid metabolism deserves further investigation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Research on β-cell autoimmunity in cystic fibrosis (CF)-related diabetes (CFRD) is still rare. We aimed to analyze the frequency of β-cell autoimmunity and the influence on age at diabetes onset, insulin requirement, type of insulin therapy, and hypoglycemic or ketoacidotic events in patients with CFRD compared with antibody-negative patients with CFRD in the Diabetes Patienten Verlaufsdokumentation (DPV) registry. We analyzed data of 837 patients with CFRD in the German/Austrian DPV database by multivariable mixed-regression modeling. In our cohort, 8.5% of patients with CFRD (n = 72) were found to be β-cell antibody positive. There was a female preponderance in this patient group: 65.3 vs. 57.6%. Diabetes onset (median [interquartile range]) was earlier (14.00 [10.15-15.90]vs. 16.10 [13.50-21.20] years; P<0.005), and insulin dose/kg body weight was higher (0.95 [0.61-1.15] vs. 0.67 [0.33-1.04]IU/kg; P<0.05). There were also differences in the type of insulin treatment. Insulin pump therapy was used significantly more often in patients with CFRD with β-cell autoimmunity (18.2 vs. 6.4%; P<0.05). The differences for multiple daily injections (ICT) and conventional therapy (CT) were not significant (ICT: 67.7 vs. 79.0%; CT: 15.2 vs. 14.6). Oral antidiabetic agents were rarely used in both groups. Rate of severe hypoglycemia with coma and rate of ketoacidosis were higher in antibody-positive patients (hypoglycemia with coma: 8.0 vs. 1.4, P<0.05; ketoacidosis: 9.3 vs. 0.9, P<0.05).\nQuestion: Does β-Cell Autoimmunity Play a Role in Cystic Fibrosis-Related Diabetes?",
    "gt": "Presence of β-cell autoantibodies in our cohort of patients with CFRD (8.5%) appeared to be greater than in the general population and was associated with female sex, earlier onset of diabetes, and higher insulin requirement. Insulin pump therapy was used significantly more often in patients with β-cell antibodies. Severe hypoglycemia and ketoacidosis were significantly more frequent in CFRD with β-cell autoimmunity compared with β-cell antibody-negative patients with CFRD.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Some studies suggest that epidural analgesia prolongs labor and increases the incidence of cesarean section, especially if it is administered before 5 cm cervical dilation. The purpose of the current study was to determine whether early administration of epidural analgesia affects obstetric outcome in nulliparous women who are in spontaneous labor. Informed consent was obtained from 344 healthy nulliparous women with a singleton fetus in a vertex presentation, who requested epidural analgesia during spontaneous labor at at least 36 weeks' gestation. Each patient was randomized to receive either early or late epidural analgesia. Randomization occurred only after the following conditions were met: (1) the patient requested pain relief at that moment, (2) a lumbar epidural catheter had been placed, and (3) the cervix was at least 3 cm but less than 5 cm dilated. Patients in the early group immediately received epidural bupivacaine analgesia. Patients in the late group received 10 mg nalbuphine intravenously. Late-group patients did not receive epidural analgesia until they achieved a cervical dilation of at least 5 cm or until at least 1 h had elapsed after a second dose of nalbuphine. Ten of the 344 patients were excluded because of a protocol violation or voluntary withdrawal from the study. Early administration of epidural analgesia did not increase the incidence of oxytocin augmentation, prolong the interval between randomization and the diagnosis of complete cervical dilation, or increase the incidence of malposition of the vertex at delivery. Also, early administration of epidural analgesia did not result in an increased incidence of cesarean section or instrumental vaginal delivery. Seventeen (10%) of 172 women in the early group and 13 (8%) of 162 women in the late group underwent cesarean section (relative risk for the early group 1.22; 95% confidence interval 0.62-2.40). Patients in the early group had lower pain scores between 30 and 150 min after randomization. Infants in the late group had lower umbilical arterial and venous blood pH and higher umbilical venous blood carbon dioxide tension measurements at delivery.\nQuestion: Does early administration of epidural analgesia affect obstetric outcome in nulliparous women who are in spontaneous labor?",
    "gt": "Early administration of epidural analgesia did not prolong labor, increase the incidence of oxytocin augmentation, or increase the incidence of operative delivery, when compared with intravenous nalbuphine followed by late administration of epidural analgesia, in nulliparous women who were in spontaneous labor at term.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Health care-associated infections (HAI) result in 100,000 deaths/year. Alcohol use disorders (AUD) increase the risk of community-acquired infections and HAI. Small studies have shown that AUD increase the risk of HAI and surgical site infections (SSI). We sought to determine the risk of HAI and SSI in surgical patients undergoing elective inpatient joint replacement, coronary artery bypass grafting, laparoscopic cholecystectomy, colectomy, and hernia repair. The Nationwide Inpatient Sample was analyzed (years 2007 and 2008). HAI were defined as health care-associated pneumonia, sepsis, SSI, and urinary tract infection. Primary outcomes were risk of HAI and SSI in patients with AUD. Secondary outcomes were mortality and hospital length of stay in patients with HAI and SSI, alpha = 10(-6). There were 1,275,034 inpatient admissions analyzed; 38,335 (3.0%) cases of HAI were documented, and 5,756 (0.5%) cases of SSI were identified. AUD was diagnosed in 11,640 (0.9%) of cases. Multivariable analysis demonstrated that AUD was an independent predictor of developing HAI: odds ratio (OR) 1.70, p<10(-6), and this risk was independent of type of surgery. By multivariable analysis, the risk of SSI in patients with AUD was also higher: OR 2.73, p<10(-6). Hospital mortality in patients with HAI or SSI was not affected by AUD. However, hospital length of stay was longer in patients with HAI who had AUD (multivariable analysis 2.4 days longer, p<10(-6)). Among patients with SSI, those with AUD did not have longer hospital length of stay.\nQuestion: Health care-associated infections in surgical patients undergoing elective surgery: are alcohol use disorders a risk factor?",
    "gt": "Patients with AUD who undergo a variety of elective operations have an increased risk of infectious postoperative morbidity.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Recently there has been growing interest in how neighbourhood features, such as the provision of local facilities and amenities, influence residents' health and well-being. Prior research has measured amenity provision through subjective measures (surveying residents' perceptions) or objective (GIS mapping of distance) methods. The latter may provide a more accurate measure of physical access, but residents may not use local amenities if they do not perceive them as 'local'. We believe both subjective and objective measures should be explored, and use West Central Scotland data to investigate correspondence between residents' subjective assessments of how well-placed they are for everyday amenities (food stores, primary and secondary schools, libraries, pharmacies, public recreation), and objective GIS-modelled measures, and examine correspondence by various sub-groups. ArcMap was used to map the postal locations of 'Transport, Health and Well-being 2010 Study' respondents (n = 1760), and the six amenities, and the presence/absence of each of them within various straight-line and network buffers around respondents' homes was recorded. SPSS was used to investigate whether objective presence of an amenity within a specified buffer was perceived by a respondent as being well-placed for that amenity. Kappa statistics were used to test agreement between measures for all respondents, and by sex, age, social class, area deprivation, car ownership, dog ownership, walking in the local area, and years lived in current home. In general, there was poor agreement (Kappa<0.20) between perceptions of being well-placed for each facility and objective presence, within 800 m and 1000 m straight-line and network buffers, with the exception of pharmacies (at 1000 m straight-line) (Kappa: 0.21). Results varied between respondent sub-groups, with some showing better agreement than others. Amongst sub-groups, at 800 m straight-line buffers, the highest correspondence between subjective and objective measures was for pharmacies and primary schools, and at 1000 m, for pharmacies, primary schools and libraries. For road network buffers under 1000 m, agreement was generally poor.\nQuestion: Do residents' perceptions of being well-placed and objective presence of local amenities match?",
    "gt": "Respondents did not necessarily regard themselves as well-placed for specific amenities when these amenities were present within specified boundaries around their homes, with some exceptions; the picture is not clear-cut with varying findings between different amenities, buffers, and sub-groups.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Previous studies reporting the impact of osteoarthritis (OA) on pain and function after hip arthroscopy largely predate resection of femoroacetabular impingement (FAI).QUESTIONS/ We determined (1) functional improvement after resection of FAI impingement lesions in patients with preoperative radiographic joint space narrowing, and (2) identified preoperative predictors of pain, function, and failure rates in these patients. Between September 2004 and April 2008, we treated 210 patients (227 hips) with FAI and a minimum 12-month followup (mean, 27 months). Group FAI consisted of 154 patients (169 hips) without radiographic joint space narrowing, whereas Group FAI-OA consisted of 56 patients (58 hips) with preoperative radiographic joint space narrowing. We collected Harris hip scores (HHS), Short Form-12 (SF-12), and pain scores on a visual analog scale (VAS) preoperatively and postoperatively. Score improvements were better for Group FAI compared with Group FAI-OA. The overall failure rate was greater for Group FAI-OA (52%) than for Group FAI (12%). Although patients with less than 50% joint space narrowing or greater than 2 mm joint space remaining on preoperative radiographs had improved scores throughout the study, we observed no score improvements at any time with advanced preoperative joint space narrowing. Greater joint space narrowing, advanced MRI chondral grade, and longer duration of preoperative symptoms predicted lower scores.\nQuestion: Does arthroscopic FAI correction improve function with radiographic arthritis?",
    "gt": "FAI correction with milder degrees of preoperative radiographic joint space narrowing resulted in improvements in pain and function at short-term followup. Patients with advanced radiographic joint space narrowing do not improve and we believe should not be considered for arthroscopic FAI correction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Cardiovascular fitness (VO(2max)) and physical activity are both related to risk of metabolic disease. It is unclear, however, whether the metabolic effects of sedentary living are the same in fit and unfit individuals. The purpose of this study was, therefore, to describe the association between physical activity and the metabolic syndrome and to test whether fitness level modifies this relationship. Physical activity was measured objectively using individually calibrated heart rate against energy expenditure. VO(2max) was predicted from a submaximal exercise stress test. Fat mass and fat-free mass (FFM) were calculated using impedance biometry. A metabolic syndrome score was computed by summing the standardized values for obesity, hypertension, hyperglycemia, insulin resistance, hypertriglyceridemia, and the inverse level of HDL cholesterol and was expressed as a continuously distributed outcome. To correct for exposure measurement error, a random subsample (22% of cohort) re-attended for three repeat measurements in the year following the first assessment. The relationship of VO(2max) (ml O2.kg(FFM)(-1).min(-1)) and the metabolic syndrome score was of borderline significance after adjusting for age, sex, physical activity, and measurement error (beta = -0.58, P = 0.06). The magnitude of the association between physical activity (kJ.d(-1).kg(FFM)(-1)) and the metabolic syndrome was more than three times greater than for VO(2max) (standardized beta = -1.83, P = 0.0042). VO(2max), however, modified the relationship between physical activity energy expenditure and metabolic syndrome (P = 0.036).\nQuestion: Does the association of habitual physical activity with the metabolic syndrome differ by level of cardiorespiratory fitness?",
    "gt": "This study demonstrates a strong inverse association between physical activity and metabolic syndrome, an association that is much steeper in unfit individuals. Thus, prevention of metabolic disease may be most effective in the subset of unfit inactive people.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Increasing evidence suggests a close association between early sexual maturation (SM) and obesity in girls and female adults. Earlier maturing girls are more likely to be obese than nonearly maturers. However, limited research has been conducted in boys. To examine the influence of early SM on fatness in boys and compare it with girls, and to test the hypothesis that the associations differ by gender because of the differences in growth and SM patterns in boys and girls. Cross-sectional study. One thousand five hundred one girls and 1520 boys (aged 8-14 years) who participated in the Third National Health and Nutrition Examination Survey survey (1988-1994) and had complete anthropometry (weight, height, skinfold thickness) and SM data. Based on each individual's age and SM status (Tanner stages: genitalia stages for boys and breast stages for girls), the subjects were classified as: 1) early maturers (those who reached a certain Tanner stage earlier than the median age for that stage), and 2) the others (average and later maturers). Overweight was defined as a body mass index (BMI)>or =85th percentile, and obesity>or =95th percentile. Logistic regression analysis was to test how early maturation affected the risks for overweight and obese. Using multiple linear regression models, the associations between fatness (BMI and skinfold thickness) and SM were systematically examined. Covariates including age, ethnicity, residence, family income, energy intake, and physical activity were adjusted. Early SM was positively associated with overweight and obesity in girls, but the associations were reverse for boys. The prevalence of overweight in early maturers versus the others was 22.6% versus 31.6% in boys and 34.4% versus 23.2% in girls; the figures for obesity were 6.7% versus 14.8% and 15.6% versus 8.1%, respectively. Odd ratios and 95% confidence intervals for obesity were 0.4 (0.2, 0.8) for boys and 2.0 (1.1, 3.5) for girls, and covariates were adjusted. Most significant differences in overweight and obesity among ethnic groups disappeared after controlling for SM. Fatness (BMI and skinfold thickness) was associated with SM stages and with early maturation in boys and girls, but the associations were in opposite directions. Compared with their counterparts, early maturing boys were thinner, whereas early maturing girls were fatter.\nQuestion: Is obesity associated with early sexual maturation?",
    "gt": "Obesity is associated with sexual maturation in both boys and girls, but the association differs. There is positive association in girls, but a negative one in boys. Maturation status should be taken into consideration when assessing child and adolescent obesity.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To identify the antibiotic prescriptions and evaluate their suitability for the infectious conditions treated at a Primary Care Centre. A prospective observation study. La Mina Primary Care Centre. Sant Adrià de Besòs (Barcelona). The on-demand visits of patients over 14 to the General Medicine and Emergency clinics between June 1991 and May 1992 provided the data through a simple multi-stage random sample. On the basis of the clinical notes, these variables were recorded: age, gender, diagnosis, the antibiotic prescribed and its manner of administration. The indication and choice of treatment was assessed in line with previously established criteria, as well as whether the antibiotic was first-choice in Primary Care. Infections treated in hospital or by specialists, non-bacterial cutaneous infections and Conjunctivitis were excluded. Out of 2,523 people examined, 474 presented infectious conditions (18.8%); the most common of these were infections of the upper respiratory tract (46.4%) and acute Bronchitis (17.3%). An antibiotic was prescribed in 206 cases (43.3%). The most used antibiotics were: Amoxicillin (41.5%), Penicillin (19.0%), Cloxacillin (11.2%), Erythromycin (10.2%) and Pipemidic Acid (7.8%). They were orally taken in 89.4% of cases. 92.3% of the antibiotics were first-choice. Overall fitness of treatment was 86.3% (56.5% unnecessary and non-prescribed treatment; and 29.7% necessary and using the recommended antibiotic). The least suitable treatment was observed for cases of acute Bronchitis without any risk factors.\nQuestion: Are antibiotics correctly prescribed in primary care?",
    "gt": "Prescriptions are adjusted to the recommendations on antibiotic policy in Primary Care, although less suitable treatment was observed for acute Bronchitis. The importance of applying a methodology based on objective criteria, in order to make a qualitative analysis in studies on the use of medication, is highlighted.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We hypothesize that oxygen consumption (V̇o2) estimation in patients with respiratory symptoms is inaccurate and can be improved by considering arterial blood gases or spirometric variables. For this retrospective study, we included consecutive subjects who underwent cardiopulmonary exercise testing. Resting V̇o2 was determined using breath-by-breath testing methodology. Using a training cohort (n = 336), we developed 3 models to predict V̇o2. In a validation group (n = 114), we compared our models with 7 available formulae. Our first model (V̇o2 = -184.99 + 189.64 × body surface area [BSA, m(2)] + 1.49 × heart rate [beats/min]+ 51.51 × FIO2 [21% = 0; 30% = 1] + 30.62 × gender [male = 1; female = 0]) showed an R(2) of 0.5. Our second model (V̇o2 = -208.06 + 188.67 × BSA + 1.38 × heart rate + 35.6 × gender + 2.06 × breathing frequency [breaths/min]) showed an R(2) of 0.49. The best R(2) (0.68) was obtained with our last model, which included minute ventilation (V̇o2 = -142.92 + 0.52 × heart rate + 126.84 × BSA + 14.68 × minute ventilation [L]). In the validation cohort, these 3 models performed better than other available equations, but had wide limits of agreement, particularly in older individuals with shorter stature, higher heart rate, and lower maximum voluntary ventilation.\nQuestion: Can we better estimate resting oxygen consumption by incorporating arterial blood gases and spirometric determinations?",
    "gt": "We developed more accurate formulae to predict resting V̇o2 in subjects with respiratory symptoms; however, equations had wide limits of agreement, particularly in certain groups of subjects. Arterial blood gases and spirometric variables did not significantly improve the predictive equations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hepatitis C virus (HCV) has emerged as a major public health problem among injection drug users. In this analysis we examine whether disinfection of syringes with bleach has a potentially protective effect on anti-HCV seroconversion. We conducted a nested case-control study comparing 78 anti-HCV seroconverters with 390 persistently anti-HCV seronegative injection drug users. These data come from the Second Collaborative Injection Drug Users Study, a prospective cohort study that recruited injection drug users from five U.S. cities between 1997 and 1999. We used conditional logistic regression to determine the effect of bleach disinfection of syringes on anti-HCV seroconversion. Participants who reported using bleach all the time had an odds ratio (OR) for anti-HCV seroconversion of 0.35 (95% confidence interval = 0.08-1.62), whereas those reporting bleach use only some of the time had an odds ratio of 0.76 (0.21-2.70), when compared with those reporting no bleach use.\nQuestion: Does bleach disinfection of syringes protect against hepatitis C infection among young adult injection drug users?",
    "gt": "These results suggest that bleach disinfection of syringes, although not a substitute for use of sterile needles or cessation of injection, may help to prevent HCV infection among injection drug users.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A network of Stop Smoking Services has been set up within the National Health Service (NHS) in England. The services deliver a combination of behavioural support and medication. It is important to establish the degree of variability in quit rates attributable to differences between individual practitioners, to gauge the scope for improvement by training and professional support. The aim of the present analysis was to examine how far short-term quit rates depend on the practitioner delivering the intervention after adjusting for potential confounding variables. Observational study using routinely collected data. Thirty-one NHS Stop Smoking Services in England. Data from 46,237 one-to-one treatment episodes (supported quit attempts) delivered by specialist practitioners. Three-level logistic regression models were fitted for carbon monoxide (CO)-validated short-term (4-week) quit rates. Models adjusted for age, gender, exemption from prescription charges, medication and intervention setting for each treatment episode, number of clients for each practitioner and economic deprivation at the level of the Stop Smoking Service. Secondary analyses included (i) the heaviness-of-smoking index (HSI) as predictor and (ii) 4-week quit rates whether or not confirmed by CO. Differences between individual specialist practitioners explained 7.6% of the variance in CO-verified quit rates after adjusting for client demographics, intervention characteristics and practitioner and service variables (P < 0.001). HSI had little impact on this figure; in quits not necessarily validated by CO, practitioners explained less variance.\nQuestion: Does it matter who you see to help you stop smoking?",
    "gt": "Individual stop smoking practitioners appear to differ to a significant degree in effectiveness. It is important to examine what underlies these differences in order to improve selection, training and professional development.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The critical shortage of surgeons and access to surgical care in Africa is increasingly being recognized as a global health crisis. Across Africa, there is only one surgeon for every 250,000 people and only one for every 2.5 million of those living in rural areas. Surgical diseases are responsible for approximately 11.2% of the total global burden of disease. Even as the importance of treating surgical disease is being recognized, surgeons in sub-Saharan Africa are leaving rural areas and their countries altogether to practice in more desirable locations. The Pan-African Academy of Christian Surgeons (PAACS) was formed in 1997 as a strategic response to this profound need for surgical manpower. It is training surgical residents through a 5-year American competency-based model. Trainees are required to be of African origin and a graduate of a recognized medical school. To date, PAACS has established six training programs in four countries. During the 2009-2010 academic year, there were 35 residents in training. A total of 18 general surgeons and one pediatric surgeon have been trained. Two more general surgeons are scheduled to finish training in 2011. Four graduates have gone on to subspecialty training, and the remaining graduates are practicing general surgery in rural and underserved urban centers in Angola, Guinea-Conakry, Ghana, Cameroon, Republic of Congo, Kenya, Ethiopia, and Madagascar.\nQuestion: Is it possible to train surgeons for rural Africa?",
    "gt": "The PAACS has provided rigorous training for 18 African general surgeons, one of whom has also completed pediatric surgery training. To our knowledge, this is the only international rural-based surgical training program in Africa.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A publication on behalf of the European Society of Urological Oncology questioned the need for removing the seminal vesicles during radical prostatectomy in patients with prostate specific antigen less than 10 ng/ml except when biopsy Gleason score is greater than 6 or there are greater than 50% positive biopsy cores. We applied the European Society of Urological Oncology algorithm to an independent data set to determine its predictive value. Data on 1,406 men who underwent radical prostatectomy and seminal vesicle removal between 1998 and 2004 were analyzed. Patients with and without seminal vesicle invasion were classified as positive or negative according to the European Society of Urological Oncology algorithm. Of 90 cases with seminal vesicle invasion 81 (6.4%) were positive for 90% sensitivity, while 656 of 1,316 without seminal vesicle invasion were negative for 50% specificity. The negative predictive value was 98.6%. In decision analytic terms if the loss in health when seminal vesicles are invaded and not completely removed is considered at least 75 times greater than when removing them unnecessarily, the algorithm proposed by the European Society of Urological Oncology should not be used.\nQuestion: Is it necessary to remove the seminal vesicles completely at radical prostatectomy?",
    "gt": "Whether to use the European Society of Urological Oncology algorithm depends not only on its accuracy, but also on the relative clinical consequences of false-positive and false-negative results. Our threshold of 75 is an intermediate value that is difficult to interpret, given uncertainties about the benefit of seminal vesicle sparing and harm associated with untreated seminal vesicle invasion. We recommend more formal decision analysis to determine the clinical value of the European Society of Urological Oncology algorithm.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate donor graft function, intraoperative blood consumption, and oxygenation and hemodynamic stability in patients undergoing lung transplantation. Prospective pilot study. University hospital. Forty-three patients undergoing lung transplantation from January 1999 to June 2001. Hemodynamic monitoring, early extubation, and noninvasive ventilation criteria. The 31 nonearly extubated patients showed a lower PaO(2)/fraction of inspired oxygen (F(I)O(2)), a higher mean pulmonary arterial pressure, extravascular lung-water index (EVLWI) and vasoactive drug support (norepinephrine), and more blood products consumption than 12 early extubated patients at the end of surgery. Seven of 12 early extubated patients did not show any signs of respiratory failure after tracheal extubation; they were alert and able to perform deep breathing exercise and coughing. In the other 5 patients, hypoxemia, hypercapnia, and an increase of respiratory rate>30 breaths/min were observed. The intermittent application of noninvasive pressure ventilation by face mask avoided endotracheal intubation.\nQuestion: Is very early extubation after lung transplantation feasible?",
    "gt": "The use of a short-acting anesthetic drug, appropriate intraoperative extubation criteria, epidural analgesia, and postoperative noninvasive ventilation make early extubation of lung-transplanted patients possible and effective.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: If glucose transport proteins (Glut) are elevated in tumors they may be good targets for tumor imaging. For targeting, the overexpression of Glut should be a general characteristic of tumors. Moreover agents which bind to Glut should accumulate selectively in tumors. To test this, we quantitated Glut in isolated membranes from three human tumor xenografts, two murine tumor models and normal murine tissues using direct binding studies. Additionally, the biodistribution of two compounds which bind to Glut, 7-[[(2-(3-(125I-p-hydroxyphenyl)propionyl)aminoethyl)amino]carbonyl]-7-+ ++desacetyl-forskolin([125I]HPP forskolin) and [3H]cytochalasin B, were studied in a tumor model which overexpressed Glut. There were multiple classes of binding sites for [3H]cytochalasin B and a percentage of these sites were competitive with D-glucose but not L-glucose. The rank potency and IC50 values for [3H]cytochalasin B binding were: 2-deoxy-D-glucose (4.5 mM)>or = D-glucose (7 mM)>mannose (25 mM)>galactose (35 mM)>rhamnose (1-3 mM)>sorbitol (1-3 mM) and were similar to reported values for transport. The average density of Glut in four tumor models and normal tissues was between 0.7 and 4 pmole/mg protein, but Kd values were not significantly different (69 nM). In LX-1 human lung tumor xenograft (LX-1) Glut were 10-to-20-fold higher than other tissues (21.6 +/- 0.6 pmole/mg protein, p<0.01). Immunostaining of Glut-1 was more prominent in LX-1 than other xenograft tumors, consistent with the binding data. Glut density was highest in poorly vascularized regions suggesting that Glut upregulation was related to a biofeedback mediated event. Iodine-125 HPP-forskolin and [3H]cytochalasin B did not localize in LX-1 tumors.\nQuestion: Targeting of glucose transport proteins for tumor imaging: is it feasible?",
    "gt": "Glut overexpression was not a common characteristic of the five tumors tested. Iodine-125 HPP-forskolin and [3H]cytochalasin B did not localize in LX-1 tumors, indicating that these agents did not target tumors with upregulated Glut. Results suggest that Glut are not a promising target for tumor imaging.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Recently, a number of studies have reported positive results from the nonoperative management of fistula-in-ano in infancy, although it has not been of use in all patients. The purpose of this study was to discern the effective treatment methods of fistula-in-ano in infants. A retrospective review was done of 310 children who required operative management for fistula-in-ano or perianal abscess between January 1991 and July 2000. Eighteen patients displayed an onset of symptoms at less than 1 year of age and a duration of symptoms longer than 12 months. The authors analyzed these patients' medical records. All patients were boys. The mean duration of the symptoms was 26.6 +/- 27.5 months. Fourteen patients had shown an onset of symptoms at less than 6 months of age. The longest duration was 10 years. The patients showed conservative periods of over 12 months because their parents did not want them to undergo surgery. The disease in these patients followed 2 patterns. One (6 patients) was an onset of symptoms followed by a silent fistula-in-ano state. The other (12 patients) was an onset of symptoms followed by an intermittent relapse of inflammation. All patients underwent fistulotomy, and none of them had recurrent fistula during the follow-up period.\nQuestion: Fistula-in-ano in infants: is nonoperative management effective?",
    "gt": "Although the advantages of a nonoperative management of fistula-in-ano in infants include the avoidance of general anesthesia and surgical intervention, the lesions cannot be cured by a period of conservation. Surgical management is more effective in respect to the time factor.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The evaluation of surgical risk is crucial in elderly patients. At present, there is little evidence of the usefulness of comprehensive geriatric assessment (CGA) as a part of the overall assessment of surgical elderly patients. We verified whether CGA associated with established surgical risk assessment tools is able to improve the prediction of postoperative morbidity and mortality in 377 elderly patients undergoing elective surgery. Overall mortality and morbidity were 2.4% and 19.9%, respectively. Multivariate analysis showed that impaired cognitive function (odds ratio [OR], 1.33; 95% confidence interval [CI], 1.15 to 4.22; P<.02) and higher Physiological and Operative Severity Score for the Enumeration of Mortality and Morbidity (OR, 1.11; 95% CI, 1.00 to 1.23; P<.04) are predictive of mortality. Higher comorbidity is predictive of morbidity (OR, 2.12; 95% CI, 1.06 to 4.22; P<.03) and higher American Society of Anesthesiologists (OR, 2.18; 95% CI, 1.31 to 3.63; P<.001) and National Confidential Enquiry into Patient Outcome of Death score (OR, 2.03; 95% CI, 1.03 to 4.00; P<.04).\nQuestion: Does comprehensive geriatric assessment improve the estimate of surgical risk in elderly patients?",
    "gt": "In elective surgical elderly patients, the morbidity and mortality are low. The use of CGA improves the identification of elderly patients at higher risk of adverse events, independent of the surgical prognostic indices.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The present study examines whether there is an association between anemia during the first trimester and the risk to develop preterm delivery (PTD), intrauterine growth restriction, and other obstetrical complications. The study population included all registered births between 2000 and 2010. Anemia was defined as hemoglobin<10 g/dl. A comparison of obstetrical characteristics and perinatal outcomes was performed between women with and without anemia. Multiple logistic regression models were used to control for confounders. The study population included 33,888 deliveries, of these 5.1% (1718) were with anemia during the first trimester. Women with anemia were significantly older, delivered earlier, and were more likely to be grand multiparous. There were significantly higher rates of PTD and low birth weight (LBW;<2500 g) among patients with anemia (12.3% vs. 9.3%; p<0.001 and 11.7% vs. 9.0%; p<0.001, respectively). On the contrary, no significant differences between the groups were noted regarding the rate of intrauterine growth restriction. Using a multivariable analysis, the significant association between anemia and PTD persisted (OR = 1.35; 95% CI 1.2-1.6, p<0.01).\nQuestion: Can anemia in the first trimester predict obstetrical complications later in pregnancy?",
    "gt": "Anemia during the first trimester is significantly and independently associated with an increased risk for subsequent PTD.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Post-operative diaphragmatic hernias (PODHs) are serious complications following esophagectomy or total gastrectomy. The aim of this study was to describe and compare the incidence of PODHs at a high volume center over time and analyze the outcomes of patients who develop a PODH. A prospective database of all resectional esophagogastric operations performed for cancer between January 2001 and December 2015 was analyzed. Patients diagnosed with PODH were identified and data extracted regarding demographics, details of initial resection, pathology, PODH symptoms, diagnosis and treatment. Out of 631 patients who had hiatal dissection for malignancy, 35 patients developed of PODH (5.5 % overall incidence). Median age was 66 (range 23-87) years. The incidence of PODH in each operation type was: 2 % (4/221) following an open 2 or 3 stage esophagectomy, 10 % (22/212) following laparoscopic hybrid esophagectomy, 7 % (5/73) following MIO, and 3 % (4/125) following total gastrectomy. The majority of patients had colon or small bowel in a left-sided hernia. Of the 35 patients who developed a PODH, 20 (57 %) patients required emergency surgery, whereas 15 (43 %) had non-urgent repair. The majority of the patients had had suture repair (n = 24) or mesh repair (n = 7) of the diaphragmatic defect. Four patients were treated non-operatively. In hospital post-operative mortality was 20 % (4/20) in the emergency group and 0 % (0/15) in the elective group. Further hernia recurrence affected seven patients (n = 7/27, 26 %) and 4 of these patients (15 %) presented with multiple recurrences.\nQuestion: Diaphragmatic herniation following esophagogastric resectional surgery: an increasing problem with minimally invasive techniques?",
    "gt": "PODH is a common complication following hybrid esophagectomy and MIO. Given the high mortality from emergency repair, careful thought is needed to identify surgical techniques to prevent PODH forming when minimal access esophagectomy are performed. Upper GI surgeons need to have a low index of suspicion to investigate and treat patients for this complication.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It has never been investigated whether first depression differs in patients who have experienced bereavement compared to patients who have not. Patients discharged with a diagnosis of a single depressive episode from a psychiatric in- or outpatient hospital setting were consecutively sampled from the Danish Psychiatric Central Research Register. Patients participated in an extensive interview including the Schedules for Clinical Assessment in Neuropsychiatry (SCAN) and the Interview of Recent Life Events (IRLE). Among 301 patients with a first depression, 26 patients (4.7%) had experienced death of a first degree relative (parent, sibling, child) or a near friend, 163 patients (54.2%) had experienced other moderate to severe stressful life events and 112 patients had not experienced stressful life events in a 6 months period prior to the onset of depression. Patients who had experienced bereavement did not differ from patients with other stressful life events or from patients without stressful life events in socio-demographic variables or in the phenomenology of the depression, psychiatric comorbidity, family history or response to antidepressant treatment.\nQuestion: Does bereavement-related first episode depression differ from other kinds of first depressions?",
    "gt": "Bereavement-related first episode depression does not differ from other kinds of first depression.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The therapy for native mitral valve endocarditis is in evolution. Antibiotics have significantly improved survival rates, but patients with complications of endocarditis may require surgical treatment. Between January 1985 and December 1995, 146 patients underwent surgical therapy (repair or replacement) for native mitral valve endocarditis. All patients had documented bacterial endocarditis. Univariate and multivariate analyses were performed to determine predictors of hospital death, long-term event-free survival, and probability of repair. Patients were evaluated in three groups: all patients, patients with acute endocarditis, and patients with chronic endocarditis. There were ten hospital deaths (6.8%). Patients undergoing repair had a lower hospital mortality rate (p = 0.008) then those having replacement. Event-free survival was improved after mitral valve repair in the overall group (p = 0.02) and in the group with healed (chronic) endocarditis (p = 0.05). Although the acute endocarditis group demonstrated an improved event-free survival rate after mitral valve repair versus replacement (74% versus 20% at 6 years), this did not reach statistical significance.\nQuestion: Is there an advantage to repairing infected mitral valves?",
    "gt": "We conclude that mitral valve repair is preferable to mitral valve replacement when possible, in patients with complications of endocarditis, as repair results in a lower hospital mortality and an improved long-term survival.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Helicobacter pylori (HP) infection can recur even after eradication by triple therapy. We hypothesize that maintenance acid suppression treatment after standard eradication therapy would be necessary to further reduce ulcer recurrence in Jordanian population. This is a retrospective study that was conducted at King Abdullah University Hospital (KAUH), a major University hospital, and tertiary care facility (>400 beds) located in North Jordan. Endoscopic and histologic results and medication history were reviewed for each patient who has prescribed eradication therapy for HP over the period from July 2003 until May 2006. Maintenance acid suppression treatment after standard eradication therapy markedly reduced the recurrence rate of peptic ulcer from 58.3% (with out maintenance acid suppression treatment) to 1.45% (with maintenance acid suppression treatment).\nQuestion: Is maintenance acid suppression necessary to reduce the rate of reinfection with Helicobacter pylori?",
    "gt": "Our results indicate that treatment of HP infection by eradication regimen (triple therapy only) is not enough to prevent recurrence of ulcer in the Jordanian population. Thus, we recommend maintenance acid suppression following standard H. pylori eradication regimen to maintain remission.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The most appropriate approach to the repair of large paraesophageal hernias remains controversial. Despite early results of excellent outcomes after laparoscopic repair, recent reports of high recurrence require that this approach be reevaluated. For this study, 60 primary paraesophageal hernias consecutively repaired at one institution from 1990 to 2002 were reviewed. These 25 open transabdominal and 35 laparoscopic repairs were compared for operative, short-, and long-term outcomes on the basis of quality-of -life questionnaires and radiographs. No difference in patient characteristics was detected. Laparoscopic repair resulted in lower blood loss, fewer intraoperative complications, and a shorter length of hospital stay. No difference in general or disease-specific quality-of-life was documented. Radiographic follow-up was available for 78% open and 91% laparoscopic repairs, showing anatomic recurrence rates of 44% and 23%, respectively (p = 0.11).\nQuestion: Should laparoscopic paraesophageal hernia repair be abandoned in favor of the open approach?",
    "gt": "Laparoscopic repair should remain in the forefront for the management of paraesophageal hernias. However, there is considerable room for improvement in reducing the incidence of recurrence.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The authors determined the usefulness of frozen section (FS) evaluation in the operative management of follicular lesions of the thyroid. Fine-needle aspiration (FNA) cannot reliably discriminate between benign and malignant follicular lesions of the thyroid. Accordingly, FS evaluation is used routinely to guide intraoperative management. One hundred twenty-five consecutive patients with follicular thyroid lesions who underwent surgical exploration at the Johns Hopkins Hospital were reviewed. Frozen sections were categorized in 104 of 120 patients (87%) as \"follicular lesion, defer to permanent section,\" rendering no useful clinical information. In only 4 of 120 patients (3.3%) did FS evaluation correctly modify the operative procedure. Notably, in six cases (5.0%), an incorrect FS evaluation misled the surgeon, resulting in four misguided operations.\nQuestion: Follicular lesions of the thyroid. Does frozen section evaluation alter operative management?",
    "gt": "Frozen section evaluation is of minimal diagnostic value for follicular thyroid lesions, rendering no additional information 87% of the time; it prolongs the operation, increases costs, and leads to misguided interventions. Until a more definitive diagnostic tool exists for follicular thyroid lesions, FS evaluation could be omitted, resection of the lobe with the nodule could be performed, and the definitive operative management could be based on the final permanent histology.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is a lack of evidence regarding the role of drainage in laparoscopic cholecystectomy (LC) for acutely inflamed gallbladder (AIGB), and drain insertion remains controversial. From December 2013 to November 2014, a total of 193 patients who needed LC due to AIGB at the four participating hospitals were entered in this study. After the operation, the patients were randomly assigned to undergo drain insertion (94 patients, 48.7%, group A) or not (99 patients, 51.3%, group B). The surgical outcomes between the two groups were prospectively reviewed. The study was registered at www.clinicaltrials.gov at the inception of enrollment (NCT02027402). Both groups were comparable in terms of patient demographics, operative time and postoperative hospital stay. In 18 cases (9.3%), postoperative morbidities such as bleeding, bile leakage, wound infection or an abscess occurred, and there was no significant difference between the two groups. The visual analog scale pain score measured at 24 h (3.9 ± 1.4 in group A and 3.3 ± 2.0 in group B, P = 0.014) and 48 h (2.1 ± 1.5 in group A and 1.5 ± 1.4 in group B, P = 0.006) was significantly higher in group A.\nQuestion: Is routine drain insertion after laparoscopic cholecystectomy for acute cholecystitis beneficial?",
    "gt": "Routine drain insertion does not prevent or reduce postoperative morbidities after LC for AIGB and can even cause prolonged postoperative pain. This prospective study suggests that routine drain use in LC for AIGB should be reconsidered.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To correlate the periodontal status of 15 patients with primary Sjögren's syndrome (SS) with their salivary levels of BAFF. The periodontal status of 15 patients who fulfilled the criteria for primary SS was compared with that of 15 controls with xerostomia who did not fulfill the criteria for primary SS but had similar symptoms of dry mouth. The level of BAFF was measured in paired samples of saliva and serum using in-house enzyme-linked immunosorbent assays. Periodontitis was assessed by the plaque index, the modified gingival index, the papillary bleeding index, and the periodontal pocket depth. Notwithstanding the better oral hygiene practices of the patients with primary SS compared with those of the xerostomia controls and the subsequent reduction of their plaque index scores, complications of periodontitis, such as bleeding, gingival hypertrophy, and periodontal pockets, were not improved. This failure to ameliorate the complications of periodontitis in patients with primary SS was associated with high levels of BAFF in their saliva compared with the levels in xerostomia controls (7.4 +/- 2.1 versus 1.0 +/- 0.4 ng/ml [P<0.002]). The levels of BAFF in saliva did not correlate with the levels in sera but did correlate with the periodontal pocket depth (P<0.002).\nQuestion: Is periodontal disease mediated by salivary BAFF in Sjögren's syndrome?",
    "gt": "These findings are similar to the bone resorption observed in patients with rheumatoid arthritis. They suggest that the known effect of B cells in periodontitis would be partly mediated by salivary BAFF in patients with primary SS.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This paper provides evidence of environmental iodine deficiency in the Gippsland region. Quantitative study; water samples were collected from 18 water treatment plants and four rain water tanks across Gippsland and water iodine concentrations were measured. Gippsland region of Victoria, Australia. This paper reports on the iodine concentration of drinking water from sources across Gippsland and examines the contribution of iodine from water to the Gippsland diet. This study also briefly examines the relationship between the concentration of iodine in water and distance from the sea. The cut-off value for water iodine concentrations considered to be indicative of environmental iodine deficiency is<2 µg L(-1) . The mean iodine concentration of water from 18 Gippsland water treatment plants was 0.38 µg L(-1) and would therefore make negligible difference to the dietary intake of iodine. This finding also falls well below the suggested dietary intake of iodine from water estimated by the 22nd Australian Total Diet Study. Our study found no linear relationship between the water iodine concentration and distance from the sea.\nQuestion: Is Gippsland environmentally iodine deficient?",
    "gt": "As Gippsland has environmental iodine deficiency there is a greater probability that people living in this region are at higher risk of dietary iodine deficiency than those living in environmentally iodine sufficient regions. Populations living in areas known to have environmental iodine deficiency should be monitored regularly to ensure that problems of iodine deficiency, especially amongst the most vulnerable, are addressed promptly.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess the influence of the surgical removal of partially impacted third molars (3Ms) and compare the effects of a 3-cornered laterally rotated flap (LRF) with primary closure (flap 1) and an envelope flap with secondary closure (flap 2) on the short-term periodontal status of the adjacent second molars (2Ms). We also assessed the postoperative complications after removal of the partially impacted 3M. A split mouth, randomized clinical study was designed. The study sample included patients with bilateral partially impacted 3Ms. The primary predictor variable was the type of flap design (flaps 1 and 2). The primary outcome variable was periodontal status (gingival recession [GR], probing depth [PD], plaque index [PI], and gingival index) of the 2Ms measured preoperatively and 90 days postoperatively. The secondary outcome variables were postoperative complications, including pain, facial swelling, alveolitis, and local wound infection. The other variables included gender, position of the 3Ms, and surgical difficulty. We performed descriptive, comparative, correlation, and multivariate analyses. The sample included 28 patients aged 18 to 28 years. The GR, PD, and PI values with the flap 2 design were greater than those with the flap 1 design (P<.05). Facial swelling with the flap 1 design was significantly greater than with the flap 2 design on the second postoperative day (P<.05). The pain levels with the flap 1 design were significantly greater than those with the flap 2 design on the first and second postoperative days (P<.05). According to the multivariate regression analyses, flap design was closely related to the periodontal status of the 2Ms and postoperative discomfort.\nQuestion: Does laterally rotated flap design influence the short-term periodontal status of second molars and postoperative discomfort after partially impacted third molar surgery?",
    "gt": "The results of the present clinical study have shown that the flap design in partially impacted 3M surgery considerably influences the early periodontal health of the 2Ms and postoperative discomfort. However, although the 3-cornered LRF design might cause more pain and swelling, it could be the method of choice for partially impacted 3M surgery because of the early periodontal healing.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The treatment of personality disorder is repeatedly reported as less successful than the treatment of patients without personality disorder. Most clinicians believe that anxiety disorder in tandem with a personality disorder often leads to longer treatment, worsens the prognosis, and thus increases treatment costs. Our study was designed to compare the short-term effectiveness of therapy in patients suffering from social phobia with and without personality disorder. The specific aim of the study was to assess the efficacy of a 6 week therapeutic program designed for social phobia (SSRIs and CBT) in patients suffering from social phobia with comorbid personality disorder (17 patients) and social phobia without comorbid personality disorder (18 patients). The patients were regularly assessed in weeks 0, 2, 4 and 6 using the CGI (Clinical Global Improvement) for severity, LSAS (Liebowitz Social Anxiety Scale), and in self-assessments BAI (Beck Anxiety Inventory) and BDI (Beck Depression Inventory). Patients in both groups improved their scores in most of the assessment instruments used. A combination of CBT and pharmacotherapy proved to be the most effective treatment for patients suffering with social phobia with or without comorbid personality disorder. Treatment efficacy in patients with social phobia without personality disorder was significantly better than in the group with social phobia comorbid with personality disorder for CGI and specific inventory for social phobia - LSAS. The scores on the subjective depression inventory (BDI) also showed significantly greater decrease over the treatment in the group without personality disorder. The treatment effect between groups did not differ in subjective general anxiety scales BAI.\nQuestion: Is there any influence of personality disorder on the short term intensive group cognitive behavioral therapy of social phobia?",
    "gt": "Our study showed that patients suffering from social phobia and comorbid personality disorder showed a smaller decrease in specific social phobia symptomatology during treatment compared than patients with social phobia without personality disorders. However, a significant decrease in symptomatology occurred in personality disorder patients as well.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We compared the results from a video-assisted thoracoscopic sympathectomy (VTS) at the T4 denervation level with those from a VTS at the T3 level for the treatment of palmar hyperhydrosis (PH). Seventy patients with PH were prospectively followed for VTS at the T3 or T4 denervation levels for 6 months. The end points of this study were: absence of PH, compensatory hyperhydrosis (CH), and quality-of-life assessment. Sixty-seven patients reported a complete resolution of PH after surgery. One failure occurred in the T3 group and 2 in the T4 group. When anhydrosis was obtained, we noticed totally dry hands in 26 patients in the T3 group and 6 patients in the T4 group. The other 27 patients in the T4 group and 8 in the T3 group maintained a small level of sweating and were also considered to be therapeutic successes. At 6 months, 25 patients in the T4 group had some degree of CH (71.42%) and all patients in the T3 group (100%), though the T4 group had a lower degree of severity of CH at the 6-month follow-up (P<0.05). After the operation, quality of life was improved similarly in both groups.\nQuestion: Is sympathectomy at T4 level better than at T3 level for treating palmar hyperhidrosis?",
    "gt": "VTS at either the T3 or T4 level provides an effective treatment for PH. VTS at the T4 level is associated with a less severe form of CH. Despite the occurrence of CH, patients' quality of life is significantly improved following VTS at the T3 or T4 levels. For this reason, the T4 resection can now be used as a treatment for PH.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Few Australian studies describe the epidemiology of penetrating trauma. This study describes the incidence and demographic features of penetrating injuries with emphasis on trends and severity analysis. Case analysis was performed utilizing data from the Liverpool Hospital Trauma Registry (1989-94), NSW Department of Health Hospital Separations (1991-93), and the NSW Bureau of Crime Statistics (1991-93) with reference to the Liverpool and Fairfield Local Government Areas (LGA). The Trauma Registry revealed 251 of penetrating trauma. The median age was 26 years (interquartile range 21-33). Ninety-one per cent of the victims were male. Fourteen per cent of patients had an Injury Severity Score (ISS)>15. Sixty-five per cent of cases were stab injuries and 20% gunshot injuries with the abdomen being the most commonly injured site. Twenty-one per cent of patients underwent laparotomy, 1.6% thoracotomy and 1.2% thoracotomy and laparatomy. There were 10 (4%) deaths. Trends in incidence of penetrating trauma and violent crime involving weapons were analysed. Static trends were observed for the annual incidence of penetrating trauma from the Liverpool Hospital Trauma Registry. Separations for penetrating trauma from Liverpool and Fairfield hospitals showed a slightly increasing trend. Violent crimes involving weapons in the Liverpool and Fairfield LGA showed a static trend. Nevertheless, separations for penetrating trauma and rates of violent crimes involving weapons were higher in south-western Sydney than metropolitan Sydney or NSW. Eight per cent of the LGA population are Vietnamese but this study identified 16% of victims as being Vietnamese.\nQuestion: Is penetrating injury on the increase in south-western Sydney?",
    "gt": "This study found no significant increase in penetrating trauma or violent crime predisposing to penetrating injury in south-western Sydney.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patients with prostate cancer with a pre-operative prostate-specific antigen (PSA)>15 ng/ml who undergo radical retropubic prostatectomy (RRP) generally do not have a good outcome, yet may have organ-confined cancer and should be offered the option of surgery.AIM: To assess the outcome of patients who underwent RRP with a pre-operative PSA>15 ng/ml. Thirty-four patients, mean pre-operative PSA: 25.46 ng/ml (15.03-76.6) and mean Gleason score: 6.4 (5-9) were assessed. Two groups were identified. Group I: 41% (14/34) have no biochemical recurrence to mean follow up of 58 months (30-106). Mean PSA: 18.8 ng/ml (15.03-25.84). Mean Gleason score: 6.1 (5-7). Clinical stage: T1c in 80%. No patient had seminal vesicle or lymph node involvement. Group II: 59% (20/34) have biochemical recurrence or died (3) from their disease to mean follow up of 66 months (36-98). Mean PSA: 28.9 ng/ml (15.28-76.6). Mean Gleason score: 6.7 (5-9). Clinical stage: T1c in 25%. Eleven patients had seminal vesicle (8) involvement or positive lymph nodes (3) or both (2).\nQuestion: Should patients with a pre-operative prostate-specific antigen greater than 15 ng/ml be offered radical prostatectomy?",
    "gt": "RRP seems feasible in patients whose pre-operative PSA is between 15 and 25 ng/ml with stage T1c, Gleason score<or = 7 and negative lymph node frozen section.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine the significant differences in smoking, drug and alcohol use between adolescent boys and girls, and to raise the possible need to design and implement prevention programs from a gender perspective. A qualitative study using eight discussion groups of adolescents aged 14-18 years (n=56) and 6 semi-structured interviews with experts and professionals in drug prevention in the Community of Madrid. Categorical interpretive analysis was performed. The adolescents and prevention professional indicated differences between boys and girls in drug and alcohol use. The significances, reasons associated with the consumption and the patterns of consumption were perceived differently by each sex. To lose weight, calm down or an image of rebelliousness was related to girls who smoked, while boys smoked less because they did more sports. The perception of certain precocity of drug consumption was associated with the step from school to Higher Education Institutions. They found smoking associated with a good social image among their groups. Adolescents showed the ineffectiveness of the campaigns and prevention messages they received, incoherence of adults between messages and actions, and the attraction of all behaviours that are banned. Professionals observed the need to include a gender perspective in prevention programs, but did not know how to achieve it, mainly because it has been translated into different activities for each sex until now.\nQuestion: Is a gender differential intervention necessary in the prevention of adolescent drug use?",
    "gt": "The significant differences associated with smoking, drug and alcohol use observed in the adolescents should lead us to design and implement prevention programs that incorporate a gender perspective. It is perhaps from this strategy where drug and alcohol use among girls can be reduced.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Size can predict malignancy in adrenocortical tumors, but the same extrapolation for pheochromocytomas (PCC) is controversial. The goal of this study was to find a correlation between the tumor size and malignant potential of PCC and determine whether the \"Pheochromocytoma of the adrenal gland scaled score\" (PASS) proposed by Thompson can be applied to predict malignancy. A retrospective analysis of patients with PCC operated on from 1991 to 2007 revealed 98 PCC removed from 93 patients. Tumor size was available for 90 tumors. Six (6.4%) patients had proven malignancy. Five familial cases were excluded from the PASS analysis. Of the benign cases, none developed recurrence or metastasis. There were 54 (60%) tumors > 6 cm and 36 (40%) tumors ≤ 6 cm. All 12 PASS parameters were individually present in higher frequency in the>6-cm group; but the difference was not statistically significant except cellular monotony (p = 0.02). Overall, a PASS ≤ 4 was found in 57 patients. Mean PASS was statistically significantly higher in the>6-cm group (4.4 vs. 3.3, p = 0.04). Of the sporadic benign cases, 21 (41%) patients with tumor size > 6 cm had a PASS of>4, and none of them developed metastasis. PASS ≤ 4 was found in 25 (81%) PCC in the ≤6-cm group, and none developed metastases. PASS ≥ 4 was found in six (19%) patients in the ≤6-cm group, and none developed metastases. 68 patients completed 5-year follow-up, and the remaining had a mean follow-up of 28.7 months. No correlation was found between tumor size and PASS > 4 and PASS ≤ 4 (7.8 cm vs. 7.1 cm; p = 0.23).\nQuestion: Size of the tumor and pheochromocytoma of the adrenal gland scaled score (PASS): can they predict malignancy?",
    "gt": "Presently there is not enough evidence to indict a large (>6 cm) PCC as malignant. Furthermore, PASS cannot be reliably applied to PCC for predicting malignancy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Follicular fluid was collected from 58 patients undergoing oocyte retrieval for IVF. Ovulation was induced with GnRH analogues and gonadotropins. Follicular fluids of mature follicles (>17 mm) were aspirated and pooled for each patient. Follicular fluid steroid hormone levels (E2, P) and VEGF, inhibin A, inhibin B concentrations were studied. The serum levels of E2, P and VEGF were also assessed on the day of the oocyte retrieval. These parameters and characteristics of the cycles were compared between the pregnant (group 1) and non pregnant (group 2) patients. The serum and FF VEGF levels were found to be significantly lower in the group in whom the pregnancy was achieved (P<0.001). The FF inhibin A and FF inhibin B were found to be significantly higher in pregnant group (P<0.001). However, age, day 3 FSH, dosage of gonadotropin administered, fertilization rate, sperm count, motile and morphologically normal sperm percentage were not significantly different in the two groups. There was an negative correlation between VEGF and number of follicles, number of oocytes, FF inhibin A, FF inhibin B. The number of oocytes retrieved, the fertilization rate were positively correlated with FF inhibin B and FF inhibin A.\nQuestion: Follicular fluid concentrations of vascular endothelial growth factor, inhibin A and inhibin B in IVF cycles: are they markers for ovarian response and pregnancy outcome?",
    "gt": "This study demonstrated that decreased FF VEGF, serum VEGF and elevated FF inhibin A and B are associated with better ovarian response and high pregnancy rate.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Studies show that stroke survivors typically have lower life satisfaction than persons who have not been diagnosed with stroke. To determine if significant differences in life satisfaction exist between stroke survivors with and without functional limitations and whether specific functional limitations, as well as participation in outpatient rehabilitation affect the odds of reported life satisfaction for stroke survivors. Chi square analysis was used to examine data from the 2013 BRFSS to determine the relationship of functional limitations as well as participation in rehabilitation services to life satisfaction for stroke survivors. Logistic regression analysis was used to determine what variables increased the odds of reported poor life satisfaction. Stroke survivors experiencing difficulty with cognition, depression and IADLs showed significantly lower life satisfaction than those who did not experience these functional limitations. Survivors exhibiting activity limitations had almost twice the odds of reporting poor life satisfaction and those experiencing limitations in cognition and IADLs had 2.88 times and 1.81 times the odds as others without these limitations of reporting poor life satisfaction, respectively. Participation in outpatient rehabilitation reduced the odds of reporting of poor life satisfaction by approximately one half.\nQuestion: Does type of disability and participation in rehabilitation affect satisfaction of stroke survivors?",
    "gt": "Rehabilitation focused on addressing these functional limitations would increase life satisfaction for persons diagnosed with stroke. Future research on specific types of cognitive and daily living limitations would assist policy makers and referral sources in making appropriate referrals to rehabilitation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patients' preferences for cardiopulmonary resuscitation (CPR) relate to their perception about the likelihood of success of the procedure. There is evidence that the lay public largely base their perceptions about CPR on their experience of the portrayal of CPR in the media. The medical profession has generally been critical of the portrayal of CPR on medical drama programmes although there is no recent evidence to support such views. To compare the patient characteristics, cause and success rates of cardiopulmonary resuscitation (CPR) on medical television drama with published resuscitation statistics. Observational study. 88 episodes of television medical drama were reviewed (26 episodes of Casualty, Casualty, 25 episodes of Holby City, 23 episodes of Grey's Anatomy and 14 episodes of ER) screened between July 2008 and April 2009. The patient's age and sex, medical history, presumed cause of arrest, use of CPR and immediate and long term survival rate were recorded. Immediate survival and survival to discharge following CPR. There were a total of 76 cardio-respiratory arrests and 70 resuscitation attempts in the episodes reviewed. The immediate success rate (46%) did not differ significantly from published real life figures (p=0.48). The resuscitation process appeared to follow current guidelines. Survival (or not) to discharge was rarely shown. The average age of patients was 36 years and contrary to reality there was not an age related difference in likely success of CPR in patients less than 65 compared with those 65 and over (p=0.72). The most common cause of cardiac arrest was trauma with only a minor proportion of arrests due to cardio-respiratory causes such as myocardial infarction.\nQuestion: Resuscitation on television: realistic or ridiculous?",
    "gt": "Whilst the immediate success rate of CPR in medical television drama does not significantly differ from reality the lack of depiction of poorer medium to long term outcomes may give a falsely high expectation to the lay public. Equally the lay public may perceive that the incidence and likely success of CPR is equal across all age groups.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate differences in second-, third-, and fourth-year medical students' knowledge of bloodborne pathogen exposure risks, as well as their attitudes toward, and intentions to comply with, Universal Precautions (UP). Cross-sectional survey. Surveys about students' knowledge, attitudes, and intentions to comply with UP were completed by 111 second-year (preclinical), 80 third-year, and 60 fourth-year medical students at Washington University School of Medicine in the spring of 1996. Preclinical students knew more than clinical students about the efficacy of hepatitis B vaccine, use of antiretroviral therapy after occupational exposure to human immunodeficiency virus, and nonvaccinated healthcare workers' risk of infection from needlestick injuries (P<.001). Students' perceived risk of occupational exposure to bloodborne pathogens and attitudes toward hepatitis B vaccine did not differ, but preclinical students agreed more strongly that they should double glove for all invasive procedures with sharps (P<.001). Clinical students agreed more strongly with reporting only high-risk needlestick injuries (P=.057) and with rationalizations against using UP (P=.008). Preclinical students more frequently reported contemplating or preparing to comply with double gloving, wearing protective eyewear, reporting all exposures, and safely disposing of sharps, whereas students with clinical experience were more likely to report compliance. Clinical students also were more likely to report having \"no plans\" to practice the first three of these precautions (P<.001).\nQuestion: Does clinical experience affect medical students' knowledge, attitudes, and compliance with universal precautions?",
    "gt": "Differences in knowledge, attitudes, and intentions to comply with UP between students with and without clinical experience may have important implications for the timing and content of interventions designed to improve compliance with UP.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The optimal medical or surgical therapy and outcome of enterococcal prosthetic joint infection are unknown. We performed a retrospective cohort study involving all patients with enterococcal total hip or knee arthroplasty infection treated at our institution from 1969 through 1999. The outcome for patients treated with combination systemic antimicrobial therapy (a cell wall-active agent and an aminoglycoside) versus monotherapy with a cell wall-active agent was analyzed. Fifty episodes of prosthetic joint infection due to enterococci occurred in 47 patients. The median duration of follow-up was 1253 days (range, 29-4610 days). The median age at the time of diagnosis was 70 years (range, 32-89 years). Fifty percent of episodes (25 of 50 episodes) occurred in male patients; 48% (24 of 50 episodes) involved total hip or knee arthroplasty. The estimate of 2-year survival free of treatment failure was 94% (95% confidence interval [CI], 83%-100%) for patients treated with 2-stage exchange, 76% (95% CI, 58%-100%) for patients treated with resection arthroplasty, and 80% (95% CI, 51.6%-100%) for patients treated with debridement and retention of the components (P=.9). The overall rate of 2-year survival free of treatment failure was 88% (95% CI, 77%-100%) for patients treated with monotherapy and 72% (95% CI, 54%-96%) for patients treated with combination therapy (P=.1). The development of cranial nerve VIII toxicity was significantly more common among patients receiving combination therapy (P=.002). Nephrotoxicity was more frequent in the combination therapy group (occurring in 26% of episodes; P=.09).\nQuestion: Outcome of enterococcal prosthetic joint infection: is combination systemic therapy superior to monotherapy?",
    "gt": "Enterococcal prosthetic joint infection is uncommon at our institution. Patients receiving combination therapy and those receiving monotherapy did not differ with respect to outcome. There were more cases of ototoxicity in the combination therapy group than there were in the monotherapy group.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Muscarinic antagonists such as tolterodine are the treatment of choice for overactive bladder (OAB). We determined the impact of concomitant stress incontinence (SI) on the therapeutic effects of tolterodine in patients with OAB with and without concomitant SI. Data from an open label, observational study involving 2,250 patients with OAB symptoms were analyzed for baseline frequency, urgency and incontinence, and alterations in these symptoms while on 12-week treatment with 2 mg tolterodine twice daily. Data are shown as the mean +/- SD. The statistical significance of differences in treatment effects was determined by multiple regression analysis, adjusting for gender, age and baseline symptom intensity. Concomitant I to III degree SI according to the Stamey grading was present in 31%, 15% and 2% of patients, respectively, and it was associated with increasing basal incontinence, although only III degree SI was associated with greater baseline frequency or urgency. In the overall group tolterodine decreased frequency, urgency and urge incontinence from 12.4 +/- 4.3 to 7.7 +/- 2.7, 8.4 +/- 5.1 to 2.0 +/- 3.0 and 3.4 +/- 4.2 to 0.8 +/- 2.0 episodes daily, respectively. On multiple linear regression analysis I and II degree SI had a minor, if any, effect on this improvement, while III degree SI was statistically associated with a smaller decrease in frequency (by 1.4 +/- 0.4 micturitions daily, p = 0.0002) and incontinence (by 2.1 +/- 0.3 episodes daily, p<0.0001) but with similar alterations in the number of urge episodes.\nQuestion: Does concomitant stress incontinence alter the efficacy of tolterodine in patients with overactive bladder?",
    "gt": "Concomitant I or II degree SI has little effect on the efficacy of tolterodine in OAB cases. Only patients with concomitant III degree SI have significantly less improvement.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Loss of voluntary contraction of the external anal sphincter is thought to be a factor in fecal incontinence. During anal manometry, computerized systems produce several parameters including fatigue rate (FR), which is the basis for calculating the fatigue rate index (FRI). Our aim was to evaluate FR and FRI and their clinical importance in patients suffering from fecal incontinence or severe constipation. All patients scheduled for an anal physiology work-up were included in the study. FR was determined by a computer program and FRI was calculated manually with the following equation: FRI (minutes) = [squeeze pressure (mm Hg) - resting pressure (mmHg)] / - FR (mmHg/min). FR and FRI were compared in patients suffering from fecal incontinence (group I) and severe constipation (group II). Furthermore, subgroups (<50 and>or = 50 years of age) were compared. Lastly, a possible relation between length of the high-pressure zone (HPZ) and FR and FRI was assessed. Between January 2000 and December 2004, 131 patients (96 with fecal incontinence, 35 with constipation) were studied. Both FR and FRI were similar between groups I and II; no significant differences were found when younger and older patients were compared within the same group. We also did not find any relation between HPZ length and either FR or FRI.\nQuestion: Anorectal manometry: are fatigue rate and fatigue rate index of any clinical importance?",
    "gt": "FR and FRI do not seem to be helpful in routine colorectal practice for evaluating the strength of the external anal sphincter.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Anti-beta(2)-Glicoprotein-1 antibodies (anti-beta(2)GPI-ab) have been related to recurrent miscarriage (RM) with conflicting results. The aim was to evaluate the role of anti-beta(2)-GPI-ab as unique biological marker in RM related to antiphospholipid (aPL). A cohort study that included 59 cases, divided in two groups, was designed: group 1 comprised 43 pregnant women with 'obstetric' antiphospholipid syndrome (APS) and group 2 included 16 cases with similar complaints but only having repeatedly anti-beta(2)-GPI-ab. Previous thrombosis and/or inherited thrombophilia were excluded. Lupus anticoagulant, anticardiolipin antibodies (aCA), anti-beta(2)-GPI-ab, and other autoantibodies were analyzed. Miscarriages, premature births, pre-eclampsia, live births, placental and systemic thromboses were studied. No differences in previous obstetric complications were detected (P = 1.00-0.164). After the treatment, differences in number of obstetric complications were not seen (P = 1.00). Live births were similar in two groups (88.4% and 93.7%; P = 1.00). Placental thrombosis was equal in both groups, 93.3% versus 80% (P = 1.00).\nQuestion: Are anti-beta-glycoprotein-I antibodies markers for recurrent pregnancy loss in lupus anticoagulant/anticardiolipin seronegative women?",
    "gt": "These results suggest that anti-beta(2)-GPI-ab may be considered a biological marker for obstetric APS.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patient quality outcomes are a major focus of the health care industry. It is unknown what effect involvement in graduate medical education (GME) has on patient outcomes. The purpose of this study is to begin to examine whether GME involvement in postoperative care impacts patient quality outcomes. The retrospective cohort included all patients who underwent a nonemergent colectomy from January 1, 2007 to January 1, 2008 at a 2-hospital system. Data collected included patient demographics, patient quality outcomes, complications, and GME involvement. Patient quality outcomes were based on compliance with the Surgical Care Improvement Project (SCIP) guidelines. A total of 159 nonemergent colectomies were analyzed. The GME group accounted for 116 (73%) patients. A significant difference was found in several SCIP process-based measures of quality when comparing the GME group with the non-GME group. Postoperative antibiotics were more likely to be stopped within 24 hours (p = 0.010), and preoperative heparin and postoperative deep vein thrombosis (DVT) prophylaxis were more likely to be administered (p<0.001). Additionally, patients in the GME group showed improved quality outcomes as there were significantly fewer postoperative complications (p<0.001) and a shorter duration of stay (p = 0.008). The use of gastrointestinal prophylaxis was more common in the non-GME group (p = 0.002). No significant differences were observed between the 2 groups in respect to age, sex, diabetes, preoperative antibiotics, antibiotics, 1 hour before surgery, postoperative antibiotics, and continuation of home beta blockade.\nQuestion: Does participation in graduate medical education contribute to improved patient outcomes as outlined by Surgical Care Improvement Project guidelines?",
    "gt": "GME at teaching institutions has a positive impact on patient quality outcomes. At our institution, many of the SCIP measurable outcomes had improved compliance if an attending physician participated in the GME program.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In this study, we aimed to investigate the differences between a sample of migraineurs and non-migraineurs with regard to their stress symptoms, tendency to stress, coping styles and life satisfaction. This study was carried out on a migraineur group (n = 62, mean age: 37.5 +/- 11.3, range: 18 to 61 years) and a non-migraineur group (n = 58, mean age: 32.0 +/- 11.2, range: 18 to 61 years). Stress Audit (Symptoms), Stress Audit (Vulnerability), Turkish version of Ways of Coping Inventory Scales and Life Satisfaction were applied to the migraineur and non-migraineur groups. No significant differences were found between the groups in the scores of the stress symptoms except in the sub scores of the sympathetic system. There was no significant difference between the groups in the tendency to stress and life satisfaction (p>.05). For scores of the coping styles, the mean scores of the seeking social support subscale was higher in the control group than that of the migraineur group. However, migraineur women had higher mean scores in the submissive and the optimistic subscales.\nQuestion: Are migraineur women really more vulnerable to stress and less able to cope?",
    "gt": "We consider that, these outcomes may emphasize the necessity to be careful when using negative expressions about stress relating to migraineurs. Further comprehensive studies are required considering the multiple triggers of the disease in various cultural contexts.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess radiation dose to the thyroid in patients undergoing neurointerventional procedures and to evaluate dose reduction to the thyroid by lead shielding. A randomized patient study was undertaken to evaluate the dose reduction by thyroid lead shields and assess their practicality in a clinical setting. Sixty-five patients attending for endovascular treatment of arteriovenous malformations (AVMs) and aneurysms were randomized into one of 2 groups a) No Thyroid Shield and b) Thyroid Lead Shield. Two thermoluminescent dosimeters (TLDs) were placed over the thyroid gland (1 on each side) at constant positions on each patient in both groups. A thyroid lead shield (Pb eq. 0.5 mm) was placed around the neck of patients in the thyroid lead shield group after the neurointerventional radiologist had obtained satisfactory working access above the neck. The total dose-area-product (DAP) value, number and type of digital subtraction angiography (DSA) runs and fluoroscopy time were recorded for all patients. Of the 72 patients who initially attended for neurointerventional procedures, 7 were excluded due to failure to consent or because of procedures involving access to the external carotid circulation. Of the remaining 65 who were randomized, a further 9 were excluded due to; procedureabandonment, unfeasible shield placement or shield interference with the procedure. Patient demographics included mean age of 47.9 yrs (15-74), F:M=1.4:1. Mean fluoroscopy time was 25.9 min. Mean DAP value was 13,134.8 cGy x cm(2) and mean number of DSA runs was 13.4. The mean relative thyroid doses were significantly different (p<0.001) between the unshielded (7.23 mSv/cGy2 x 105) and shielded groups (3.77 mSv/cGy2 x 105). A mean thyroid dose reduction of 48% was seen in the shielded group versus the unshielded group.\nQuestion: Thyroid dose during neurointerventional procedures: does lead shielding reduce the dose?",
    "gt": "Considerable doses to the thyroid are incurred during neurointerventional procedures, highlighting the need for increased awareness of patient radiation protection. Thyroid lead shielding yields significant radiation protection, is inexpensive and when not obscuring the field of view, should be used routinely.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare personality traits of psychiatry residents with various characteristics. The authors administered Cloninger's personality inventory to residents at two schools. There were no trait differences between international medical graduates (IMGs) and U.S. medical graduates (USMGs) or those for whom psychiatry was a first or second choice.\nQuestion: Do the personalities of international and U.S. medical graduates in psychiatry differ?",
    "gt": "Perceived differences between IMG and USMG psychiatry residents appear unrelated to personality.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study and compare the specific postoperative complications of thyroidectomy in a population with a BMI ≥25 with a population having a BMI below 25. A prospective study was carried out from September 2010 to January 2013. Postoperative calcemia, laryngeal mobility, bleeding or infectious complications, postoperative hospital stay, and operation time were studied and compared statistically by a χ(2)-test or Student's t-test. A total of 240 patients underwent total thyroidectomy and 126 underwent a partial thyroidectomy. Of them, 168 patients had a BMI below 25 and 198 patients had a BMI ≥25. There was no statistically significant difference in the occurrence of early or permanent hypoparathyroidism, recurrent laryngeal nerve palsy, bleeding complications, or postoperative duration of hospital stay. There was, however, a significant operative time in patients with a BMI ≥25.\nQuestion: Thyroidectomy in patients with a high BMI: a safe surgery?",
    "gt": "Despite the longer operative time, thyroidectomy (total or partial) can be performed safely in patients with a BMI ≥25.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Venous blood is the usual sample for measuring various biomarkers, including 25-hydroxyvitamin D (25OHD). However, it can prove challenging in infants and young children. Hence the finger-prick capillary collection is an alternative, being a relatively simple procedure perceived to be less invasive. We elected to validate the use of capillary blood sampling for 25OHD quantification by liquid chromatography tandem-mass spectrometry (LC/MS-MS). Venous and capillary blood samples were simultaneously collected from 15 preschool-aged children with asthma 10days after receiving 100,000IU of vitamin-D3 or placebo and 20 apparently healthy adult volunteers. 25OHD was measured by an in-house LC/MS-MS method. The venous 25OHD values varied between 23 and 255nmol/l. The venous and capillary blood total 25OHD concentrations highly correlated (r(2)=0.9963). The mean difference (bias) of capillary blood 25OHD compared to venous blood was 2.0 (95% CI: -7.5, 11.5) nmol/l.\nQuestion: Assessing vitamin D nutritional status: Is capillary blood adequate?",
    "gt": "Our study demonstrates excellent agreement with no evidence of a clinically important bias between venous and capillary serum 25OHD concentrations measured by LC/MS-MS over a wide range of values. Under those conditions, capillary blood is therefore adequate for the measurement of 25OHD.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The reuse of disposable laparoscopic instruments carries a risk of transmitting infectious diseases such as hepatitis and HIV. We evaluated the safety of reusing disposable trocars by studying the chances of their harboring infectious viruses after resterilization in an in vitro setting. Disposable laparoscopic trocars were exposed to horse blood contaminated with high or low viral concentrations of herpes simplex virus type 1 (HSV1) and attenuated polio virus type 1 at room temperature for 2 h. HSV1 was chosen as the surrogate for lipid viruses that include hepatitis B and HIV virus; polio virus represented the nonlipid viruses that cause infections in immunocompromised patients and are more resistant to sterilization. The trocars were subsequently cleaned and resterilized by low-temperature steam and formaldehyde at 80 degrees C for 3 h. Viral cultures were then repeated after sterilization. A cytopathic effect (CPE) was demonstrated at both concentrations for HSV1 in all trocars before but not after sterilization. For the polio virus, CPE was evident in 50% of the trocars (two of four) exposed to high viral concentration after sterilization.\nQuestion: Is it safe to reuse disposable laparoscopic trocars?",
    "gt": "Disposable trocars are difficult to resterilize and may harbor infectious viruses after their initial use. Therefore, the reuse of disposable trocars in laparoscopic surgery cannot be recommended.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: In recent years, hospital medicine programs have adopted \"procedure teams\" that supervise residents in performing invasive bedside procedures. The effect of procedure teams on patient satisfaction is unknown. We sought to measure patient satisfaction with procedures performed by a hospitalist-supervised, intern-based procedure service (HPS) with a focus on patient perception of bedside communication. This was a prospective survey. We surveyed all patients referred to the HPS for bedside thoracentesis, paracentesis, lumbar puncture, and arthrocentesis at a single academic medical center. Following each procedure, surveys were administered to English-speaking patients who could provide informed consent. Survey questions focused on patients' satisfaction with specific aspects of procedure performance as well as the quality and impact of communication with the patient and between members of the team. Of 95 eligible patients, 65 (68%) completed the survey. Nearly all patients were satisfied or very satisfied with the overall experience (100%), explanation of informed consent (98%), pain control (92%), and expertise (95%) of physicians. The majority of patients were satisfied with procedure duration (88%) and in those with therapeutic procedures most (89%) were satisfied with improvement in symptoms. Hearing physicians discuss the procedure at the bedside was reassuring to most patients (84%), who felt this to be a normal part of doing a procedure (94%).\nQuestion: Patient satisfaction with a hospitalist procedure service: is bedside procedure teaching reassuring to patients?",
    "gt": "Patients are highly satisfied with procedure performance by supervised trainees, and many patients were reassured by physician communication during the procedure. These results suggest that patient experience and teaching can be preserved with a hospitalist-supervised procedure service.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The study aim was to assess if an undersized mitral annuloplasty for functional mitral regurgitation (FMR) in dilated cardiomyopathy can determine a clinically relevant mitral stenosis during exercise. Both, rest and stress echocardiography were performed in 12 patients submitted to an undersized ring annuloplasty for FMR in dilated cardiomyopathy. The mean ring size was 27 +/- 1.3 mm. All patients were in NYHA functional classes I-II, were in stable sinus rhythm, and without significant residual mitral regurgitation (grade<or = 2/4). At peak exercise (mean 81 +/- 12 W), the main cardiac performance indices were significantly improved, including systolic blood pressure (121 +/- 5.6 versus 169 +/- 14 mmHg, p<0.001), stroke volume (63 +/- 15 versus 77 +/- 14 ml, p<0.001), left ventricular ejection fraction (43 +/- 9% versus 47 +/- 9%, p = 0.001), and systolic right ventricular function (pulsed tissue Doppler index peak systolic velocity: 8.6 +/- 1.7 versus 11.1 +/- 3.2 cm/s, p = 0.004). A mild increase in planimetric mitral valve area was observed at peak exercise (2.12 +/- 0.4 versus 2.17 +/- 0.3 cm2, p = 0.05). Although the transmitral mean gradient was increased from 3.2 +/- 1.2 to 6.3 +/- 2.3 mmHg (p<0.0001), the systolic pulmonary artery pressure did not change significantly (27 +/- 2.8 versus 30.1 +/- 6.4 mmHg, p = 0.3), thus revealing a preserved cardiac adaptation to exercise.\nQuestion: Undersized annuloplasty for functional mitral regurgitation: is it responsible for clinically relevant mitral stenosis during exercise?",
    "gt": "In these preliminary data, postoperative clinically relevant mitral stenosis was not observed in patients submitted to mitral repair for FMR. Stress echocardiography represents a valuable tool to assess an appropriate cardiac response to exercise and to detect a significant exercise-induced pulmonary hypertension after undersized annuloplasty ring surgery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the level of informed choice in women invited for breast cancer screening for the first time. To determine the content of decision-relevant knowledge, 16 experts were asked to judge whether each of 51 topics represented essential information to enable informed choices. To assess the level of informed choices, a questionnaire was then sent to all 460 invited women in the south-western part of the Netherlands who turned 50 in August 2008. Of all 229 respondents, 95% were deemed to have sufficient knowledge as they answered at least 8 out of 13 items correctly. In 90% there was consistency between intention (not) to participate and attitude. As a result, 88% made an informed choice. Sixty-eight percent of women responded correctly on the item of over-diagnosis. Even if all non-respondents were assumed to have no knowledge, 50% of the total group invited to participate still had sufficient knowledge.\nQuestion: Do women make an informed choice about participating in breast cancer screening?",
    "gt": "Women were deemed to have sufficient relevant knowledge of the benefits and harms if they answered at least half of the items correctly.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine if column agglutination technology (CAT) for titration of anti-D and anti-c concentrations produces comparable results to those obtained by continuous flow analyser (CFA). Anti-D and anti-c are the two commonest antibodies that contribute to serious haemolytic disease of the foetus and neonate (HDFN). Current practice in the UK is to monitor these antibodies by CFA quantification, which is considered more reproducible and less subjective than manual titration by tube IAT (indirect antiglobulin test). CAT is widely used in transfusion laboratory practice and provides a more objective endpoint than tube technique. Antenatal samples were (i) quantified using CFA and (ii) titrated using CAT with the reaction strength recorded by a card reader and expressed as a titre score (TS). The TS rose in accordance with levels measured by quantification and was able to distinguish antibody levels above and below the threshold of clinical significance.\nQuestion: Antenatal monitoring of anti-D and anti-c: could titre scores determined by column agglutination technology replace continuous flow analyser quantification?",
    "gt": "CAT titre scores provided a simple and reproducible method to monitor anti-D and anti-c levels. The method was sensitive to a wide range of antibody levels as determined by quantification. This technique may have the potential to replace CFA quantification by identifying those cases that require closer monitoring for potential HDFN.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hepatitis E is a major health problem in developing countries including India. The incidence and mortality rate in pregnant women with fulminant hepatic failure (FHF) due to hepatitis E virus (HEV) has been reported to be significantly higher, specifically in Asian women. Pregnancy is usually associated with an altered status of sex steroid hormones and immunity. Steroid hormones directly influence the replication through their effects on viral regulatory elements. Moreover, pregnant women in Asia generally suffer from folate deficiency, which is known to cause reduced immunocompetence leading to greater risk of multiple viral infections and higher viral load. To correlate and analyze the viral load and genotypes of HEV in acute liver failure with that of acute viral hepatitis among pregnant and nonpregnant women. A total of 100 FHF and 150 acute viral hepatitis (AVH) patients (50, 75 pregnant and 50, 75 nonpregnant, respectively), were included in the study. These cases were evaluated on the basis of history, clinical examination, liver function profile, and serological test of hepatitis A, B, C, and E using commercially available ELISA kits. Quantification of HEV RNA-positive samples was carried out. Out of 100 FHF and 150 acute viral hepatitis (AVH) patients, 28 (56%) and 22 (29.3%) pregnant and 7 (14%) and 8 (16%) nonpregnant, respectively, were HEV RNA-positive. HEV viral load in FHF pregnant women was 5.87 x 10(4)+/- 1.5 x 10(5) microL/mL as compared to AVH pregnant women 343.29 +/- 216.44 microL/mL and FHF and AVH nonpregnant 199.2 +/- 225.5 microL/mL and 13.83 +/- 7.8 microL/mL, respectively. Sequencing data of all the positive samples of FHF and AVH pregnant and nonpregnant women showed genotype 1.\nQuestion: Does hepatitis E viral load and genotypes influence the final outcome of acute liver failure during pregnancy?",
    "gt": "HEV viral load was found to be significantly higher (P<0.05) in pregnant patients compared to the nonpregnant. Pregnancy appears to be a risk factor for viral replication. The viral copies of HEV in FHF pregnant women were comparatively higher when compared to AVH pregnant women, which may be related to the severity of the disease in these patients. We could detect only one genotype (genotype 1) in our study population. Thus in the absence of other genotypes in this population, the impact of genotype could not be adequately assessed in this study.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To provide evidence whether mechanical thrombectomy with stent-retrievers in the treatment of acute ischemic stroke causes intimal damage. This study analyzed thrombi retrieved by mechanical thrombectomy from cerebral arteries in 48 consecutive patients with acute ischemic stroke for the presence of endothelial cells using CD34 antibodies. Of 48 thrombi analyzed, CD34-positive cells were absent in 20, present as isolated cells in 21, and found in clusters in 7 thrombi. We did not find any subendothelial vessel wall structures.\nQuestion: Immunohistochemical analysis of thrombi retrieved during treatment of acute ischemic stroke: does stent-retriever cause intimal damage?",
    "gt": "Our findings suggest that mechanical thrombectomy with stent-retrievers does not cause relevant intimal damage in acute ischemic stroke treatment. Clinical Trial Registration- URL: http://www.germanctr.de. Unique identifier: DRKS00004695.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Nitric oxide (NO), a potent vasodilator, is presumed to be constitutively released in most mammalian blood vessels. In isolated rat thoracic aorta, however, hemoglobin (Hb), a nitric oxide scavenger, elicited contraction only when the vessels were precontracted with an alpha adrenergic agonist. Does vascular contraction induce endothelial NO release? Thoracic aortic rings from male Sprague-Dawley rats were prepared with or without the endothelium. Vessel rings were contracted with several distinct types of contractile agonists and NO release was probed using a Hb contraction assay in the presence and absence of nitro-l-arginine methyl ester (NAME), a NO synthase inhibitor. In vessel rings precontracted with norepinephrine, potassium chloride, arginine vasopressin, prostaglandin F(2alpha), or serotonin, Hb elicited significant additional contractions. In contrast, Hb failed to elicit significant contractions in vessel rings without the functional endothelium or vessels pretreated with NAME. The Hb mediated additional contraction was not inhibited by calmidazolium, a calmodulin antagonist, and protein kinase inhibitors staurosporine and 2,5-dihydromethylcinnamate. Intercellular gap junction inhibitor 2,3-butanedione monoxime at a low dose (<2 mM) significantly attenuated the NE/Hb mediated contractions but at a high dose (>15 mM) completely prevented both contractions. The contraction coupled NO release may be mediated through a mechanism distinct from the Ca(2+)-calmodulin-dependent endothelial NOS pathway.\nQuestion: Contraction coupled endothelial nitric oxide release: a new paradigm for local vascular control?",
    "gt": "In the isolated rat thoracic aorta, endothelial NO release may be coupled to contractile stimulus. This vascular property appears to render a unique local control mechanism independent of baroreflex and other central mechanisms.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We investigated whether hemodialysis (HD) patients prefer standard or renal-specific oral nutritional supplements (ONS). Standard ONS Fortisip (Nutricia Clinical Care, Wiltshire, Trowbridge, UK) and renal ONS Renilon (Nutricia Clinical Care) and Nepro (Abbott Laboratories, Ltd., Maidenhead, Berkshire, UK) were compared using single-blind taste tests and face-to-face, interviewer-administered questionnaires. This study took place in our HD unit in September 2007. There were 40 patients, including 24 males, 14 smokers, and 26 Caucasians, aged<30 years (n = 6), 31 to 50 years (n = 13), 51 to 70 years (n = 12), and>70 years (n = 9). Patients ranked ONS taste on a Likert scale (1 to 5), and compared flavor options, phosphate-binder requirements, and fluid contribution. Which factors influenced a patient's choice of ONS? Gender, smoking status, ethnicity, and age influenced patients' choices. The taste of Fortisip and Nepro was liked by 58% (n = 23), versus 28% liking Renilon (n = 11). Renilon was disliked by 35% (n = 14), Nepro was disliked by 30% (n = 12), and Fortisip was disliked by 25% (n = 10). The favorite taste was Fortisip, in 52% (n = 21). However, 21% (n = 4) who preferred the taste of renal ONS would not choose them long-term because of their limited flavor ranges. The lack of phosphate binders with Renilon was a deciding factor in 27% (n = 19/33). The low fluid contribution of renal ONS influenced the choice of 43% (n = 12/28). All factors considered, standard ONS remained most popular for patients aged>70 years. However, in all other subgroups, and particularly males and non-Caucasians, renal ONS became more popular. Many patients (23%; n = 9) would sacrifice taste for the benefits of renal ONS.\nQuestion: Do hemodialysis patients prefer renal-specific or standard oral nutritional supplements?",
    "gt": "Renal ONS are more popular in HD patients because of their low fluid contribution and phosphate-binder requirements, which can influence preference over taste. Patients need information to make informed choices.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Current guidelines on the management of mild head trauma (traumatic brain injury/TBI) do not include the presence of a skull fracture in determining the risk of intracranial injury. However, in our setting cranial radiography is still performed frequently to rule out the presence of skull fracture. To estimate the prevalence of clinically-important traumatic brain injuries (ciTBI) in children younger than two years of age with mild TBI. Descriptive observational study. All children attended in emergency department with mild TBI (Glasgow ≥14 points) for a year were included. We defined ciTBI as intracranial injuries that caused death or required neurosurgery, intubation for more than 24 hours, inotropic drugs or mechanical ventilation. The study included 854 children, of which 457 (53.5%) were male. The median patient age was 11.0 months (P25-75: 7.5-17.0 months). In 741 cases (86.8%) the mechanism of TBI was a fall. In 438 cases (51.3%) skull radiography was performed. Eleven children (1.3%) had intracranial injury, but none met the criteria for ciTBI (estimated prevalence of ciTBI was 0%; CI 95%: 0%-0.4%).\nQuestion: Children with minor head injury in the emergency department: Is skull radiography necessary for children under 2 years?",
    "gt": "Children younger than two years of age with mild TBI have low prevalence of ciTBI. Consequently, it is possible to monitor children younger than two years with a TBI without performing skull radiography.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The dietary diversity score (DDS) is a good indicator of diet quality as well as of diet-disease relationships; therefore, the present study was undertaken to reveal the effect of a lifestyle intervention on this index. A baseline and three evaluation studies were conducted in two intervention districts (Isfahan and Najaf-Abad) and a reference area (Arak), all located in central Iran. The Isfahan Healthy Hearth Programme (IHHP) targeted the entire population of nearly 2 million in urban and rural areas of the intervention communities. One of the main strategies of the lifestyle intervention phase in the IHHP was healthy nutrition. Usual dietary intake was assessed using a forty-nine-item FFQ. A diversity score for each food group was calculated and the DDS was considered the sum of the diversity scores of the food groups. There were significant increases in DDS in both intervention areas (P = 0.0001) after controlling for confounding factors. There was a significant interaction between area and evaluation stage with regard to DDS (P = 0.0001). The effect of the intervention on the diversity scores of all food groups was also significant (P = 0.0001 for all) after adjusting for socio-economic status.\nQuestion: Do lifestyle interventions affect dietary diversity score in the general population?",
    "gt": "The community-based lifestyle intervention in the IHHP was successful in improving DDS which might be related to an increase of diet quality of the population that in turn might decrease the risks of chronic diseases.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Many modifications to the traditional residency model contribute to the ongoing paradigm shift in surgical education; yet, the frequency and manner by which such changes occur at various institutions is less clear. To address this issue, our study examined the variability in endoscopy and laparoscopy training, the potential impact of new requirements, and opinions of Program Directors in Surgery (PDs). A 22-item online survey was sent to 251 PDs in the United States. Appropriate parametric tests determined significance. In all, 105 (42%) PDs responded. No difference existed in response rates among university (56.2%), university-affiliated/community (30.5%), or community (13.3%) program types (p = 0.970). Surgeons alone (46.7%) conducted most endoscopy training with a trend toward multidisciplinary teams (43.8%). A combination of fellowship-trained minimally invasive surgeons and other surgeon types (66.7%) commonly provided laparoscopy training. For adequate endoscopy experience in the future, most PDs (74.3%) plan to require a formal flexible endoscopy rotation (p<0.001). For laparoscopy, PDs intend for more minimally invasive surgery (59%) as well as colon and rectal surgery (53.4%) rotations (both p<0.001). Respondents feel residents will perform diagnostic endoscopy (86.7%) and basic laparoscopy (100%) safely on graduation. Fewer PDs confirm graduates will safely practice therapeutic endoscopy (12.4%) and advanced laparoscopy (52.4%). PDs believe increased requirements for endoscopy and laparoscopy will improve procedural competency (79% and 92.4%, respectively) and strengthen the fields of surgical endoscopy and minimally invasive surgery (55.2% and 68.6%, respectively). Less believe new requirements necessitate redesign of cognitive and technical skills curricula (33.3% endoscopy, 28.6% laparoscopy; p = 0.018). A national surgical education curriculum should be a required component of resident training, according to 79% of PDs.\nQuestion: Do increased training requirements in gastrointestinal endoscopy and advanced laparoscopy necessitate a paradigm shift?",
    "gt": "PDs employ and may implement varied tools to meet the increased requirements in endoscopy and laparoscopy. With such variability in educational methodology, establishment of a national surgical education curriculum is very important to most PDs.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Neonatal mortality and morbidity are gender-biased in low-birth-weight (LBW) infants. The male disadvantage theory has been suggested to be responsible for these maturational differences. To examine the impact of gender on neonatal hyperbilirubinemia.DESIGN/ A retrospective observational study. Data on all LBW infants admitted to George Washington University neonatal intensive care unit and surviving for>48 hrs from January 1992 to March 2003 were analyzed. Males and females were compared for gestational age, birth weight, race, Apgar scores at 1 and 5 mins, peak bilirubin levels, sepsis, and intraventricular hemorrhage (IVH). Significant differences were entered in a regression model to detect the influence of gender on bilirubin (Bili). Analysis was repeated after stratification of infants into: group A,<1000 g; group B, 1000-1499 g; and group C, 1500-2499 g. A total of 840 infants were included in this study. When comparing males (n = 407) with females (n = 433), significant differences were detected in birth weight (1,539 +/- 541 vs. 1,428 +/- 549 g; p = .003), IVH (14.2% vs. 9%; p = .025), and Bili (10.1 +/- 3.0 vs. 9.2 +/- 2.8 mg%; p<.001). No differences were detected in gestational age, sepsis, or Apgar 1 and 5. Difference in Bili for the entire group remained significant in the regression model (regression coefficient [RC] = 0.79 +/- 0.22; p<.001). In subgroup analyses: group A Bili (8.4 +/- 2.3 vs. 8.0 +/- 2.0; p = .14) and group B Bili (9.0 +/- 2.1 vs. 9.2 +/- 2.2; p = .51) did not differ in bivariate or multivariate analyses. In group C, Bili was (11.3 +/- 3.1 vs. 10.1 +/- 3.3; p<.001) and remained the only significant difference in the regression model (RC = 1.19 +/- 0.37; p = .001).\nQuestion: Does gender affect neonatal hyperbilirubinemia in low-birth-weight infants?",
    "gt": "Bili in LBW infants is significantly higher in males when compared with females. After stratification to birth weight subgroups, significance is retained in the 1500- to 2499-g group after logistic regression analysis. Bili levels in infants<1500 g are influenced more significantly by factors other than gender, such as sepsis and IVH.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Numerous clinical studies have shown that biofilm formation by Staphylococcus epidermidis on the outer surface of a silicone breast implant is strongly associated with capsular contracture formation. Traditional administration of systemic antibiotics and antiseptic washing are not necessarily the most effective methods for the prevention of initial biofilm formation on implants in the clinical scenario. In this study an alternative or supplement was sought for preventing or delaying bacterial colonisation and adherence to the outer surface of a breast implant, by establishing an in vitro model for investigating this complex problem. The in vitro antimicrobial activity of several antimicrobial agents was investigated for inhibitory effects on biofilm formation by S. epidermidis. The study consisted of two experiments. The first experiment consisted of two groups (A and B) of seven discs each whilst the second experiment was divided into three groups (C, D and E) of 14 discs each. Each group of 14 consisted of seven smooth and seven textured discs. Discs (biopsies) of each implant were individually coated with one of six different antimicrobial agents. Controls that received no agent were included in the various experimental groups. In the first experiment disc diffusion sensitivity testing was performed and inhibition zone sizes were measured. In the second experiment the discs were cultured in broth. The degree of biofilm formation was evaluated by scanning electron microscopy (SEM). In the first in vitro experiment, all six agents showed a measurable antimicrobial effect against the biofilm-forming strain of S. epidermidis when compared to the effect against the American Type Culture Collection strain. In the second in vitro experiment, discs coated with Chloramex, Fucidin and Terramycin did not allow biofilm formation to take place for at least 7 days.\nQuestion: Antimicrobial coating agents: can biofilm formation on a breast implant be prevented?",
    "gt": "Staphylococcus epidermidis biofilm formation on the outer surface of a silicone breast implant was prevented in vitro for at least 7 days by coating with an appropriate antimicrobial agent. Further evaluation of the interaction between antimicrobial coating agents and S. epidermidis biofilm formation needs to be made before conclusions regarding the clinical scenario can be drawn.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess whether adoption of the patient-centered medical home (PCMH) reduces emergency department (ED) utilization among patients with and without chronic illness. Data from approximately 460,000 Independence Blue Cross patients enrolled in 280 primary care practices, all converting to PCMH status between 2008 and 2012. We estimate the effect of a practice becoming PCMH-certified on ED visits and costs using a difference-in-differences approach which exploits variation in the timing of PCMH certification, employing either practice or patient fixed effects. We analyzed patients with and without chronic illness across six chronic illness categories. Among chronically ill patients, transition to PCMH status was associated with 5-8 percent reductions in ED utilization. This finding was robust to a number of specifications, including analyzing avoidable and weekend ED visits alone. The largest reductions in ED visits are concentrated among chronic patients with diabetes and hypertension.\nQuestion: Do patient-centered medical homes reduce emergency department visits?",
    "gt": "Adoption of the PCMH model was associated with lower ED utilization for chronically ill patients, but not for those without chronic illness. The effectiveness of the PCMH model varies by chronic condition. Analysis of weekend and avoidable ED visits suggests that reductions in ED utilization stem from better management of chronic illness rather than expanding access to primary care clinics.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A wish to die is common in older persons and is associated with increased mortality. Several risk factors have been identified, but the association between religiousness and a wish to die in older adults has been underexplored, and the association between death attitudes and the presence of a wish to die has not been investigated yet. The aim of this study is to explore the relationship between religiousness and death attitudes on the one hand and wish to die on the other hand, adjusting for clinical factors such as the presence of depression or somatic disorder. The sample comprised 113 older inpatients (from a psychiatric and somatic ward) with a mean age of 74 years. Psychiatric diagnoses were assessed by the Structured Clinical Interview for DSM-IV Disorders, and logistic regression analyses estimated the unique contribution of religiousness and death attitudes to the wish to die, controlling for socio-demographic variables, depressive disorder, and somatic symptoms. Both religiousness and death attitudes were associated with a wish to die in univariate models. Adding these variables in a multivariate logistic hierarchical model, death attitudes remained significant predictors but religiousness did not; 55% of the pseudovariance of the wish to die was explained by these variables, with an effective size of 0.89. Major depressive episode, somatic symptoms, Fear of Death, and Escape Acceptance were the most important predictors of the wish to die.\nQuestion: Are religiousness and death attitudes associated with the wish to die in older people?",
    "gt": "This study suggests that how older adults perceive death partly determines whether they have a wish to die. There may be a clinical, patient-oriented benefit in discussing with older patients about how they perceive death, as this can play a role in the early detection (and prevention) of death or suicide ideation and associated behaviors in older adults.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Measuring FE(NO) is a novel and non-invasive way to monitor airway inflammation (e.g. asthma). This clinical study was designed to investigate whether drinking ethanol might distort FE(NO) measurements. Twenty healthy subjects drank 0.40 g ethanol/kg body weight in 15 min. Measurement of FE(NO) started approximately 30 min before drinking and at various times afterwards for 4 h post-dosing. Ethanol concentrations were determined in venous blood by gas chromatography and in end-exhaled breath by infra-red spectrometry. The within subject standard deviation for determination of FE(NO) was 1.3 ppb, corresponding to a CV of 7.7%. The mean change in FE(NO) from pre-drinking levels during the 4h testing was statistically significant (P<0.001) according to repeated measures ANOVA. In absolute units the mean change was small, -2.01 and -1.94 ppb at 3 and 4h post-dosing, respectively (P<0.013, P<0.005).\nQuestion: Does consumption of ethanol distort measurements of exhaled nitric oxide?",
    "gt": "FE(NO) measurements were reproducible even in subjects with moderate concentrations of ethanol in blood and breath. The small decrease in FE(NO) observed at 3 and 4 h post-drinking was less than the intra-subject variations in FE(NO) measurements. The breath-alcohol concentrations in this study exceed all other endogenous volatiles, thus making it unlikely that other substances in human breath will bias the FE(NO) measurements.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate whether L-Arginine has an effect on endogenous epidermal growth factor secretion and intestinal adaptation in massive small bowel resection an experimental study was performed. Fourteen albino Wistar rats weighing 250-300 g were used for the study. After performing 50% small bowel resection and anastomosis the rats were randomly divided into two groups. The first group received 500 mg/kg/day of L-Arginine intraperitoneally for 14 days just after the surgical procedure. The control group received isotonic saline instead. Body weight measurement was preformed daily. At the end of the second postoperative week all rats underwent relaparotomy. Small bowel was resected for histopathological examination. Levels of epidermal growth factor were measured by enzyme-linked immunosorbent assay in serum, saliva, and urine at the end of second postoperative week in both groups. The weight gain was higher in the L-Arginine treated group (P<0.05). Serum, saliva and urinary epidermal growth factor levels were significantly higher at the end of the second week compared to the control group (P<0.05). The villus height was higher on histopathological examination in L-Arginine treated group compared to the control group (P<0.05).\nQuestion: Does L-arginine induce intestinal adaptation by epithelial growth factor?",
    "gt": "L-Arginine resulted in a better intestinal adaptation after massive bowel resection. The high levels of epidermal growth factor in body fluids of L-Arginine treated rats could be the explanation for this effect.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: China has a high burden of drug-resistant tuberculosis (TB) and diabetes mellitus (DM). The objectives of this study were to determine the following in patients with culture-confirmed TB: 1) demographic characteristics and disease patterns in relation to the presence or absence of type 2 diabetes and 2) presence or absence of drug resistance to isoniazid (INH), rifampicin (RMP) or both in relation to duration of diabetes and control of diabetes. This is a cross-sectional and retrospective study involving record reviews. There were 621 patients with culture-positive TB, of whom 187 (30%) had previously known or new type 2 diabetes. In those with diabetes, there was a significantly higher proportion of males, persons aged ≥35 years and patients registered with new TB (p<0.05). Prevalence of multidrug-resistant TB (MDR-TB) was 6.2% in new patients (N=422) and 62.3% in previously treated patients (N=199), with no significant differences between those with and without diabetes. In patients with diabetes, there was no association of drug resistance with diabetes duration or disease control [assessed by fasting blood glucose (FBG) at 1 week].\nQuestion: Is resistance to anti-tuberculosis drugs associated with type 2 diabetes mellitus?",
    "gt": "A high proportion of patients with TB in a tertiary health facility, Beijing, China, had diabetes, but there was no association between type 2 diabetes and drug-resistant TB. Further prospective studies are needed to confirm these findings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The value of epicardial adipose tissue (EAT) thickness as determined by echocardiography in cardiovascular risk assessment is not well understood. The aim of this study was to determine the associations between EAT thickness and Framingham risk score, carotid intima media thickness, carotid artery plaque, and computed tomographic coronary calcium score in a primary prevention population. Patients presenting for cardiovascular preventive care (n = 356) who underwent echocardiography as well as carotid artery ultrasound and/or coronary calcium scoring were included. EAT thickness was weakly correlated with Framingham risk score. The prevalence of carotid plaque was significantly greater in those with EAT thickness ≥ 5.0 mm who either had low Framingham risk scores or had body mass indexes ≥ 25 kg/m(2), compared with those with EAT thickness<5.0 mm. No significant association between EAT thickness and carotid intima-media thickness or coronary calcium score existed.\nQuestion: Epicardial fat: an additional measurement for subclinical atherosclerosis and cardiovascular risk stratification?",
    "gt": "EAT thickness ≥ 5.0 mm may identify an individual with a higher likelihood of having detectable carotid atherosclerosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The study was carried out to determine the learning curve patterns for basic laparoscopic technical skills. Thirty-seven surgical residents with limited laparoscopic experience performed 10 repetitions of 6 tasks on a virtual-reality trainer (MIST-VR) with standardized distribution of practice. Assessment was based on time, errors, and economy of motion as measured by MIST-VR. Proficiency levels were established by testing experienced laparoscopic surgeons. Four learning curve patterns were determined. Surgeons in group 1 (5.4%) demonstrated proficiency from the beginning; group 2 (70.3%) achieved predefined expert criteria between 2 and 9 repetitions; group 3 (16.2%) demonstrated improvement but was unable to achieve proficiency within 10 repetitions. Group 4 (8.1%) underperformed and showed no tendency of skills improvement, reflecting a group of subjects who probably are unable to learn laparoscopic technique.\nQuestion: Can everyone achieve proficiency with the laparoscopic technique?",
    "gt": "The results indicated that a group of subjects could not reach proficiency in the psychomotor skills relevant for laparoscopy. We believe that this is an important issue that should be addressed in future research.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Professional setting might be a key determinant of physicians' attitudes toward practice guidelines, influencing the effect of their implementation. Because no previous surveys have specifically considered this aspect, we evaluated the perceived role and usefulness of guidelines, as well as barriers to and facilitators of their implementation, for hospital, primary care, and nonpracticing clinicians. A 43-item self-administered questionnaire was sent to all National Health Service physicians in the province of Modena, Italy (593 primary care physicians, 1049 hospital physicians, and 149 nonpracticing clinicians), and 1199 (66.9%) responded. Opinions and attitudes were assessed using 5-point ordinal scales and an attitude measurement scale. Results were evaluated overall and by professional setting, sex, age, year of graduation, and academic background. Practice guidelines were generally perceived to be less useful than other sources of medical information (eg, personal experience, conferences, colleagues, articles, the Internet, and textbooks [pharmaceutical representatives were the exception]). Most physicians thought that guidelines are developed for cost-containment reasons and expressed concerns about their limited applicability to individual patients and local settings. Most respondents did not favor the involvement of health professionals other than physicians in guideline development and use and preferred nonmonetary incentives for their implementation. Answers to individual items and attitude scores varied significantly across professional settings. Primary care physicians showed, in general, the least favorable attitudes toward practice guidelines, toward nonphysicians participating in guideline development and use, and toward incentives for guideline users.\nQuestion: Practice guidelines: useful and \"participative\" method?",
    "gt": "Physicians perceived practice guidelines as externally imposed and cost-containment tools rather than as decision-supporting tools. Regularly monitoring attitudes toward practice guidelines can be helpful to evaluate potential barriers to their adoption.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Serum FSH elevations and decreases in inhibin B have been consistently demonstrated in the early follicular phase of cycles in women of advanced reproductive age. However, secretory products of the dominant follicle (estradiol and inhibin A) in the serum of older ovulatory women are maintained at levels similar to those of their younger counterparts. The goal of this investigation was to determine if ovarian secretory capacity is dependent on relative FSH levels and if basal measures of ovarian reserve reflect ovarian secretory capacity. We administered equivalent low, but effective doses of recombinant FSH for 5 days to a group of older subjects (40-45 years, n=9) and younger controls (20-25 years, n=10) after pituitary suppression with a GnRH agonist. Outcome measures included follicular development as determined by serial transvaginal ultrasound examinations and serum levels of estradiol, inhibin A and inhibin B. Serum levels of estradiol and inhibin A were not statistically different between the two groups, while the number of large follicles formed was greater in the younger subjects. Basal parameters of ovarian reserve were not significantly correlated with ovarian secretory capacity, but did correlate with the number of follicles recruited in response to low-dose FSH.\nQuestion: Reproductive ageing and ovarian function: is the early follicular phase FSH rise necessary to maintain adequate secretory function in older ovulatory women?",
    "gt": "By providing equivalent serum levels of FSH in older and younger reproductive aged women, this study demonstrates that the secretory capacity of recruited follicles is maintained in older reproductive aged women.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Many emergency medicine staff report anecdotally that fellow hospital staff have a low opinion of emergency medicine. No research into this attitude has been published. The aim of this study is to determine whether there is stigma attached to emergency medicine and practitioners. A postal questionnaire of all medical staff at a district general hospital, to evaluate the presence or absence of eight perceptions associated with stigma. The response rate was 49.5%, with the response rate decreasing with decreasing grade. Of the stigmatizing themes tested in this study, six of the eight were demonstrated to be associated with negative attitudes, with the remaining two themes positive attitudes towards emergency medicine were suggested. The responses were similar, irrespective of grade and speciality (where given by respondees). Responses that were ambivalent or not completed varied between 25 and 48% in the returned questionnaires.\nQuestion: Is a career in emergency medicine associated with stigma?",
    "gt": "This paper demonstrates that stigmatizing opinions towards emergency medicine exist and that these negative opinions may be widely held by hospital staff.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The introduction of ambulatory blood pressure monitoring into clinical practice has defined a clinical condition called 'isolated office hypertension'. The aim of this study was to evaluate the long-term systolic and diastolic blood pressure changes in patients with isolated office hypertension and to identify the presence of markers capable of identifying which patients will develop sustained hypertension. All the 407 patients enrolled had a random office systolic or/and diastolic blood pressure of over 140/90mmHg and a mean daytime ambulatory blood pressure of 130/84mmHg or less. At enrollment, each patient underwent a 'baseline examination' made up of a physical evaluation, a 24h ambulatory blood pressure monitoring, and a mental arithmetic test performed at the end of the 24h ambulatory monitoring. Of the 173 patients finally studied, 102 (58.9%) developed sustained hypertension with an increase in both ambulatory systolic and diastolic blood pressure. At the time of the baseline examination, the patients were divided into two groups. Group A included patients with mean ambulatory systolic and diastolic blood pressures in the first hour of 130/84mmHg or less; group B included patients with mean ambulatory systolic and diastolic pressures in the first hour of greater than 130/84mmHg. During the mental arithmetic test, the systolic and heart rate values increased significantly only in group B patients. Of the 102 patients who had become hypertensive by the time of the follow-up examination, 84 (82%) belonged to group B.\nQuestion: Isolated office hypertension: are there any markers of future blood pressure status?",
    "gt": "These data suggest that isolated office hypertension may indeed be a transitional state towards the development of sustained hypertension. Moreover, the mean ambulatory blood pressure value during the first hour can be considered to be a marker of a higher risk of developing sustained hypertension.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Full thickness grafts on the nose do not always heal without problems. Partial or entire necrosis of the graft is likely to lead to less favourable cosmetic results and prolonged wound care. No consensus exists as to the use of systemic antibiotics to increase the success rate of survival of a full thickness skin graft on the nose after non-melanoma skin cancer surgery. The objective of the study was to evaluate the effect of systemic antibiotics on the survival of full thickness grafts on the nose. We performed a randomized, controlled trial in which we compared azithromycin with standard treatment in 30 patients, who underwent a full thickness graft reconstruction of a surgical defect on the nose after surgery for non-melanoma skin cancer. Percentage survival of the graft was the main outcome measure. A statistically significant difference in favour of the grafts treated with azithromycin was seen (P=0.002). Of all the variables analysed, only smoking had a significant negative effect on the survival of the graft.\nQuestion: Do systemic antibiotics increase the survival of a full thickness graft on the nose?",
    "gt": "Systemic antibiotics with an accurate bacterial spectrum should be advised in full thickness skin graft reconstruction after surgery for non-melanoma skin cancer of the nose. Smoking should be strongly discouraged.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: DSM-IV subtypes anorexia nervosa by the presence or absence of bulimic symptoms. Assessing whether bulimic symptoms are related to the probability of recovery can provide justification for subtyping of anorexia. Two hundred twenty-five treatment-seeking women with anorexia and/or bulimia nervosa were interviewed every 3 months for up to 4 years. Survival methods were used for analyses. Less than half of the entire cohort recovered; however, the great majority of the women became less symptomatic over time. Contrary to findings from previous studies, bulimic anorexics had a higher rate of recovery than restricting anorexics.\nQuestion: Subtyping eating disorders: is it justified?",
    "gt": "Differences in course provide some support for the subtyping of anorexia nervosa. Additional prospective studies are needed before subtyping can be warranted.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Central venous catheter (CVC)-related infections are a substantial problem in the intensive care unit (ICU). Our infection control team initiated the routine use of antiseptic-coated (chlorhexidine-silver sulfadiazine; Chx-SS) CVCs in our adult ICUs to reduce catheter-associated (CA) and catheter-related (CR) blood stream infection (BSI) as we implemented other educational and best practice standardization strategies. Prior randomized studies documented that the use of Chx-SS catheters reduces microbial colonization of the catheter compared with an uncoated standard (Std) CVC but does not reduce CR-BSI. We therefore implemented the routine use of uncoated Std CVCs in our surgical ICU (SICU) and examined the impact of this change. The use of uncoated Std CVCs does not increase CR-BSI rate in an SICU. Prospective evaluation of universal use of uncoated Std CVCs, implemented November 2007 in the SICU. The incidences of CA-BSI and CR-BSI were compared during November 2006-October 2007 (universal use of Chx-SS CVCs) and November 2007-October 2008 (universal use of Std CVCs) by t-test. The definitions of the U.S. Centers for Disease Control and Prevention were used for CA-BSI and CR-BSI. Patient data were collected via a dedicated Acute Physiology and Chronic Health Evaluation (APACHE) III coordinator for the SICU. Annual use of CVCs increased significantly in the last six years, from 3,543 (2001) to 5,799 (2006) total days. The APACHE III scores on day 1 increased from a mean of 54.4 in 2004 to 55.6 in 2008 (p = 0.0010; 95% confidence interval [CI] 1.29-5.13). The mean age of the patients was unchanged over this period, ranging from 58.2 to 59.6 years. The Chx-SS catheters were implemented in the SICU in 2002. Data regarding the specific incidence of CR-BSI were collected beginning at the end of 2005, with mandatory catheter tip cultures when CVCs were removed. Little difference was identified in the incidence of BSI between the interval with universal Chx-SS use and that with Std CVC use. (Total BSI 0.7 vs. 0.8 per 1,000 catheter days; CA-BSI 0.5 vs. 0.8 per 1,000 catheter days; CR-BSI 0.2 vs. 0 per 1,000 catheter days.) No difference was seen in the causative pathogens of CA-BSI or CR-BSI.\nQuestion: Prevention of catheter-related blood stream infection: back to basics?",
    "gt": "Eliminating the universal use of Chx-SS-coated CVCs in an SICU with a low background incidence of CR-BSIs did not result in an increase in the rate of CR-BSIs. This study documents the greater importance of adherence to standardization of the processes of care related to CVC placement than of coated CVC use in the reduction of CR-BSI.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Implantable left ventricular assist devices (LVADs) were designed for permanent implant, but we began their use for bridge-to-transplant (BTTx) to study their safety and effectiveness. We review our experience in order to compare the BTTx lessons learned with the outcomes and goals of permanent implants. From December 1991 until January 2002, 264 patients received 277 LVADs for BTTx. We analyzed temporal trends in pre-LVAD patient factors and device-specific time-related complications. Survival to transplant was 69%. Adverse event analysis demonstrated a high risk of infections (0.56, 1.28, and 1.88 per patient at 30 days and 3 and 6 months). HeartMate devices were more prone to infection than Novacor devices (p<0.0001). Cerebral infarctions occurred less commonly than infections (0.15, 0.25, 0.30 at 30 days and 3 and 6 months), were more common in Novacor than HeartMate (p = 0.0001), and were decreased by the new Novacor Vascutek conduit (p = 0.07), but these were still slightly higher than the HeartMate (p = 0.04). Device failures occurred in 21 instances (all but one were in HeartMate devices [p = 0.04 vs Novacor]), but have significantly decreased (p<0.0001) in HeartMate since 1998.\nQuestion: Do left ventricular assist device (LVAD) bridge-to-transplantation outcomes predict the results of permanent LVAD implantation?",
    "gt": "Infections and device durability limit the chronic use of the HeartMate device, but device failures are decreasing. Novacor has fewer problems with infection and durability, and the new Vascutek conduit will reduce, but not eliminate, strokes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: All epidemiological studies (cohort and case-control) which estimate risk of congenital malformations after exposure to metronidazole during early pregnancy were included in the meta-analysis. To obtain a summary odds ratio, the Mantel-Haenszel method was used. A test to verify absence of heterogeneity was also performed. One unpublished case-control and four published cohort studies fulfilled the inclusion criteria and were not statistically heterogeneous. A summary odds ratio was calculated for metronidazole exposure during the first trimester: OR = 1.08, 95% CI: 0.90-1.29, heterogeneity test chi2 = 4.72, P = 0.32.\nQuestion: Is metronidazole teratogenic?",
    "gt": "This meta-analysis did not find any relationship between metronidazole exposure during the first trimester of pregnancy and birth defects.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether access to cardiac procedures and drugs contributes to social and ethnic differences in coronary heart disease in a population setting. Prospective study with follow up over 15 years. Civil service employment grade was used as a measure of individual socioeconomic position. Need for cardiac care was determined by the presence of angina, myocardial infarction, and coronary risk factors. 20 civil service departments originally located in London. 10,308 civil servants (3414 women; 560 South Asian) aged 35-55 years at baseline in 1985-8. Use of exercise electrocardiography, coronary angiography, and coronary revascularisation procedures and secondary prevention drugs. Inverse social gradients existed in incident coronary morbidity and mortality. South Asian participants also had higher rates than white participants. After adjustment for clinical need, social position showed no association with the use of cardiac procedures or secondary prevention drugs. For example, men in the low versus high employment grade had an age adjusted odds ratio for angiography of 1.87 (95% confidence interval 1.32 to 2.64), which decreased to 1.27 (0.83 to 1.94) on adjustment for clinical need. South Asians tended to be more likely to have cardiac procedures and to be taking more secondary prevention drugs than white participants, even after adjustment for clinical need.\nQuestion: Does access to cardiac investigation and treatment contribute to social and ethnic differences in coronary heart disease?",
    "gt": "This population based study, which shows the widely observed social and ethnic patterning of coronary heart disease, found no evidence that low social position or South Asian ethnicity was associated with lower use of cardiac procedures or drugs, independently of clinical need. Differences in medical care are unlikely to contribute to social or ethnic differences in coronary heart disease in this cohort.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Adherence to statin therapy has been shown to be suboptimal. In statin-treated patients with residual elevated low density lipoprotein cholesterol (LDL-C) levels the physician must decide whether to switch to a more potent statin or try and achieve better adherence. We examined the association between adherence and LDL-C within low, moderate and high intensity statin groups in a \"real world\" setting. We assessed annual adherence by the mean MPR (Medication Possession Ratio = number of purchased/prescribed daily doses) in unselected patient group. Statins were stratified (ACC/AHA Guideline) into low, moderate and high intensity groups. The impact of adherence on LDL levels was assessed by LOESS (locally weighted scatter plot smoothing). Out of 1183 patients 173 (14.6%) were treated with low, 923 (78.0%) with moderate and 87 (7.4%) with high intensity statins. Statin intensity was inversely associated with adherence (MPR 77±21, 73±22 and 69±21% for low, moderate and high intensity respectively, p=0.018). Non-adjusted LDL levels decreased with higher adherence: a 10% adherence increase resulted in LDL decrease of 3.5, 5.8 and 7.1mg/dL in low, moderate and high intensity groups. Analysis of the adherence effect on LDL levels adjusted for age, DM and ischemic heart disease showed that MPR above 80% was associated with an additional decrease in LDL levels only in the high intensity group.\nQuestion: Statin adherence and LDL cholesterol levels. Should we assess adherence prior to statin upgrade?",
    "gt": "Increased adherence to statins beyond an MPR of 80% improves LDL levels only among patients given high intensity therapy. Switching from lower to higher intensity therapy may be more effective than further efforts to increase adherence.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We employed the placebo-caffeine paradigm to test whether the presence or absence of a substance (caffeine) influences the placebo effect. In experiment 1 consisting of four conditions with n = 15 participants each (control, placebo, two double-blind groups, each with placebo only), we maximized the placebo effect through expectation. Effects were assessed with physiological (blood pressure, heart rate), psychomotor (response times), and well-being indicators (self-report). In experiment 2, caffeine was administered in one of the double-blind groups, and another condition was added where caffeine was given openly. Effect sizes were medium to large for some outcome parameters in experiment 1 and 2, showing partial replicability of the classical placebo effect. Although not formally significant, differences between the double blind placebo conditions of the two experiments (with and without caffeine present) were medium to small. There was a significant difference (p = 0.03) between experiment 1 and experiment 2 in the physiological variables, and a near significant interaction effect between groups and experiments in the physiological variables (p = 0.06).\nQuestion: Does the presence of a pharmacological substance alter the placebo effect?",
    "gt": "The question warrants further scrutiny. The presence of a pharmacological substance might change the magnitude of the placebo response.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There have been dramatic changes in neurology over the past decade; these advances require a constant adaptation of residents' theoretical and practical training. The French Association of Neurology Residents and the College of Neurology Teachers conducted a national survey to assess the French neurology residents' satisfaction about their training. A 16-item questionnaire was sent via e-mail to French neurology residents completing training in 2014. Data were collected and processed anonymously. Of eligible respondents, 126 returned the survey, representing approximately 40% of all the French neurology residents. Most residents (78%) rated their clinical training favorably. Seventy-two percent reported good to excellent quality teaching of neurology courses from their faculty. However, many residents (40%) felt insufficient their doctoral thesis supervision. All residents intended to enter fellowship training after their residency, and most of them (68%) planned to practice in a medical center.\nQuestion: Are the French neurology residents satisfied with their training?",
    "gt": "French neurology residents seemed satisfied with the structure and quality of their training program. However, efforts are required to improve management of the doctoral thesis and make private practice more attractive and accessible during the residency. In the future, similar surveys should be scheduled to regularly assess neurology residents' satisfaction and the impact of the forthcoming national and European reforms.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study the relationship between the primary sensitization to wasp venoms and the geographical and seasonal circumstances of the anaphylaxis-induced sting. We performed a retrospective review of 115 patients (age 10-80) who suffered a systemic reaction to a wasp sting. Season and type of locality (urban or rural) at the moment of the sting were recorded. Serum specific IgE levels to venoms from Vespula and Polistes were measured, and a primary sensitization was determined to whichever genus of wasp for which the highest class of specific IgE was observed. The primary sensitization in relation to the type of locality and the season was assessed using the chi-square test. Most reactions occurred in urban areas (67.8 %), and in the summer season (63.4 %). Most patients were sensitized to Vespula venom (94.8 %). Primary sensitization was to Vespula in 56.5 %, to Polistes in 10.4 %, and undetermined in 33 %. The distribution of geographical areas did not show significant differences in relation to primary sensitization (p>0.05). Most patients with primary sensitization to Vespula suffered the anaphylaxis-induced sting after the spring season, with a statistically significant result (p<0.05).\nQuestion: Hypersensitivity to Vespula and Polistes: can we tell the primary sensitization from the clinical history?",
    "gt": "In our population, the probability of Vespula sting is higher than Polistes sting when the reaction occurs after spring. This finding can help us to identify the responsible vespid when the diagnostic tests do not provide an accurate result.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patients with single-suture craniosynostosis (SSC) are at an elevated risk for long-term learning disabilities. Such adverse outcomes indicate that the early development of neural processing in SSC may be abnormal. At present, however, the precise functional derangements of the developing brain remain largely unknown. Event-related potentials (ERPs) are a form of noninvasive neuroimaging that provide direct measurements of cortical activity and have shown value in predicting long-term cognitive functioning. The current study used ERPs to examine auditory processing in infants with SSC to help clarify the developmental onset of delays in this population. Fifteen infants with untreated SSC and 23 typically developing controls were evaluated. ERPs were recorded during the presentation of speech sounds. Analyses focused on the P150 and N450 components of auditory processing. Infants with SSC demonstrated attenuated P150 amplitudes relative to typically developing controls. No differences in the N450 component were identified between untreated SSC and controls.\nQuestion: Direct brain recordings reveal impaired neural function in infants with single-suture craniosynostosis: a future modality for guiding management?",
    "gt": "Infants with untreated SSC demonstrate abnormal speech sound processing. Atypicalities are detectable as early as 6 months of age and may represent precursors to long-term language delay. Electrophysiological assessments provide a precise examination of neural processing in SSC and hold potential as a future modality to examine the effects of surgical treatment on brain development.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The cognitive behavioural (CB) model of health anxiety proposes parental illness leads to elevated health anxiety in offspring by promoting the acquisition of specific health beliefs (e.g. overestimation of the likelihood of illness). Our study tested this central tenet of the CB model. Participants were 444 emerging adults (18-25-years-old) who completed online measures and were categorized into those with healthy parents (n = 328) or seriously ill parents (n = 116). Small (d = .21), but significant, elevations in health anxiety, and small to medium (d = .40) elevations in beliefs about the likelihood of illness were found among those with ill vs. healthy parents. Mediation analyses indicated the relationship between parental illness and health anxiety was mediated by beliefs regarding the likelihood of future illness.\nQuestion: Linking Illness in Parents to Health Anxiety in Offspring: Do Beliefs about Health Play a Role?",
    "gt": "Our study incrementally advances knowledge by testing and supporting a central proposition of the CB model. The findings add further specificity to the CB model by highlighting the importance of a specific health belief as a central contributor to health anxiety among offspring with a history of serious parental illness.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Pyelectasis can be defined as mild to moderate dilatation of the urinary tract and is diagnosed by means of an ultrasound scan (0.5-2cm transverse diameter in the initial ultrasound performed after birth). There is some disagreement about whether cystography should be indicated as standard practice. The aim of this study was to establish if renal function tests are useful in determining which cases of mild to moderate dilatation of the urinary tract do not require an initial cystography. The study was conducted on 79 infants (57 males, 22 females) with pyelectasis. Seventy-three were diagnosed in utero and 6 after birth. All infants underwent at least one cystography and one desmopressin urine concentration test before one year of age. Compared to infants without vesicoureteral reflux (VUR) (n=68), infants with VUR (n=11; two with Grade I, three with Grade II, five with Grade III, two with Grade IV) showed a significantly lower (P=.006) maximum urine osmolality and a significantly higher microalbumin/creatinine ratio (P<.001) and NAG/creatinine ratio (P=.003). The negative predictive value of the first two tests was 93%. Sensitivity of the maximum urine osmolality to detect VUR was 72.7% (specificity 63.2%). Sensitivity of the microalbumin/creatinine ratio to detect VUR was 62.5% (specificity 75%). The positive probability ratio (PR) was 1.29 for the NAG/creatinine ratio, 2.03 for the maximum urine osmolality and 2.5 for the microalbumin/creatinine ratio. The negative PR was 0.95 for the NAG/creatinine ratio, 0.43 for the maximum urine osmolality and 0.5 for the microalbumin/creatinine ratio.\nQuestion: Should a cystography be performed on all breastfeeding infants with mild to moderate dilatation of the urinary tract?",
    "gt": "Pyelectasis is a benign condition. Only 2 patients required pharmacological intervention (prophylactic treatment for VUR Grade IV patients). Initially at least, cystography should not be indicated in cases of microalbuminuria and/or normal urine concentrations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Drug therapy can improve patients' quality of life and health outcomes; however, underuse, overuse and inappropriate use of drugs can occur. Systematic examination of potential opportunities for improving prescribing and medication use is needed. To convene a diverse group of stakeholders to learn about and discuss advantages and limitations of data sources, tools and methods related to drug prescribing indicators; foster methods to assess safe, appropriate and cost-effective prescribing; increase awareness of international organizations who develop and apply performance indicators relevant to Canadian researchers, practitioners and decision-makers; and provide opportunities to apply information to the Canadian context. Approximately 50 stakeholders (health system decision-makers, senior and junior researchers, healthcare professionals, graduate students) met June 1-2, 2009 in Halifax, Canada. Four foundational presentations on evaluating quality of prescribing were followed by discussion in pre-assigned breakout groups of a prepared case (either antibiotic use or prescribing for seniors), followed by feedback presentations. Many European countries have procedures to develop indicators for prescribing and quality use of medicines. Indicators applied in diverse settings across the European Union use various mechanisms to improve quality, including financial incentives for prescribers.\nQuestion: Prescribing indicators: what can Canada learn from European countries?",
    "gt": "Further Canadian approaches to develop a system of Canadian prescribing indicators would enable federal/provincial/territorial and international comparisons, identify practice variations and highlight potential areas for improvement in prescribing, drug use and health outcomes across Canada. A more standardized system would facilitate cross-national research opportunities and enable Canada to examine how European countries use prescribing indicators, both within their country and across the European Union.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether intrauterine growth retardation associated with normal umbilical artery blood flow is a benign condition. A prospective comparative study of growth retarded fetuses with normal and abnormal umbilical artery blood flow. The fetal assessment clinic of a large maternity hospital in Ireland. 179 Women with singleton pregnancies in which the fetal abdominal circumference, measured by ultrasonography, was below the fifth centile for gestation. Perinatal deaths, fetal distress requiring caesarean section, preterm delivery, cerebral irritation. Of 124 fetuses with normal flow, all physically normal fetuses survived but one baby had cerebral irritation; there were six preterm deliveries and four caesarean sections for fetal distress. Among 55 women with abnormal flow there were two midtrimester abortions, three perinatal deaths, and one case of cerebral irritation in physically normal fetuses.\nQuestion: Is intrauterine growth retardation with normal umbilical artery blood flow a benign condition?",
    "gt": "Intrauterine growth retardation associated with normal umbilical blood flow is a different entity from that associated with abnormal flow, normal flow being largely benign and abnormal flow carrying a serious risk of adverse outcome.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although posterior wall of left atrium (LA) is known to be arrhythmogenic focus, little is known about the effect of posterior wall isolation (PWI) in patients who undergo radiofrequency catheter ablation (RFCA) for persistent atrial fibrillation (PeAF). We randomly assigned 120 consecutive PeAF patients to additional PWI [PWI (+), n=60] or control [PWI (-), n=60]groups. In all patients, linear ablation was performed after circumferential pulmonary vein isolation (PVI). Linear lesions included roof, anterior perimitral, and cavotricuspid isthmus lines with conduction block. In PWI (+) group, posterior inferior linear lesion was also conducted. Creatine kinase-MB (CK-MB) and troponin-T levels were measured 1day after RFCA. LA emptying fraction (LAEF) was assessed before and 12 months after RFCA. A total of 120 subjects were followed for 12 months after RFCA. There were no significant differences between two groups in baseline demographics and LA volume (LAV). The levels of CK-MB and troponin-T and procedure time were not significantly different between the groups. AF termination during RFCA was more frequently observed in PWI (+) than control (P=0.035). During follow-up period, recurrence occurred in 10 (16.7%) patients in PWI (+) and 22 (36.7%) in control (P=0.02). The change in LAEF was not significantly different between the groups. On multivariate analysis, smaller LAV and additional PWI were independently associated with procedure outcome.\nQuestion: Does isolation of the left atrial posterior wall improve clinical outcomes after radiofrequency catheter ablation for persistent atrial fibrillation?",
    "gt": "PWI in addition to PVI plus linear lesions was an efficient strategy without deterioration of LA pump function in patients who underwent RFCA for PeAF.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Ceramic-on-ceramic bearing couples are theoretically attractive in total hip arthroplasty (THA) because of low wear, but concerns regarding ceramic fracture and squeaking have arisen. Improved material properties of newer alumina matrix composite (AMC) materials, known as Delta ceramics, may reduce these risks. In addition, the use of thinner liners and larger femoral heads may be helpful clinically to lower the rate of dislocation. However, limited short-term clinical results are available and intermediate-term effects are unclear.QUESTIONS/ (1) What is the frequency of bearing-related complications (dissociation, fracture, and noise) with ceramic-on-ceramic AMC bearings in cementless THA? (2) What other complications arose in patients treated with these bearings? (3) What are the Harris hip scores (HHS) and survivorship free from reoperation and revision at a minimum of 5 years after cementless THA performed with AMC bearings? Over a 9-month period in 2009, one surgeon performed 125 THAs, of which 100 (80% of the total) were performed with cementless, AMC bearings. During the period in question, the exclusion criteria for this implant were primary THAs with severe acetabular or femoral bone defect and revision THAs. Of these, 94 hips (95%) in 91 patients were available for analysis at a minimum of 5 years (range, 5-6 years), because five patients (six hips) had died. Mean age at the time of arthroplasty was 55 ± 14 years. Prostheses with an identical design and Biolox(®) Delta ceramics were used in all patients. Noise was classified into squeaking, clicking, grinding, and popping. Ceramic fracture, dislocation, and any other complications associated with the use of AMC ceramics were also investigated. Clinical evaluation included the modified HHS preoperatively and at each followup. Survivorship free from reoperation and revision was calculated using the Kaplan-Meier method. Of 91 patients, four developed bearing-related complications, including one with liner dissociation despite initial square seating and three with clicking. No patients had ceramic fractures. A single event of perioperative dislocation occurred in one patient and postoperative periprosthetic fracture occurred in two hips. Mean HHS improved from 56 to 93 points at the final followup (p<0.001). Survivorship at 5 years free from reoperation and revision was 96.8% and 97.9%, respectively.\nQuestion: Do alumina matrix composite bearings decrease hip noises and bearing fractures at a minimum of 5 years after THA?",
    "gt": "Improved material properties combined with the possible use of larger diameter heads make AMC ceramics a promising alternative bearing option with seemingly comparable clinical outcomes reported by others with conventional ceramic bearings. Despite these encouraging results, however, meticulous technical precautions such as square seating and proper impaction in particular should be taken during liner insertion, because we did observe one liner dissociation and several patients with hip noises.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The benefit of concurrent chemoradiotherapy (CCRT) in elderly patients with inoperable esophageal squamous cell carcinoma (SCC) is controversial. This study aimed to assess the efficiency and safety of CCRT in elderly thoracic esophageal cancer patients. Between January 2002 and December 2011, 128 patients aged 65 years or older treated with CCRT or radiotherapy (RT) alone for inoperable thoracic esophageal SCC were analyzed retrospectively (RT alone, n = 55; CCRT, n = 73). No treatment-related deaths occurred and no patients experienced any acute grade 4 non-hematologic toxicities. Patients treated with CCRT developed more severe acute toxicities than patients who received RT alone. The 3-year overall survival (OS) rate was 36.1% for CCRT compared with 28.5% following RT alone (p = 0.008). Multivariate analysis identified T stage and treatment modality as independent prognostic factors for survival. Further analysis revealed that survival was significantly better in the CCRT group than in the RT alone group for patients ≤ 72 years. Nevertheless, the CCRT group had a similar OS to the RT group for patients>72 years.\nQuestion: Is there a benefit in receiving concurrent chemoradiotherapy for elderly patients with inoperable thoracic esophageal squamous cell carcinoma?",
    "gt": "Our results suggest that elderly patients with inoperable thoracic esophageal SCC could benefit from CCRT, without major toxicities. However, for patients older than 72 years, CCRT is not superior to RT alone in terms of survival benefit.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: malnutrition is regarded as a major risk factor for complications and delayed recovery in hospitalised elderly patients. to examine the prevalence of malnutrition in hospitalised elderly patients and evaluate simple clinical screening criteria. To investigate whether malnutrition was related to lack of care from the health care or social welfare system, quality of life and hospital length of stay (LOS). non-acute geriatric hospital. 294 elderly patients admitted for rehabilitation after acute hospital care; 244 patients were available for assessment. questionnaire interview about nutrition, social network and quality of life. Anthropometric and biochemical measurements, assessment of physical and cognitive function, recording of LOS, discharge destination and diagnosis. 126 patients (51.6%) were at risk of malnutrition using the criteria of body mass index<22 kg/m2 and/or weight loss>or=5%/6 months. Poor quality of life in women (P<0.04) and loss of the health of a spouse (P<0.02) correlated with weight loss. No differences were found in patients at risk regarding LOS, discharge destination, or aid from the social welfare system.\nQuestion: Older hospitalised patients at risk of malnutrition: correlation with quality of life, aid from the social welfare system and length of stay?",
    "gt": "this study confirms a high prevalence of malnutrition risk in hospitalised elderly patients. The health care and social welfare system appeared to be unaware of the problem. Poor quality of life in females and loss of the health of a spouse were related to malnutrition risk. The screening variables that were used appeared not to predict hospital length of stay or discharge destination.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A clinical and experimental assessment using human samples of lumbar ligamentum flavum (LF). To identify platelet-derived growth factor-BB (PDGF-BB) expression in hypertrophied LF of patients with lumbar spinal canal stenosis (LSS) and relate it to fibrosis. Recent studies showed that fibrosis in LF hypertrophy was due to accumulation of inflammation-related scar tissue. PDGF-BB participates in scar formation and collagen development in wound healing and fibrosis diseases. However, it is unclear whether PDGF-BB expression is associated with fibrosis of the hypertrophied LF in LSS. In all, 10 patients of LSS was enrolled in this study, while 10 patients of lumbar disc herniation (LDH) as a control group. LF thickness was measured by axial T1-weighted magnetic resonance imaging. Fibrosis was graded and type of collagen was identified. The location and the expression of PDGF-BB were analyzed using immunohistochemical stains, real-time polymerase chain reaction, and Western Blotting. Correlation among LF thickness, fibrosis, and PDGF-BB expression was analyzed. LF thickness was 5.3 ± 1.0 mm (range from 3.9 to 7.5 mm) in the LSS group and 2.8 ± 0.7 mm (range from 1.69 to 3.8 mm) in the LDH group. Obvious fibrosis was observed in all samples of the LSS group, and correlated to LF thickness of the dural, middle, and dorsal layers (P<0.05), respectively. PDGF-BB was detected in the hypertrophied LF, particularly in the dorsal layer. PDGF-BB expression was higher in the LSS group than that in the LDH group (P<0.05), and in the dorsal layer than the dural layer in the LSS group (P<0.05). PDGF-BB mRNA correlated significantly to thickness of LF (r = 0.41) and the severity of fibrosis (r = 0.69) (P<0.05).\nQuestion: Is platelet-derived growth factor-BB expression proportional to fibrosis in the hypertrophied lumber ligamentum flavum?",
    "gt": "A higher PDGF-BB expression existed in the hypertrophied LF of patients with LSS and could be a risk factor of the fibrosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To explore the putative effect of cardiac rehabilitation programs on the 'health-related quality of life' and 'return to work' in pre-retirement patients one year after coronary artery bypass grafting. Of the 2,085 patients aged 45-64 who survived one year after CABG and were Israeli residents, 145 (6.9%) had participated in rehabilitation programs. Of these, 124 (83%) who answered QOL questionnaires were individually matched with 248 controls by gender, age within 5 years, and the time the questionnaire was answered. All patients had full clinical follow-up including a pre-operative interview. The Short Form-36 QOL questionnaire as well as a specific questionnaire were mailed to surviving patients one year after surgery. Study outcomes included the scores on eight scales and two summary components of the SF-36, as well as 'return to work' and 'satisfaction with medical services' from the specific questionnaire. Analysis was done for matched samples. Cardiac rehabilitation participants had significantly higher SF-36 scores in general health, physical functioning, and social functioning. They had borderline significant higher scores in the physical summary component of the SF-36. The specific questionnaire revealed significantly better overall functioning, higher satisfaction with medical care, and higher rate of return to work. While participants in cardiac rehabilitation and their controls were similar in their socio-demographic and clinical profiles, participating patients tended to be more physically active and more fully employed than their controls.\nQuestion: Is participation in cardiac rehabilitation programs associated with better quality of life and return to work after coronary artery bypass operations?",
    "gt": "Rehabilitation participants had a self-perception of better HRQOL, most significantly in social functioning. Our findings of more frequent return to work and higher satisfaction with medical care should induce a policy to encourage participation in cardiac rehabilitation programs after CABG.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The incidental finding of hemangiomas has increased, but the problem of the correct surgical indications of this tumor has yet to be solved. The aim of this work is to establish whether the psychological request of surgery from patients known to have a benign tumor of the liver must be avoided or not. Age, sex, symptoms, estroprogestinic oral therapy, methods of diagnosis, surgical procedures, morbidity, mortality, postoperative hospital stay and follow-up of the patients affected by hepatic hemangioma, observed from 1992 to 2002 in our institution, have been considered. Seventeen patients, with a mean age of 44 years (range 26-72), were hospitalized for hepatic hemangioma, 8 (47%) of them were operated on and 9 (53%) were managed by observation. The operated patients presented various symptoms. One patient was operated on for traumatic rupture of the hemangioma. Non-operated patients were asymptomatic or with slight dyspeptic symptoms not related with the tumor. The first diagnostic radiological examination was ultrasonography (US) in all cases. All lesions were larger than 4cm. The types of surgical procedures were 5 enucleations, and 3 hepatic resections. All operated patients resolved their clinical symptomatology, except two patients that had requested surgery for psychological implications. These patients presented their symptoms again after 2and 3 years of follow-up respectively.\nQuestion: Does the psychological request of the patient justify the surgery for hepatic hemangioma?",
    "gt": "Our results suggest that liver hemangiomas should be operated for symptoms well related to the tumor or for bleeding. Psychological requests from the patients should be avoided every time.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Patients with end-stage renal failure undergoing haemodialysis (HD) are exposed to oxidative stress. Increased levels of malondialdehyde (MDA) were demonstrated in plasma of uraemic patients, indicating accelerated lipid peroxidation (LPO) as a consequence of multiple pathogenetic factors. The aim of our investigation was to examine the role of renal anaemia in oxidative stress in HD patients. MDA and 4-hydroxynonenal (HNE) were measured in three groups of patients undergoing HD: group I comprised eight patients with a blood haemoglobin (Hb)<10 g/dl (mean Hb = 8.1+/-1.3 g/dl), and group II were eight patients with a Hb>10 g/dl (mean Hb=12.4+/-1.9g/dl); none of these 16 patients had been treated with human recombinant erythropoietin (rHuEpo). Group III comprised 27 patients with a mean Hb of 10.5+/-1.6 g/dl after long-term rHuEpo treatment. Mean plasma concentrations of both MDA and HNE were significantly higher (P<0.0001) in all 43 HD patients than in 20 healthy controls (MDA 2.85+/-0.25 vs 0.37+/-0.03 microM, HNE 0.32+/-0.03 vs 0.10+/-0.01 microM). Comparing the three groups, it was shown that HD patients with a Hb<10 g/dl had significantly higher plasma levels of LPO products (MDA 3.81+/-0.86 microM, HNE 0.45+/-0.07 microM) than HD patients with a Hb>10g/dl (MDA 2.77+/-0.58 UM, HNE 0.25+/-0.05 microM), and than HD patients treated with rHuEpo (MDA 2.50+/-0.12 microM, HNE 0.29+/-0.03 microM). Furthermore, an inverse correlation between plasma concentration of LPO products and haemoglobin levels was seen (r=0.62, P<0.0001).\nQuestion: Does long-term treatment of renal anaemia with recombinant erythropoietin influence oxidative stress in haemodialysed patients?",
    "gt": "Radical generation in HD patients might be caused in part by renal anemia itself. Treatment with rHuEpo may decrease radical generation effectively in HD patients due to the increase in the number of red blood cells and blood haemoglobin concentration.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Personality and cognition are often considered as disparate constructs, both in normal individuals and in those with a psychosis. The goal of the present study was to analyze the relationship between dimensions of personality and cognitive performance in individuals with psychosis. Sixty-one consecutively admitted patients with an acute psychotic episode were recruited for this study. Personality was assessed through a semistructured interview with a close relative using the Personality Assessment Schedule. A wide neuropsychological battery was applied, including attentional, executive, memory tasks and global cognition. Assessments took place when symptomatology was in remission. Higher scores on a passive-dependent dimension were significantly associated with poorer memory performance. Similarly, higher levels for a schizoid dimension were significantly associated with poorer executive performance. The results remained significant after partialling out the effect of gender, psychopathological dimensions and drug status.\nQuestion: Are personality traits associated with cognitive disturbance in psychosis?",
    "gt": "It is hypothesized that personality traits and cognitive performance are interrelated domains in psychosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Between December 2011 and November 2013, we enrolled 118 consecutive cases with severe sepsis admitted to ICU in this retrospective study. Levels of C-reactive protein (CRP), NLR, and white blood cell count (WBC) were recorded on admission and patients' renal function was monitored for seven consecutive days. The rate of AKI occurrence 7 days after enrollment was 57.6%. NLR levels were higher in the AKI group (Group 1) than in the non-AKI group (Group 2) on the day of ICU admission (p<0.001). AKI development was independently associated with NLR, Acute Physiology and Chronic Health Evaluation II (APACHE II) and duration of invasive mechanical ventilation (MV) in multivariate logistic regression analysis. The area under the receiver-operating characteristic (ROC) curve of NLR for predicting AKI was 0.986, which was superior to WBC and CRP (p<0.05). The cut-off value of 10.15 for NLR had the highest validity for predicting AKI in patients with severe sepsis. The sensitivity, specificity, negative-predictive value (NPV), and positive-predictive value (PPV), for this cut-off value was 90.2%, 92.9%, 90.4%, and 92.7%, respectively.\nQuestion: Can neutrophil-lymphocyte ratio be independent risk factor for predicting acute kidney injury in patients with severe sepsis?",
    "gt": "NLR is superior to CRP, and WBC for predicting the development of AKI in patients with severe sepsis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Myocarditis is an inflammation of the heart muscle and represents a challenge for diagnosis and treatment. On account of the lack of sensitivity and specificity of routine cardiac tests, there is a need for accurate diagnostic imaging. The aim of this study is to review the role of gated 99Tc-methoxyisobutylisonitrile myocardial perfusion scintigraphy (G-MPS) in the diagnosis and follow-up of the patients with myocarditis in comparison with gallium scintigraphy. Thirteen patients with a clinical diagnosis of myocarditis were included in the study. All underwent rest G-MPS and the images were then evaluated by quantitative perfusion single-photon emission computed tomography and quantitative gated single photon emission computed tomography software program. Visual evaluation of perfusion was performed as well as analysis of motion with thickening function [expressed as summed rest score, summed motion score, and summed thickening score (STS)] with calculation of ejection fraction (EF) and lung-to-heart (L/H) ratio. Eight patients underwent 67Ga scintigraphy. Clinical, echocardiography, and cardiac enzymes (creatinine kinase-MB, myoglobulin, troponin T, brain natriuretic peptide) data were gathered from the patients' charts. Clinical outcome was grouped according to prognosis. Spearman's correlation (SC) test was used for comparison analysis. Myocardial perfusion defects were observed in eight patients. Perfusion defects in the left ventricle involve a mean of 7.25% (range: 1-11%), whereas wall motion abnormality on G-MPS was more prominent, which showed to be a better marker for myocardial inflammation and necrosis. The 67Ga scintigraphy findings were normal in all, but two. The G-MPS EF (33+/-21%) was slightly lower than the echocardiography EF (40+/-15%), but with close correlation (SC coefficient: 0.635). Comparison of scintigraphic findings with clinical parameters showed that summed motion score with G-MPS EF and STS with L/H ratios were highly correlated (0.932 and 0.622, respectively). The maximum brain natriuretic peptide and L/H ratio with STS were highly correlated with the patients' outcomes (SC coefficient: -0.621, 0.821, and 0.579, respectively), as well.\nQuestion: Gated myocardial perfusion scintigraphy in children with myocarditis: can it be considered as an indicator of clinical outcome?",
    "gt": "Tc-methoxyisobutylisonitrile G-MPS is therefore helpful in providing additional diagnostic and prognostic information in patients with myocarditis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Both the material and geometry of a total knee arthroplasty (TKA) component influence the induced periprosthetic bone strain field. Strain, a measure of the local relative deformation in a structure, corresponds to the mechanical stimulus that governs bone remodeling and is therefore a useful in vitro biomechanical measure for assessing the response of bone to new implant designs and materials. A polyetheretherketone (PEEK) femoral implant has the potential to promote bone strains closer to that of natural bone as a result of its low elastic modulus compared with cobalt-chromium (CoCr).QUESTIONS/ In the present study, we used a Digital Image Correlation (DIC) technique to answer the following question: Does a PEEK TKA femoral component induce a more physiologically normal bone strain distribution than a CoCr component? To achieve this, a DIC test protocol was developed for periprosthetic bone strain assessment using an analog model; the protocol aimed to minimize errors in strain assessment through the selection of appropriate analysis parameters. Three synthetic bone femurs were used in this experiment. One was implanted with a CoCr femoral component and one with a PEEK femoral component. The third (unimplanted) femur was intact and used as the physiological reference (control) model. All models were subjected to standing loads on the corresponding polyethylene (ultrahigh-molecular-weight polyethylene) tibial component, and speckle image data were acquired for surface strain analysis using DIC in six repeat tests. The strain in 16 regions of interest on the lateral surface of each of the implanted bone models was plotted for comparison with the corresponding strains in the intact case. A Wilcoxon signed-rank test was used to test for difference at the 5% significance level. Surface analog bone strain after CoCr implantation indicated strain shielding (R2= 0.6178 with slope, β = 0.4314) and was lower than the intact case (p = 0.014). The strain after implantation with the PEEK implant deviated less from the intact case (R2= 0.7972 with slope β = 0.939) with no difference (p = 0.231).\nQuestion: Does a PEEK Femoral TKA Implant Preserve Intact Femoral Surface Strains Compared With CoCr?",
    "gt": "The strain shielding observed with the contemporary CoCr implant, consistent with clinical bone mineral density change data reported by others, may be reduced by using a PEEK implant.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was performed to determine whether the implementation of clinical pathways for patients who undergo major vascular procedures in a community hospital would shorten the length of stay and reduce charges when compared with Medicare standards. Length of stay, hospital costs, and morbidity, mortality, and readmission rates for the four most common vascular diagnosis-related group (DRG) categories at our institution were compared with Medicare standards. The four categories were DRG 005 (extracranial vascular procedures), DRG 110 (aortic and renal procedures), DRG 478 (leg bypass with comorbidity), and DRG 479 (leg bypass without comorbidity). Between May 1, 1994, and June 30, 1996, 112 patients underwent carotid endarterectomy, 42 patients underwent aortic or renal procedures, and 130 patients underwent lower extremity bypass procedures (68% with comorbidity). Only Medicare patients were included because exact cost/reimbursement data were available. No admissions were excluded. The average length of stay was 1.2 days for DRG 005, 6.9 days for DRG 110, and 3.2 and 2.1 days for DRGs 478 and 479, respectively. The average cost savings when compared with the Medicare reimbursement was $4338 for DRG 005, $7161 for DRG 110, $4108 for DRG 478, and $2313 for DRG 479. Readmission was necessary for 9% of peripheral bypass patients. Ten percent of patients in DRG 005 and 86% of patients in DRG 110 needed intensive care, whereas only 2% of patients who underwent complicated bypass procedures did. Ninety percent of carotid endarterectomy patients and 23% of leg bypass patients were discharged on the first postoperative day. There were two postoperative strokes (2%) after carotid surgery. Thirty-three percent of aortic/renal patients had complications that led to care outside the clinical pathway. Twenty-five percent of leg bypass patients required home care to treat open foot wounds. Total inpatient cost savings were $1,256,000 when compared with Medicare reimbursement.\nQuestion: Do clinical pathways for major vascular surgery improve outcomes and reduce cost?",
    "gt": "Clinical pathways significantly improve the length of stay and decrease inpatient charges for major vascular surgical procedures while maintaining high standards of care. Factors that favorably affected the length of stay and hospital charges were outpatient arteriography, same-day admission, early ambulation, physical therapy, home care, use of the intensive care unit on a selective basis, and early discharge. Factors that adversely affected these outcomes were emergency admission, inpatient arteriography, thrombolytic therapy, complications, and the need for dialysis or anticoagulation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Hepatitis C virus (HCV) infection is often clinically silent in haemodialysed (HD) patients and their immune response may modulate liver damage in HCV infection. IL-10 and TGF-beta1 could play a role in this setting as, IL-10 down-regulates hepatic fibrosis, while TGF-beta1 is a pro-fibrotic cytokine.AIM: To evaluate the role of IL-10 and TGF-beta1 in HD/HCV+ patients. 71 HD/HCV+ patients (58 with normal [HD/HCV-N] and 13 with high serum transaminases [HD/HCV-H]), 40 non-uremic patients with chronic hepatitis C (HCV+), 56 HD anti-HCV- patients and 20 healthy volunteers (H). IL-10 and TGF-beta1 serum levels were assessed using ELISA tests. Liver histology was assessed by Ishak's score. IL-10 serum levels were significantly higher in HD patients, both HCV+ (3.7+/-0.4 pg/ml; p<0.01) and HCV- (3.8+/-0.8 pg/ml; p<0.05) than in non-uremic HCV patients (2.3+/-0.4 pg/ml). Among the HD/HCV+ patients, IL-10 serum levels were similar in HD/HCV-N and in HD/HCV-H patients. Among the HD/HCV+ patients, IL-10 serum levels were similar in those with moderate histological damage compared to those with mild damage. TGF-beta1 serum levels were significantly lower in HD patients, both HCV+ (4.6+/-0.9 ng/ml) and HCV- (6.0+/-0.9 ng/ml) than in non-uremic HCV+ patients (8.1+/-1.1 ng/ml; p<0.001 and p<0.01, respectively), but similar to the values found in H (5.3+/-0.9 ng/ml; p=n.s.). No correlation was seen between IL-10 and TGF-beta1 serum levels in any of the groups considered.\nQuestion: HCV infection in haemodialysed patients: a role for serum IL-10 and TGF-beta1 in liver damage?",
    "gt": "Patients on haemodialysis treatment to have high levels of IL-10, which remain high even when patients are anti-HCV+, whereas the opposite is true of TGF-beta1. The cytokine pattern observed in HD patients is compatible with the hypothesis explaining the relatively benign evolution of HCV-related liver disease in HD patients, and has a pathophysiological role.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Thrombocytosis can follow surgery and has occasionally been observed after major orthopaedic surgery. The aim of the present study was to ascertain the platelet count (PLTC) change in patients admitted to a rehabilitation unit after major joint surgery and whether deep venous thrombosis (DVT) and poor outcomes occurred in those who had thrombocytosis. PLTC, red blood cells (RBC), haemoglobin (Hb), fibrinogen, and D-dimers were assessed in patients on admission and at discharge after major joint surgery. Functional outcomes were ascertained using the Barthel Scale (BS), the Functional Independence Measure (FIM) and gait evaluation. Thrombocytosis was considered to have occurred when PLTC was greater than or equal to 500 × 100(9)/L. All subjects with thrombocytosis had ultrasonography to assess DVT occurrence. The patients were divided into \"young\" and \"old\" groups according to an age cut-off of 75 years to investigate potential age-related differences. Two hundred and seventy-five patients were identified and 142 (36 M and 106 F, mean age 77.2 ± 10.7) were enrolled. Seventy-six (53.5%) underwent total hip arthroplasty (THA), 40 (51.1%) underwent hip internal fixation and 26 (18.3%) subjects underwent total knee arthroplasty (TKA). The young and old groups included 60 and 82 patients, respectively. Fifty-nine (42.4%) patients had PLTC above 400 × 100(9)/L. Of these, 28 (20.1%) had thrombocytosis with PLTC above 500 × 100(9)/L, and 15 of them (10.7%) had very high values above 600 × 100(9)/L. Increased levels of fibrinogen and D-dimers were also detected. No subject with thrombocytosis had DVT. Outcome was not affected by PLTC. At discharge, significant improvement in all functional assessments was observed in young compared to old people; gait: 2.9 ± 0.2 vs. 2.2 ± 0.8; BS: 97 ± 6.9 vs. 70.5 ± 25.6; and FIM: 116.4 ± 10.9 vs. 83.6 ± 31.2 (p < 0.004), respectively. BS and FIM mean scores were positively correlated with Hb level.\nQuestion: Thrombocytosis after hip and knee surgery in the rehabilitation setting: is it an occasional phenomenon?",
    "gt": "Elevated PLTC and thrombocytosis were not uncommon in patients after major joint surgery, but no subject developed DVT. Platelet count change did not affect the outcome. Higher age and lower haemoglobin level correlated with poorer functional recovery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We hypothesised that pharmacokinetic factors might go some way to explaining the risk of major gastrointestinal haemorrhage with non-steroidal anti-inflammatory drugs (NSAIDs), with bleeders exhibiting a reduced clearance of NSAIDs compared with non-bleeders and set out to investigate this. Fifty patients presenting to hospital with acute gastrointestinal bleeding while taking piroxicam, indomethacin, diclofenac or naproxen and age, sex, musculoskeletal disease and drug matched community dwelling controls, up to two for each index case, who had not bled were recruited. Clinical details including duration of therapy were recorded. Bleeders discontinued the implicated NSAID at presentation, controls at least five half-lives before the study. Bleeders were contacted by letter 1 month after discharge and invited to take part and were studied after a median delay of 5 months. Subjects received an oral dose of their respective NSAID and venous blood was sampled, over a period determined by the half-life of the NSAID. Plasma concentrations were determined by high performance liquid chromatography. The median length of treatment for the index patients was 1 year (range 2 weeks--28 years) and for the control patients 2 years (1 month--25 years), P<0.0005. There were no significant differences in peak plasma concentration, time to peak plasma concentration or area under the plasma concentration-time curve between bleeders or controls for any of the NSAIDs studied, apart from piroxicam Cmax being lower in bleeders at 2.07 mg l(-1) than in controls at 3.21 mg l(-1), mean difference (95% CI) -1.14 (-1.83 - -0.48), P<0.005.\nQuestion: Are altered pharmacokinetics of non-steroidal anti-inflammatory drugs (NSAIDs) a risk factor for gastrointestinal bleeding?",
    "gt": "The data failed to support the hypothesis that reduced clearance of NSAIDs, which results in higher plasma concentrations, is a risk factor for acute gastrointestinal haemorrhage.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the clinical features, regularly associated microorganisms and their susceptibility to antibiotics, and the clinical outcomes of foot ulcers in patients with diabetes at the Yaoundé Central Hospital, Cameroon. A retrospective analysis of routinely collected hospital data, and data validation by survey of clinical notes was conducted from November 1999 to October 2002 for adult diabetic patients with foot ulcers. Clinical data were recorded for each patient, followed by a record of microbiological investigations where available. Of 503 patients with diabetes admitted during the study period, 54 (10.7%) had foot ulcers. Male subject represented 66.7% of this population. The mean age of the study population was 59.66 +/- 1.52 years. The foot ulcer led to the diagnosis of diabetes in six patients in whom the condition was previously unidentified. Of the 54 patients with foot ulcers, nine (16.7%) were selected for surgery and the remaining 45 were managed conservatively. Microbiological investigations were available for 21 patients. Proteus mirabilis was the most frequent microorganism yielded, and was regularly associated with Staphylococcus aureus. All the microorganisms isolated showed high sensitivity to second-generation quinolone antibiotics and were regularly sensitive to aminoglycoside antibiotics. Nine (16.7%) patients died and seven (13%) were discharged at their own request.\nQuestion: Diabetic foot ulcers in Cameroon: can microflora prevalence inform probabilistic antibiotic treatment?",
    "gt": "The mortality rate among our diabetic patients with foot ulcers is high and the combination of second-generation quinolone and aminoglycoside antibiotics can be proposed as a probabilistic antibiotic approach to treating foot infection.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We report the case of a 58-year-old female with clinical, radiological, and histopathological evidence of Rasmussen's encephalitis, representing the oldest confirmed case to date. The patient presented with complex partial seizures characterized by numbness of the left face and staring spells. These progressed to a state of epilepsia partialis continua with jerking of the left face, as well as severe cognitive impairment and loss of all communication. The patient responded well to Intravenous Immunoglobulin (IVIG) therapy despite early complications and with ongoing treatment is living independently with minimal cognitive impairment.\nQuestion: Rasmussen's encephalitis in a 58-year-old female: still a variant?",
    "gt": "This represents the oldest confirmed case of Rasmussen's encephalitis and suggests that this diagnosis should be considered in patients of any age with an appropriate clinical picture. We recommend IVIG as a first line therapy for adult cases of Rasmussen's encephalitis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Indications for operative intervention in the treatment of diverticulitis have become unclear. We hypothesized that surgical treatment for diverticulitis has decreased resulting in proportionately more complicated diverticulitis cases (free perforation and/or abscess). We conducted a retrospective analysis of patients with diverticular disease in the Nationwide Inpatient Sample from 1991 through 2005. We used diagnostic codes to identify all patient discharges with diverticular disease and then determined the proportion of discharges with diverticulitis, perforated disease, diverticular abscess, and surgical treatment. During the study period, 685,390 diverticulitis discharges were recorded. The ratio of diverticulitis discharges increased from 5.1 cases per 1,000 inpatients in 1991 to 7.6 cases per 1,000 inpatients in 2005 (P<0.0001). The proportion of patients who underwent colectomy for uncomplicated diverticulitis declined from 17.9% in 1991 to 13.7% in 2005 (P<0.0.0001). During the same period, the proportion of free diverticular perforations as a fraction of all diverticulitis cases remained unchanged (1.5%). The proportion of diverticular abscess discharges as a fraction of all diverticulitis cases increased from 5.9% in 1991 to 9.6% in 2005 (P<0.0001). Last, we noted a decrease in diverticular perforations and/or abscess treated with colectomy, 71.0% in 1991 to 55.5% in 2005 (P<0.0001).\nQuestion: Is the decline in the surgical treatment for diverticulitis associated with an increase in complicated diverticulitis?",
    "gt": "Despite a significant decline in surgical treatment for diverticulitis, there has been no change in the proportion of patients discharged for free diverticular perforation. There was an increase in diverticular abscess discharges, but this finding was not associated with an increase in same stay surgical treatment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There is accumulating evidence that greater availability of green space in a neighbourhood is associated with health benefits for the local population. One mechanism proposed for this association is that green space provides a venue for, and therefore encourages, physical activity. It has also been suggested that socio-economic health inequalities may be narrower in greener areas because of the equalised opportunity for physical activity green spaces provide. However, research exploring associations between the availability of green space and physical activity has produced mixed results. Limits to the assessment of the type and amount of physical activity which occurs specifically in green space may account for these mixed findings. This observational study was therefore concerned with the extent to which green space is a venue for physical activity and whether this could account for narrower socio-economic health inequalities in greener neighbourhoods. Secondary analysis of cross sectional data on 3679 adults (16+) living in urban areas across Scotland matched with a neighbourhood level measure of green space availability. Associations between green space availability and both total physical activity, and activity specifically within green space, were explored using logistic regression models. Interactions between socio-economic position and physical activity were assessed. All models adjusted for age, sex and household income. The availability of green space in a neighbourhood was not associated with total physical activity or that specifically in green space. There was no evidence that income-related inequalities in physical activity within green space were narrower in greener areas of Scotland.\nQuestion: Is level of neighbourhood green space associated with physical activity in green space?",
    "gt": "Physical activity may not be the main mechanism explaining the association between green space and health in Scotland. The direct effect of perceiving a natural environment on physiological and psychological health may offer an alternative explanation.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although epinephrine is one of the most commonly used vasoconstrictor in association with local anesthesia in dentistry, systemic effects of topical admission of epinephrine for sinus augmentation have not been investigated yet. The purpose of this study was to reveal the safety of epinephrine as a topical vasoconstrictor in sinus augmentation procedures. Forty-three healthy patients who require sinus floor augmentation for dental implant placement were included in this study. Patients were divided into 2 groups according to the application of either epinephrine-soaked cottonoid or saline-soaked cottonoid for sinus floor augmentation, and heart rate, systolic, and diastolic pressures were evaluated and compared before, during, and after the procedure. Although there were changes in heart rate, systolic, and diastolic blood pressures, no statistical significance was observed for neither heart rate nor systolic and diastolic blood pressures (P>0.05).\nQuestion: Does the topical use of epinephrine for sinus floor augmentation affect systemic hemodynamics?",
    "gt": "This study showed that the topical use of 1/100,000 epinephrine ensures efficacy by helping the clinician to elevate the sinus membrane and keeps the changes in systemic hemodynamics within safe limitations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A better prognosis in obese patients has been described in acute coronary syndromes (ACS). However, this evidence is mostly based on retrospective studies and has provided conflicting results. No study reported cause-specific mortality according to body mass index (BMI) in ACS. We aimed to prospectively assess the impact of BMI on mortality and its specific causes in ACS patients. We included non-selected ACS patients admitted in a tertiary care coronary unit, collecting baseline characteristics, management and clinical course. Patients were stratified into five clinically meaningful BMI subgroups of<20, 20-24.9, 25-29.9, 30-35,>35 kg/m(2). The primary outcome was 1 year mortality, its causes and its association with BMI. This association was assessed by the Cox regression method. We included 2040 patients in our study with a mean age of 62.1 years. Low weight patients (BMI<20) were older, with less cardiovascular risk factors, higher prevalence of chronic obstructive pulmonary disease and worse renal function. Mean follow up was 334 days. The unadjusted analysis showed lower all-cause mortality in all subgroups as compared to low weight patients. After adjusting for potential confounders, this association remained significant for patients with a BMI 20-24.9. Cardiac mortality was similar across BMI subgroups. In contrast, the adjusted analysis showed a significantly lower non-cardiac mortality in patients with a BMI 20-24.9, 25-29.9 and 30-35 as compared to low weight patients.\nQuestion: Body mass index and acute coronary syndromes: paradox or confusion?",
    "gt": "Baseline characteristics in ACS patients significantly differ according to their BMI status. The prognostic impact of BMI seems mostly related to extra-cardiac causes in low weight patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The objective of this study is to determine parents' awareness of their children's headaches and to evaluate some of the factors that affect this awareness. The subjects of the study are 2601 children who were diagnosed with headache. Data on the children and the parents was collected using a detailed data form. The diagnosis of headache in children was made on the basis of the criteria of the International Headache Society (IHS). If the parents of a child diagnosed with headache reported that their child had headache, the parent was evaluated to be aware of his/her child's headache. In the statistical analyses, chi-square and binary logistic regression were used. Almost 74% of parents were aware of their children's headache. It was found that migraine type headache, female gender, being the first child of the family, travel sickness of children, the presence of headache history in one of the family members; the number of family members and mother's age are factors that affect the awareness level of parents. It was also revealed that parents who do not work outside are more aware of their children's headache and that educational and financial status do not have any effect on the degree of awareness.\nQuestion: Are parents aware of their schoolchildren's headaches?",
    "gt": "In a city like Mersin, which is economically well developed when compared with the rest of the country, one quarter of the parents are not aware of their children's headache.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: For direct laryngoscopy, we compared midline and left-molar approaches with respect to ease of intubation, using a Macintosh blade. We investigated the relationship between failure of the left-molar approach and preoperative risk factors for difficult intubation. With local ethics committee approval, 200 consecutive adult, nonpregnant patients were included in the study. The demographic data, body mass index, Mallampati modified score, interincisor gap, and mentohyoid and thyromental distances were measured preoperatively. First, the Macintosh blade was inserted using the midline approach, and then optimal external laryngeal manipulation (OELM) was applied. Second, the blade was inserted using the left-molar approach. The glottic views were assessed according to the Cormack-Lehane classification before and after OELM in both approaches. In cases where tracheal intubation failed with the left-molar approach, the midline approach was applied again and endotracheal intubation took place. The grade I glottic view obtained using the midline approach without OELM did not change in 94.3% of the patients with the left-molar approach without OELM; in addition, the grade II glottic view improved to grade I in 52.8% of the patients with the same technique (P<0.001). Although the number of patients with a grade I or II glottic view in the left-molar approach was 197, only 37 patients could be intubated using the left-molar approach. In addition, 59.5% of them were intubated at the second attempt with the left-molar approach, while the incidence of a second attempt was 1.2% with the midline approach (P<0.001). There was no correlation between the preoperative risk factors for difficult intubation and failure of the left-molar approach.\nQuestion: Left-molar approach for direct laryngoscopy: is it easy?",
    "gt": "Difficulty in the insertion of the endotracheal tube limits the efficacy of the left-molar approach. It is not possible to predict the failure of intubation with the left-molar approach by considering the preoperative risk factors.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Psychological interventions show greater efficacy when evaluated with distressed patients. We report on the feasibility of implementing screening for recruiting distressed cancer patients to a randomized controlled trial of problem-solving therapy (PST), characteristics associated with enrolment, and time investment and challenges of implementing screening. Three medical settings implemented screening of patients, directly after cancer treatment (T1) and 2 months later (T2), using Hopkins Symptom Checklist-25 and one question about need for services. Distressed patients indicating need for services were interviewed. Eligible patients were offered the possibility to participate in the trial. Consenting patients were randomized to PST or waitlist. At T1, 366 of 970 screened patients (37%) scored above the cutoff and at T2, 208 of 689 screened patients (30%). At either or both T1 and T2, 423 patients reported distress, of whom 215 indicated need for services. Only 36 (4% of 970) patients consented to trial participation. Twenty-seven patients needed to be screened to recruit a single patient, with 17 h required for each patient recruited. Barriers to screening were time constraints and negative attitudes of oncology staff towards screening.\nQuestion: Is implementing screening for distress an efficient means to  recruit patients to a psychological intervention trial?",
    "gt": "Implementing screening proved inefficient for recruiting distressed cancer patients post-treatment to a randomized controlled trial on PST, with need for services being much less than anticipated. Consecutively screening patients did not result in a sample representative of the larger pool of distressed patients, which may lower generalizability. An adequately powered intervention trial using screening requires a feasibility study establishing recruitment rates and dedicated, funded staff assistance.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Transurethral laser prostatectomy has evolved as a viable alternative for the management of benign prostate enlargement. Since the renaissance of laser prostatectomy with the advent of the holmium:yttrium-aluminum-garnet laser in the 1990s, various lasers and subsequent procedures have been introduced. These techniques can be categorized as vaporizing, resecting, and enucleating approaches. Photoselective vaporization of the prostate (PVP) is dominated by high-power lithium triborate (LBO) crystal lasers (GreenLight XPS). The mainstay of this technique is for the treatment of small to medium prostate volumes whereas enucleating techniques, such as holmium laser enucleation of the prostate and thulium enucleation of the prostate, focus on large-volume glands. In order to perspectively \"delimit\" LBO into the field of large-volume prostates, we developed LBO en bloc enucleation to render it as a competing transurethral enucleating approach. We present a detailed stepwise progressive technique developed in Madrid, Spain, for the complete removal of the transitional zone by vapoenucleation. The steps include exposition of the prostatic capsule by PVP toward the peripheral zone, thereby identifying the anatomical limits of enucleation. Subsequently, the transitional zone is excised in a single bloc and morcellated after its placement into the bladder.\nQuestion: Common trend: move to enucleation-Is there a case for GreenLight enucleation?",
    "gt": "This new GreenLight en bloc enucleation technique allows to treat larger prostates than those previously treated with the PVP technique.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The goal of this study was to examine the reasons for early readmissions within 30 days of discharge to a major academic neurosurgical service. A database of readmissions within 30 days of discharge between April 2009 and September 2010 was retrospectively reviewed. Clinical and administrative variables associated with readmission were examined, including age, sex, race, days between discharge and readmission, and insurance type. The readmissions were then assigned independently by 2 neurosurgeons into 1 of 3 categories: scheduled, adverse event, and unrelated. The adverse event readmissions were further subcategorized into patients readmitted although best practices were followed, those readmitted due to progression of their underlying disease, and those readmitted for preventable causes. These variables were compared descriptively. A total of 348 patients with 407 readmissions were identified, comprising 11.5% of the total 3552 admissions. The median age of readmitted patients was 55 years (range 16-96 years) and patients older than 65 years totaled 31%. There were 216 readmissions (53% of 407) for management of an adverse event that was classified as either preventable (149 patients; 37%) or unpreventable (67 patients; 16%). There were 113 patients (28%) who met readmission criteria but who were having an electively scheduled neurosurgical procedure. Progression of disease (48 patients; 12%) and treatment unrelated to primary admission (30 patients; 7%) were additional causes for readmission. There was no significant difference in the proportion of early readmissions by payer status when comparing privately insured patients and those with public or no insurance (p = 0.09).\nQuestion: Are readmission rates on a neurosurgical service indicators of quality of care?",
    "gt": "The majority of early readmissions within 30 days of discharge to the neurosurgical service were not preventable. Many of these readmissions were for adverse events that occurred even though best practices were followed, or for progression of the natural history of the neurosurgical disease requiring expected but unpredictably timed subsequent treatment. Judicious care often requires readmission to prevent further morbidity or death in neurosurgical patients, and penalties for readmission will not change these patient care obligations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We earlier discovered partial recovery in a patient with autoimmune Addison's disease. The aim of this study was to assess the occurrence of adrenocortical recovery in patients with autoimmune adrenalitis. Cross-sectional study. Twenty-seven adult patients with autoimmune Addison's disease on stable glucocorticoid and mineralocorticoid replacement therapy (RT) attending the Department of Endocrinology of a university teaching hospital were included in this study. Adrenocortical function was assessed by performing an adrenocorticotrophic hormone (ACTH) (250 μg Synacthen) stimulation test (SST) after interruption of current glucocorticoid and mineralocorticoid RT. A normal adrenal response was defined as a serum cortisol concentration ≥500 nm 30 or 60 min after stimulation. Partial recovery was defined as a cortisol concentration ≥100 and ≤500 nm after stimulation. In 17 patients (63%), serum cortisol concentrations remained undetectable 30 and 60 min after the administration of ACTH. None of the remaining 10 participants had a normal response. Only one patient reached a cortisol concentration of 100 nm after 60 min, but this could not be confirmed during a second SST.\nQuestion: Does recovery of adrenal function occur in patients with autoimmune Addison's disease?",
    "gt": "In this cross-sectional study among 27 patients with autoimmune adrenalitis, no new cases of adrenocortical recovery were found.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Depletion of central nervous system catecholamines, including dopamine, can decrease MAC (the minimum alveolar concentration of an inhaled anesthetic required to suppress movement in response to a noxious stimulus in 50% of test subjects); release of central nervous system catecholamines, including dopamine, can increase MAC; and increased free dopamine concentrations in the striatum can decrease MAC. Such findings suggest that dopamine receptors might mediate part of the capacity of inhaled anesthetics to provide immobility in the face of noxious stimulation. We measured the effect of blockade of D2 dopamine-mediated transmission with 0.3 mg/kg or 3.0 mg/kg droperidol on the MAC of cyclopropane, desflurane, halothane, isoflurane, or sevoflurane in rats, and the effect of 3.0 mg/kg droperidol on the dose or concentration of etomidate (an anesthetic known to act principally by enhancing the response of gamma-aminobutyric acid(A) receptors to gamma-aminobutyric acid) required to suppress movement in response to noxious stimulation. Blockade of D2 dopamine-mediated transmission with droperidol does not decrease the MAC of cyclopropane, desflurane, halothane, isoflurane, or sevoflurane or its equivalent for etomidate in rats.\nQuestion: Do dopamine receptors mediate part of MAC?",
    "gt": "These data, plus data from studies by others about D1 dopamine receptors, indicate that dopamine receptors do not mediate the immobility produced by inhaled anesthetics.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Congenic strains of mice are assumed to differ only at a single gene or region of the genome. These mice have great importance in evaluating the function of genes. However, their utility depends on the maintenance of this true congenic nature. Although, accumulating evidence suggests that congenic strains suffer genetic divergence that could compromise interpretation of experimental results, this problem is usually ignored. During coinfection studies with Salmonella typhimurium and Theiler's murine encephalomyelitis virus (TMEV) in major histocompatibility complex (MHC)-congenic mice, we conducted the proper F2 controls and discovered significant differences between these F2 animals and MHC-genotype-matched P0 and F1 animals in weight gain and pathogen load. To systematically evaluate the apparent non-MHC differences in these mice, we infected all three generations (P0, F1 and F2) for 5 MHC genotypes (b/b, b/q and q/q as well as d/d, d/q, and q/q) with Salmonella and TMEV. Infected P0 MHC q/q congenic homozygotes lost significantly more weight (p = 0.02) and had significantly higher Salmonella (p<0.01) and TMEV (p = 0.02) titers than the infected F2 q/q homozygotes. Neither weight nor pathogen load differences were present in sham-infected controls.\nQuestion: Infection-dependent phenotypes in MHC-congenic mice are not due to MHC: can we trust congenic animals?",
    "gt": "These data suggest that these strains differ for genes other than those in the MHC congenic region. The most likely explanation is that deleterious recessive mutations affecting response to infection have accumulated in the more than 40 years that this B10.Q-H-2q MHC-congenic strain has been separated from its B10-H-2b parental strain. During typical experiments with congenic strains, the phenotypes of these accumulated mutations will be falsely ascribed to the congenic gene(s). This problem likely affects any strains separated for appreciable time and while usually ignored, can be avoided with the use of F2 segregants.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the effect of treatment by a cardiologist on mortality of elderly patients with acute myocardial infarction (AMI, heart attack), accounting for both measured confounding using risk-adjustment techniques and residual unmeasured confounding with instrumental variables (IV) methods.DATA SOURCES/ Medical chart data and longitudinal administrative hospital records and death records were obtained for 161,558 patients aged>or =65 admitted to a nonfederal acute care hospital with AMI from April 1994 to July 1995. Our principal measure of significant cardiologist treatment was whether a patient was admitted by a cardiologist. We use supplemental data to explore whether our analysis would differ substantially using alternative definitions of significant cardiologist treatment. This retrospective cohort study compared results using least squares (LS) multivariate regression with results from IV methods that accounted for additional unmeasured patient characteristics. Primary outcomes were 30-day and one-year mortality, and secondary outcomes included treatment with medications and revascularization procedures.DATA COLLECTION/ Medical charts for the initial hospital stay of each AMI patient underwent a comprehensive abstraction, including dates of hospitalization, admitting physician, demographic characteristics, comorbid conditions, severity of clinical presentation, electrocardiographic and other diagnostic test results, contraindications to therapy, and treatments before and after AMI. Patients admitted by cardiologists had fewer comorbid conditions and less severe AMIs. These patients had a 10 percent (95 percent CI: 9.5-10.8 percent) lower absolute mortality rate at one year. After multivariate adjustment with LS regression, the adjusted mortality difference was 2 percent (95 percent CI: 1.4-2.6 percent). Using IV methods to provide additional adjustment for unmeasured differences in risk, we found an even smaller, statistically insignificant association between physician specialty and one-year mortality, relative risk (RR) 0.96 (0.88-1.04). Patients admitted by a cardiologist were also significantly more likely to have a cardiologist consultation within the first day of admission and during the initial hospital stay, and also had a significantly larger share of their physician bills for inpatient treatment from cardiologists. IV analysis of treatments showed that patients treated by cardiologists were more likely to undergo revascularization procedures and to receive thrombolytic therapy, aspirin, and calcium channel-blockers, but less likely to receive beta-blockers.\nQuestion: Does physician specialty affect the survival of elderly patients with myocardial infarction?",
    "gt": "In a large population of elderly patients with AMI, we found significant treatment differences but no significant incremental mortality benefit associated with treatment by cardiologists.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Laparoscopic donor nephrectomy has become the standard of care in many renal transplant centers. Many centers are reluctant to perform right laparoscopic donor nephrectomies, primarily due to concerns about transplanting a kidney with a short renal vein. A retrospective review of 26 right and 24 left consecutive donor nephrectomies and their recipients was performed. Patient demographics, preoperative, perioperative, and postoperative data were recorded and compared. Patient demographics were similar between groups. Multiple vessels were encountered more frequently on the right side (10 vs. 3, p = 0.04) and the donated kidney had lesser preoperative function in the right group as determined by nuclear medicine imaging (46.5% vs. 49.4%, p<0.001). Donor operating times were less in the right group (198 vs. 226 min, p = 0.016). There was no difference in implantation difficulty as demonstrated by similar operative and warm ischemia times. Complication rates were similar between both groups of donors and recipients.\nQuestion: Is right laparoscopic donor nephrectomy right?",
    "gt": "Right laparoscopic donor nephrectomy requires less operating time than, and is associated with similar outcomes for donors and recipients as, left laparoscopic donor nephrectomy. Right laparoscopic donor nephrectomy may be preferable in general and should be considered when multiple renal vessels are present on the left side and/or when preoperative function of the left kidney is greater than the right.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was conducted to determine whether vaccination with the quadrivalent human papillomavirus (HPV) vaccine after loop electrosurgical excision procedure (LEEP) for high-grade cervical intraepithelial neoplasia (CIN2-3) is effective in preventing recurrence of CIN2-3. Between August 2007 and July 2010, 737 patients aged 20-45 years who were diagnosed with CIN2-3 were treated by LEEP and followed. Three hundred and sixty patients were vaccinated with the quadrivalent HPV vaccine after LEEP (vaccination group), and 377 patients were followed without vaccination (non-vaccination group). The vaccination group received the first dose at 1 week after LEEP and the remaining two doses two and six months later. Post-LEEP follow-up was performed at 3, 6, 9, 12, 18, and 24 months during the first 2 years and yearly thereafter. Irrespective of causal HPV type, 36 (4.9%) patients developed recurrence. In the vaccination group (360 patients), 9 patients (2.5%) developed recurrence, whereas 27 patients (7.2%) in the non-vaccination group (377 patients) developed recurrence. In patients infected with HPV of 16 and/or 18 type, 5 patients (2.5%) in the vaccination group (197 patients) and 18 patients (8.5%) in the non-vaccination group (211 patients) developed recurrent disease related to vaccine HPV types (HPV 16 or 18 types) after LEEP (P<0.01). Multivariate analysis showed that no vaccination after LEEP was an independent risk factor for recurrent CIN2-3 (HR=2.840; 95% confidence interval, 1.335-6.042; P<0.01).\nQuestion: Is vaccination with quadrivalent HPV vaccine after loop electrosurgical excision procedure effective in preventing recurrence in patients with high-grade cervical intraepithelial neoplasia (CIN2-3)?",
    "gt": "Vaccination with the quadrivalent HPV vaccine after treatment may be considered in preventing recurrence of CIN2-3.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study the appropriateness of lipid-lowering drugs treatment through four methods of calculating coronary risk (CR). Crossover study. Primary care centre. All patients receiving lipid-lowering drugs. CR was determined for individuals with application criteria by four methods: the simplified Framingham, Dundee-Risk-Disk, modified Sheffield label and Cardiovascular Risk in Primary Care (CVRap). 330 patients followed the treatment, 137 men and 193 women with an average age of 58.8 (SD 10.2). 54.2% received statims, 28.5% clofibrates, 13.6% resins and 3.6% other drugs. 186 patients were included, 75 (22.7%) being excluded because of secondary prevention and the rest because they were not the right age or had no cholesterol data prior to treatment. 38.3% were at high CR according to Framingham, 25.6% according to CVRap, 18.7% according to Dundee-Risk-Disk and 16% according to modified Sheffield. Concordance between these methods was adequate.\nQuestion: Do the patients we treat with hypolipemic drugs have a coronary risk?",
    "gt": "Between 16% and 38.3% of the individuals treated are at high CR. If we also include patients with severe Hypercholesterolaemia and diabetics with Hypercholesterolaemia, this percentage rises to 59.7-73.3%, according to the CR assessment method used.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess the outcome of men presenting with lower urinary tract symptoms (LUTS) associated with large postvoid residual urine volumes (PVR). The study included men presenting with LUTS and a PVR of>250 mL who, because of significant comorbidity, a low symptom score or patient request, were managed conservatively and prospectively, and were followed with symptom assessment, serum creatinine levels, flow rates and renal ultrasonography. Patients were actively managed if there was a history of previous outflow tract surgery, prostate cancer, urethral strictures, neuropathy, elevated creatinine or hydronephrosis. In all, 93 men (mean age 70 years, range 40-84) with a median (range) PVR of 363 mL (250-700) were included in the study and followed for 5 (3-10) years. At presentation, the median maximum flow rate was 10.2 (3-30) mL/s and the voided volume 316 (89-714) mL. The measured PVR remained stable in 47 (51%), reduced in 27 (29%) and increased in 19 (20%) patients; 31 patients (33%) went on to transurethral resection of the prostate after a median of 30 (10-120) months, because of serum creatinine elevation (two), acute retention (seven), increasing PVR (eight) and worsening symptoms (14). Of 31 patients 25 were available for evaluation after surgery; their median PVR was 159 (0-1000) mL, flow rate 18.4 (4-37) mL/s and voided volume 321 (90-653) mL. Symptoms were improved in all but five men. There was no difference in initial flow rate, voided volume or PVR between those who developed complications or went on to surgery and those who did not. Urinary tract infections (UTIs) occurred in five patients and two developed bladder stones.\nQuestion: Is the conservative management of chronic retention in men ever justified?",
    "gt": "Complications such as renal failure, acute retention and UTIs are uncommon in men with large, chronic PVRs. Conservative management for this group of patients is reasonable but outpatient review is prudent. There were no factors that could be used to predict those patients who eventually required surgery.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: An in vivo sheep model was used to investigate the effect of spinal instrumentation on the healing process of posterolateral spinal fusion. To examine the role of spinal instrumentation during the healing process of posterolateral fusion. In long bone fractures, internal fixation improves the union rate but does not accelerate the healing process. Spinal instrumentation also improves the fusion rate in spinal arthrodesis. However, it remains unclear whether the use of spinal instrumentation expedites the healing process of spinal fusion. Sixteen sheep underwent posterolateral spinal arthrodeses at L2-L3 and L4-L5 using equal amounts of autologous bone. One of those segments was selected randomly to be augmented with transpedicular screw fixation (Texas Scottish Rite Hospital spinal system). The animals were killed at 8 weeks or 16 weeks after surgery. Fusion status was evaluated by biomechanical testing, manual palpation, plain radiography, computed tomography, and histology. Instrumented fusion segments demonstrated significantly higher stiffness than did uninstrumented fusions at 8 weeks after surgery. Radiographic assessment and manual palpation showed that the use of spinal instrumentation improved the fusion rate at 8 weeks (47% versus 38% in radiographs, 86% versus 57% in manual palpation). Histologically, the instrumented fusions consisted of more woven bone than the uninstrumented fusions at 8 weeks after surgery. The 16-week-old fusion mass was diagnosed biomechanically, radiographically, and histologically as solid, regardless of pedicle screw augmentation.\nQuestion: Does spinal instrumentation influence the healing process of posterolateral spinal fusion?",
    "gt": "The current study's results demonstrated that spinal instrumentation creates a stable mechanical environment to enhance the early bone healing of spinal fusion.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Measurement of Peak Nasal Inspiratory Flow (PNIF) seems to be a cheap and easily performed method to assess nasal patency. As demonstrated in a previous work, PNIF is influenced by SEX, AGE and HEIGHT. However there is a large degree of between-patient variability in PNIF levels. The purpose of this analysis is to determine whether the measurement of the pulmonary ventilatory capacity, by mean of Peak Expiratory Flow (PEF), enables more precise determination of PNIF. Repeated measurements of PNIF and PEF were performed in 112 volunteers. 100 of these fulfilled the study criteria (55 females and 45 males) and all of them were non-smokers, non-asthmatic, without nose and paranasal sinuses problems, with ages ranging from 15 to 71 years. Statistical analysis was undertaken to determine whether a relationship existed between PNIF and age, sex and height, but which also considered PEF. The data from both experiments were analysed together. In both groups there is a clear tendency for PNIF to increase with PEF. As clearly demonstrated in this work the value of PEF is informative in predicting PNIF and that the larger the value of PEF, the larger the value of PNIF.\nQuestion: Does peak nasal inspiratory flow relate to peak expiratory flow?",
    "gt": "PNIF is a useful method to study nasal patency in both primary and secondary care to aid diagnosis of nasal disease, but low values of PNIF have to be confirmed by a study of the PEF as PNIF low values may be an expression of low ventilatory activity rather than an expression of nasal obstruction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Cyclin E is a protein that plays a key role in the G1 -->S transition of the normal cell cycle. The product of retinoblastoma gene (pRb) is the master regulator of entry into the cell cycle and p21 protein is a cyclin-dependent kinase inhibitor that disturbs the progression through the cell cycle. The expression of these proteins, among many others, is being deregulated in tumorogenesis. The aim of this study was to investigate whether cyclin E, pRb, and p21 can be used as prognostic indicators in gastric cancer. Fifty-six patients with gastric adenocarcinoma, who underwent curative resection, constituted the group of our study. The immunohistochemical expression of cyclin E, pRb, and p21 proteins was examined and correlated with clinical-pathological parameters and survival. Positive cyclin E immunostaining was observed in 23 tumors (41.1%). It was associated with intestinal Lauren classification (P=0.003), nodal infiltration (P=0.0025), size of the tumor>5 cm (P=0.032), and lymphatic (P=0.042) and vascular invasion (P= 0.0029). Nevertheless, the survival of patients with positive cyclin E tumors was not significantly shorter than that of negative patients. Positive pRb immunostaining was found in 24 (42.9%) cases and it was associated with the absence of Helicobacter pylori (P=0.044), whereas positive p21 immunostaining was found in 21 tumors (37.5%) and it was associated with less depth of gastric wall infiltration (P=0.001), the absence of lymphatic (P=0.019) and vascular infiltration (P=0.024), and the absence of liver metastasis (P=0.044). Cyclin E expression was associated with pRb expression (P=0.023), but was correlated inversely with p21 expression (P=0.009). The survival of patients with pRb-positive tumors and the survival of patients with p21-positive tumors were significantly longer than that of negative patients (P= 0.0044 and P<0.001, respectively).\nQuestion: Does the expression of cyclin E, pRb, and p21 correlate with prognosis in gastric adenocarcinoma?",
    "gt": "The expression of cyclin E could not predict the survival in this series of patients with gastric cancer, whereas the expression of pRb and p21 was associated with a favorable prognosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: First-time pass rates on the American Board of Surgery Certifying Examination (ABSCE) have now become one of the standards of excellence to evaluate residency programs. Our residency program started monthly simulated and critiqued (verbal, written, and video) oral examinations (MSCE) in 2003. The current study explores the outcomes of this intervention. We evaluated ABSCE performance of 48 residents who graduated from a large academic/community program between the years 2001 and 2006 though a prospective study with historical controls. Residents were divided into 2 groups: The intervention group comprised the 2003 to 2006 classes, which underwent MSCE; the historical control group spanned the 2001 and 2002 classes, which did not undergo MSCE. Results in the ABSCE were compared between groups using the Fisher exact test. In addition, the intervention group was queried in relation to the most important aspects of the MSCE as a learning experience through a structured questionnaire. A statistically significant improvement (p = 0.038) in ABSCE first-time pass rates was noted in the intervention group. Examinees unanimously asserted they had been helped by the MSCE. Improvements in clinical reasoning and promotion of self-study were the most often cited benefits of the MSCE.\nQuestion: Improving outcomes on the ABS Certifying Examination: can monthly mock orals do it?",
    "gt": "Monthly simulated and critiqued oral examinations improved the first-time pass rate of the American Board of Surgery Certifying Examination. Additional perceived benefits of this intervention included improvements in clinical reasoning and promotion of self-study.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Although disaster simulation trainings were widely used to test hospital disaster plans and train medical staff, the teaching performance of the instructors in disaster medicine training has never been evaluated. The aim of this study was to determine whether the performance indicators for measuring educational skill in disaster medicine training could indicate issues that needed improvement. The educational skills of 15 groups attending disaster medicine instructor courses were evaluated using 13 measurable performance indicators. The results of each indicator were scored at 0, 1 or 2 according to the teaching performance. The total summed scores ranged from 17 to 26 with a mean of 22.67. Three indicators: 'Design', 'Goal' and 'Target group' received the maximum scores. Indicators concerning running exercises had significantly lower scores as compared to others.\nQuestion: Can performance indicators be used for pedagogic purposes in disaster medicine training?",
    "gt": "Performance indicators could point out the weakness area of instructors' educational skills. Performance indicators can be used effectively for pedagogic purposes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether three-dimensional conformal partial breast irradiation (3D-PBI) spares lung tissue compared with whole breast irradiation (WBI) and to include the biologically equivalent dose (BED) to account for differences in fractionation. Radiotherapy treatment plans were devised for WBI and 3D-PBI for 25 consecutive patients randomized on the NSABP B-39/RTOG 0413 protocol at Mayo Clinic in Jacksonville, Florida. WBI plans were for 50 Gy in 25 fractions, and 3D-PBI plans were for 38.5 Gy in 10 fractions. Volume of ipsilateral lung receiving 2.5, 5, 10, and 20 Gy was recorded for each plan. The linear quadratic equation was used to calculate the corresponding dose delivered in 10 fractions and volume of ipsilateral lung receiving these doses was recorded for PBI plans. Ipsilateral mean lung dose was recorded for each plan and converted to BED. There was a significant decrease in volume of lung receiving 20 Gy with PBI (median, 4.4% vs. 7.5%; p<0.001), which remained after correction for fractionation (median, 5.6% vs. 7.5%; p = 0.02). Mean lung dose was lower for PBI (median, 3.46 Gy vs. 4.57 Gy; p = 0.005), although this difference lost significance after conversion to BED (median, 3.86 Gy(3) vs 4.85 Gy(3), p = 0.07). PBI plans exposed more lung to 2.5 and 5 Gy.\nQuestion: Does three-dimensional external beam partial breast irradiation spare lung tissue compared with standard whole breast irradiation?",
    "gt": "3D-PBI exposes greater volumes of lung tissue to low doses of radiation and spares the amount of lung receiving higher doses when compared with WBI.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Different surgical techniques for pilonidal disease have been described in the literature. In this study, our aim was to evaluate the influence of routine cavity drainage in the Karydakis flap technique. As much as 50 male patients with pilonidal sinus who underwent the Karydakis flap operation were evaluated prospectively.The patients were assigned randomly into two groups (Group 1 with suction drain; Group 2 fibrin glue). Fluid collection was encountered in 8 out of 50 patients (6.25%): 6 in Group 2 (24%) of which 4 experienced superficial, healed with simple dressing, the other 2 with substantial dehiscence healed with wound dressing; 2 in Group 1 (8%) were treated with wound punctures.There has been no recurrence in any of the patients during the follow-up period.The Karydakis flap operations can be performed with a near zero recurrence rate with the use of drains.\nQuestion: Are postoperative drains necessary with the Karydakis flap for treatment of pilonidal sinus?",
    "gt": "We recommend the use of fibrin sealant with Karydakis flap procedure, but further studies are needed to confirm this conclusion.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Preoperative core needle biopsies may increase the risk of surgical site infection (SSI) in breast cancer surgery. The purpose of this randomized trial was to determine whether a prophylactic antibiotic would prevent SSI under these conditions. Imaging-guided multiple core needle biopsies were performed one to two weeks prior to surgery to obtain confirmation of the presence of breast cancer. Then the patients were randomized to receive either a single intravenous dose of 1.0 g of dicloxacillin (n = 144) or placebo infusion of saline (n = 148) 30 min prior to operation. After breast surgery, incisional morbidity was monitored for 30 days. The number of SSIs was compared with that in 672 patients treated before the implementation of core needle biopsies. The patient characteristics and risk factors for SSI were similar in the antibiotic prophylaxis and placebo groups. The incidence of SSI was 7.2% (21/292) in the prospective trial compared with 6.8% (46/672) in the retrospective cohort (p = 0.890). The incidence of postoperative SSIs was 5.6% (8/144) in the dicloxacillin group and 8.8% (13/148) in the placebo group (p = 0.371). For the first two weeks, there was a non-significant trend to fewer SSIs in the antibiotic group (n = 1) than the placebo group (n = 4). Body mass index, smoking, or previous illness did not affect the likelihood of SSI.\nQuestion: Does preoperative core needle biopsy increase surgical site infections in breast cancer surgery?",
    "gt": "Core needle biopsy did not increase the incidence of SSI. Antibiotic prophylaxis did not prevent SSI, probably because so few infections occurred.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: An institutional ethical review board approved the case-control study carried out at the Gazi University, Faculty of Dentistry, Turkey. A total of 80 patients with traumatic dental injuries and 80 patients with other dental problems participated in the study. Patients' parents filled in two scales: Conners' Rating Scales-Revised Attention Deficiency Hyperactive Disorder-Index, Oppositional Behavior, Hyperactivity, Anxious-Shy, Social Problems, Inattentive and Hyperactive-Impulsive subscales; and Emotion Regulation Checklist, with two subscales of Emotional Lability and Emotion Regulation. Multiple logistic regression analyses were performed separately for male and female patients. Oppositional behaviour, hyperactivity and social problems were found to be risk factors for male patients. Being anxious/shy was the protective factor for both males and females. Classification accuracy for males and females were calculated to be 79.2% and 85.2% respectively.\nQuestion: Are behaviour risk factors for traumatic dental injuries in childhood different between males and females?",
    "gt": "Several risk factors for childhood traumatic dental injuries were found to differ for male and female patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Statins have a well-established role in prevention of vascular events but are associated with muscle-related adverse events. The dose relationship with these adverse events is unclear. We present an original analysis of Canadian and US case reports of statin-associated rhabdomyolysis with a focus on dose response. A typical clinical case is also summarized. All cases of statin-associated rhabdomyolysis reported to Health Canada's Canadian Vigilance Program and to the US Food and Drug Administration's Adverse Event Reporting System from 2004-2008 were analyzed by severity and dose equivalence. Canadian national statin utilization data from 2002-2007 were used to estimate the dose-related incidence of rhabdomyolysis corrected for levels of utilization. The clinical case illustrates well the potential severity of statin-induced rhabdomyolysis. Combined Canadian/US data revealed an average of 812 cases of statin-induced rhabdomyolysis reported annually with a mean patient age of 64.4 years (35.5% female). The worst outcomes reported were renal dysfunction in 17.0%, acute renal failure in 19.8%, dialysis in 5.2%, and death in 7.6%. Using 10 mg atorvastatin per day as the reference dose, the odds ratios of rhabdomyolysis were 3.8 (95% CI 2.3-6.6) for 40 mg/day atorvastatin dose equivalent and 11.3 (95% CI 6.4-20.4) for 80 mg/day atorvastatin dose equivalent.\nQuestion: Statin-associated rhabdomyolysis: is there a dose-response relationship?",
    "gt": "The results of our adverse drug analysis suggest a dose-response relationship. Given the widespread use of statins, the ability to predict which patients will experience serious muscle-related harm is a research priority.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Issues around end-of-life health care have attracted increasing attention in the last decade. One question that has arisen is whether very elderly individuals receive overly aggressive treatment at the end of life. The purpose of this study was to address this issue by examining whether health care use at the end life varies by age. The study included all adults 65 years old or older who died in Manitoba, Canada in 2000 (N = 7678). Measures were derived from administrative data files and included location of death, hospitalizations, intensive care unit (ICU) admission, long-term care (LTC) use, physician visits, and prescription drug use in the last 30 days versus 180 days before death, respectively. Individuals 85 years old or older had increased odds of being in a LTC institution and also dying there than did individuals 65-74 years old. They had, correspondingly, lower odds of being hospitalized and being admitted to an ICU. Although some statistically significant age differences emerged for physician visits, the effects were small. Prescription drug use did not vary by age.\nQuestion: Health care use at the end of life among older adults: does it vary by age?",
    "gt": "These findings indicate that very elderly individuals tended to receive care within LTC settings, with care that might be considered aggressive declining with increasing age. However, health care use among all age groups was substantial. A critical issue that needs to be examined in future research is how to ensure quality end-of-life care in a variety of clinical contexts and care settings for individuals of all ages.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There are many risk classification schemes that determine both treatment and outcome for patients with papillary thyroid cancer. Most of these formulas often utilize tumor size as the key predictor of outcome. Furthermore, there is no clear consensus regarding the treatment of small papillary cancers. Therefore, we reviewed our experience in order to determine which factors best predict outcome for papillary thyroid cancer. In addition, we sought to establish a tumor size threshold beyond which papillary cancers require treatment. From May 1994 to October 2004, 174 patients underwent surgery for papillary thyroid cancer (PTC) at our institution. These patients were divided into five groups based on tumor size. The data from these groups were analyzed utilizing ANOVA, Chi-square and linear regression analysis. The mean age of the patients was 42 +/- 1 years and 126 (72%) were female. Mean tumor size was 17.2 +/- 1.1 mm. The overall outcome was quite good with a survival rate of 97% and a recurrence rate of 12%. On univariate analysis, there was no difference amongst the groups in regards to age or gender. However, there was a significantly higher incidence of lymph node metastasis amongst those with the largest tumors. Consequently, those patients with the largest tumors were treated more aggressively, with 75% undergoing total thyroidectomies and 85% receiving radioactive iodine therapy. However, on univariate and multivariate analysis, tumor size was not shown to correlate with higher recurrence. Rather, the only factor associated with a greater recurrence rate was the presence of lymph node metastases.\nQuestion: Is tumor size the best predictor of outcome for papillary thyroid cancer?",
    "gt": "At our institution, the recurrence rates for PTC were similar for all sizes of tumors. Furthermore, presence of metastatic disease at the time of diagnosis, rather than tumor size, seems to be a better predictor of recurrence and outcome.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We conducted a community-based study to determine the relationship among night-time frequency, sleep disturbance and general health-related quality of life (GHQL). A total of 2271 participants, men and women, aged 41-70 and randomly selected in three Japanese towns completed a postal questionnaire survey. This questionnaire included: the International Prostate Symptom Score, the overall incontinence score of the International Consultation of Incontinence Questionnaire Short Form for lower urinary tract symptoms, the Pittsburg Sleep Quality Index for sleep problems, the Medical Outcome Study Short Form-8 for GHQL, and medical history of disease, cigarette smoking, and alcohol consumption. A multiple regression model was used for statistical analysis, and P<0.05 was considered significant. Although night-time frequency by itself was closely associated with most aspects of GHQL, this association disappeared in four domains (general health perception, vitality, mental health and emotional role) and in the two summary scores of the Medical Outcome Study Short Form-8 after inclusion of the influence of sleep problems represented by the total score on the Pittsburg Sleep Quality Index. However, three domains (physical function, physical role, and social function) remained significantly associated with night-time frequency. Sleep problems were by far the worst risk factor for the deterioration of GHQL.\nQuestion: Night-time frequency, sleep disturbance and general health-related quality of life: is there a relation?",
    "gt": "Night-time frequency appeared to be associated with GHQL mainly by affecting sleep conditions, a symptom that independently influenced some aspects of GHQL.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Studies of the protective effect of breastfeeding on asthma have not brought unequivocal results, and thus this issue remains controversial. Antibiotic use, known to increase asthma risk, may be involved in this relationship. The objective of this study was to assess the influence of breastfeeding duration on obesity and asthma risk in childhood and to test a mediating role of antibiotic use in infancy. A cross-sectional anthropometric and questionnaire study was conducted on 1,277 schoolchildren 8 years of age. Data on weight status, asthma, breastfeeding duration, antibiotic administration in infancy, socioeconomic status, and lifestyle were analyzed. Multivariate standard and logistic regression and mediation analyses, controlling for confounders, were applied. Total duration of breastfeeding was negatively related to the child's body mass index (p=0.038), fat percentage (p=0.030), and obesity risk (p=0.032). Dropping the variable of antibiotic use from the model made the breastfeeding duration a significant predictor of low asthma risk (p=0.027). Antibiotic treatment mediated the relationship between breastfeeding duration and asthma risk (Sobel's z=-2.61, p=0.009).\nQuestion: Is the Relationship Between Breastfeeding and Childhood Risk of Asthma and Obesity Mediated by Infant Antibiotic Treatment?",
    "gt": "Our findings support protective effects of longer duration of breastfeeding against obesity and asthma. We propose a new mechanism for a relationship between breastfeeding and asthma: shorter breastfeeding compromises infant health and thereby leads to antibiotic treatment, which in turn increases the risk of asthma.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Inguinal hernia repair, hydrocelectomy, and orchidopexy are commonly performed surgical procedures in children. Postoperative pain control is usually provided with a single-shot caudal block. Blockade of the ilioinguinal nerve may lead to additional analgesia. The aim of this double-blind, randomized controlled trial was to evaluate the efficacy of an adjuvant blockade of the ilioinguinal nerve using ultrasound (US) guidance at the end of the procedure with local anesthetic vs normal saline and to explore the potential for prolongation of analgesia with decreased need for postoperative pain medication. Fifty children ages 1-6 years scheduled for unilateral inguinal hernia repair, hydrocelectomy, orchidopexy, or orchiectomy were prospectively randomized into one of two groups: Group S that received an US-guided ilioinguinal nerve block with 0.1 ml x kg(-1) of preservative-free normal saline and Group B that received an US-guided nerve block with 0.1 ml x kg(-1) of 0.25% bupivacaine with 1 : 200,000 epinephrine at the conclusion of the surgery. After induction of anesthesia but prior to surgical incision, all patients received caudal anesthesia with 0.7 ml x kg(-1) of 0.125% bupivacaine with 1 : 200,000 epinephrine. Patients were observed by a blinded observer for (i) pain scores using the Children and Infants Postoperative Pain Scale, (ii) need for rescue medication in the PACU, (iii) need for oral pain medications given by the parents at home. Forty-eight patients, consisting of 46 males and two females, with a mean age of 3.98 (SD +/- 1.88) were enrolled in the study. Two patients were excluded from the study because of study protocol violation and/or alteration in surgical procedure. The average pain scores reported for the entire duration spent in the recovery room for the caudal and caudal/ilioinguinal block groups were 1.92 (SD +/- 1.59) and 1.18 (SD +/- 1.31), respectively. The average pain score difference was 0.72 (SD +/- 0.58) and was statistically significant (P<0.05). In addition, when examined by procedure type, it was found that the difference in the average pain scores between the caudal and caudal/ilioinguinal block groups was statistically significant for the inguinal hernia repair patients (P<0.05) but not for the other groin surgery patients (P = 0.13). For all groin surgery patients, six of the 23 patients in the caudal group and eight of the 25 patients in the caudal/ilioinguinal block group required pain rescue medications throughout their entire hospital stay or at home (P = 0.76). Overall, the caudal group received an average of 0.54 (SD +/- 1.14) pain rescue medication doses, while the caudal/ilioinguinal block group received an average of 0.77 (SD +/- 1.70) pain rescue medication doses; this was, however, not statistically significant (P = 0.58).\nQuestion: Unilateral groin surgery in children: will the addition of an ultrasound-guided ilioinguinal nerve block enhance the duration of analgesia of a single-shot caudal block?",
    "gt": "The addition of an US-guided ilioinguinal nerve block to a single-shot caudal block decreases the severity of pain experienced by pediatric groin surgery patients. The decrease in pain scores were particularly pronounced in inguinal hernia repair patients.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Despite the development of new surgical techniques, the fascial sling procedure remains an important surgical technique for the treatment of female urinary stress incontinence. An advantage of combining it with an additional Burch colposuspension has been suggested. The objective of our study was to evaluate retrospectively selected patients who had undergone a fascial sling procedure with and without Burch colposuspension. Of a total of 390 females who underwent an incontinence operation at our department between 1990 and 1999, 56 patients had had a fascial sling plasty. A total of 50 patients (89 %) were followed for a median of 59.5 months. The median age was 60 years. 56 % of the patients displayed recurrent stress incontinence. The previous operations had been performed via a vaginal approach in 42.9 % and an abdominal approach in 57.1 %. The sling procedure used was that of Narik and Palmrich. Of the 50 patients, 14 had an additional Burch colposuspension. The continence rates (no pads) were for patients with a fascial sling procedure alone 63.9 % and for the combination of both operations 64.4 %. An improvement (1-3 pads) was seen in 27.8 % and 21.4 %, respectively. No changes were seen in 5.6 % and 7.1 % and impairment was seen in 2.7 % and 7.1 %, respectively. After a five-year follow-up, the total patient satisfaction rate was 78 %.\nQuestion: Does a Combined Fascial Sling - Burch Colposuspension Display Advantages over a Fascial Sling alone for Treatment of Urinary Stress Incontinence in Females?",
    "gt": "The fascial sling is effective operative technique for treating female urinary stress incontinence, especially in severe and type III incontinence and in patients who had undergone previous operations for incontinence. The operation is safe and is the only technique that offers controlled overcorrection in desperate cases. An advantage of adding a Burch colposuspension to the fascial sling procedure was not detected in our patient group.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Studies have reported associations between mortality and air pollution, but questions subsist on the identification of susceptible subgroups in the population. We studied individual characteristics that modify the relationship between particulate air pollution and mortality among elderly. We examined 527 nonaccidental deaths (197 cardiorespiratory deaths) among the 1469 subjects from the Personnes Agees QUID cohort in Bordeaux between 1988 and 1997. Air pollution was measured as black smoke by urban monitoring background stations. We used a case crossover approach and calculated odds ratio by conditional logistic regression models. We observed associations between the third lag day and cardiorespiratory mortality for an increase of 10 microg/m3 of black smoke (odds ratio = 1.30, 95% confidence interval: 1.01-1.68).\nQuestion: Do subject characteristics modify the effects of particulate air pollution on daily mortality among the elderly?",
    "gt": "Our results provide insight into factors possibly conferring susceptibility to the acute effect of urban air pollution.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Annual trends in the rate of utilisation of PHI in three different clinical categories were compared with published trends in PHI membership to assess the degree to which PHI membership predicts PHI use in Western Australia. The WA Data Linkage System was used to extract all hospital morbidity records in Western Australia from 1981 to 2001. The adjusted annual incidence rate ratio of hospitalisation as a privately insured patient versus a public (Medicare) patient was estimated using Poisson regression in each clinical category across three age groups in each year. The rate ratios were graphed as segmented trend lines and compared with published data for trends in PHI membership. The most significant changes in the use of PHI versus the public system occurred between 1981 and 1984 overall clinical categories. These changes were consistent with those documented for PHI membership. From 1992 onwards, significant changes in the trend were observed in the surgical clinical category, compared with the medical and obstetric clinical categories. Further, the trend observed in the surgical clinical category at this time was inconsistent with that documented for PHI membership. Between 2000 and 2001, only the surgical clinical category showed a similar change in trend as that documented for PHI membership.\nQuestion: Do marginal changes in PHI membership accurately predict marginal changes in PHI use in Western Australia?",
    "gt": "Between 1981 and 1991 the timing and direction of changes in PHI membership were found to be congruent with that of PHI use in all three clinical categories. However, between 2000 and 2001 trends in PHI membership were only congruent with trends in PHI use in the surgical clinical category. We conclude that investigating marginal changes in PHI membership represents an incomplete method for assessing the effectiveness of policies aimed at reducing the pressure on the public system.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Percutaneous transluminal treatment of a thrombotic vein graft yields poor results. We have previously reported our experience with transluminal percutaneous coronary ultrasound thrombolysis (CUT) in the setting of acute myocardial infarction (AMI). This report describes the first experience with ultrasound thrombolysis in thrombus-rich lesions in saphenous vein grafts (SVGs), most of which were occluded. The patients (n=20) were mostly male (85%), aged 64+/-4 years old. The presenting symptom was AMI in 2 patients (10%) and unstable angina in the rest. Fifteen patients (75%) had totally occluded SVGs. The median age of clots was 6 days (range, 0 to 100 days). The ultrasound thrombolysis device has a 1.6-mm-long tip and fits into a 7F guiding catheter over a 0.014-in guidewire in a \"rapid-exchange\" system. CUT (41 kHz, 18 W,</=6 minutes) led to device success in 14 (70%) of the patients and residual stenosis of 65+/-28%. Procedural success was obtained in 13 (65%) of the patients, with a final residual stenosis of 5+/-8%. There was a low rate of device-related adverse events: 1 patient (5%) had a non-Q-wave myocardial infarction, and distal embolization was noted in 1 patient (5%). Adjunct PTCA or stenting was used in all patients. There were no serious adverse events during hospitalization.\nQuestion: Percutaneous transluminal therapy of occluded saphenous vein grafts: can the challenge be met with ultrasound thrombolysis?",
    "gt": "Ultrasound thrombolysis in thrombus-rich lesions in SVGs offers a very promising therapeutic option.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine the necessity and adequacy of basic science training for urologic oncology training programs. Evaluated whether urology physician scientists are adequately trained in the basic sciences. The current urologic oncology training system does not adequately train physician scientists. We propose a major reform to define, train, and maintain the urology physician scientists.\nQuestion: The hybrid of basic science and clinical training for the urologic oncologist: Necessity or waste?",
    "gt": "Urology physician scientists have played a major role in advancement of urologic oncology. Major reform is necessary, if we wish to continue to successfully train urologic oncology physician scientists.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate trends in the provision of mental health services and financing in Brazil. Data from DATASUS (the Brazilian Unified Health Computerized System) with free access in the web were collected regarding the number of beds, the development of new community centers, the number of mental health professionals, and costs involved from 1995 to 2005. In ten years, the number of psychiatric beds decreased 41% (5.4 to 3.2 per 10,000 inhabitants) while community services have increased nine-fold (0.004 to 0.037 per 10,000 inhabitants). Psychologists and social workers have accounted for three and two-fold, respectively, as much hirings as psychiatrists. Psychiatric admissions accounted for 95.5% of the budget in 1995 and 49% in 2005, and the expenses with community services and medication have increased 15% each. As a whole, the expenses in mental health decreased by 26.7% (2.66 to 1.95 US$ per capita).\nQuestion: Is psychiatric reform a strategy for reducing the mental health budget?",
    "gt": "There has been a clear switch from hospital to community psychiatric care in Brazil, where the system can now provide a diversity of treatments and free access to psychotropics. However, the coverage of community services is precarious, and the reform was not accompanied by an increased public investment in mental health. The psychiatric reform is not a strategy for reducing costs; it necessarily implies increasing investments if countries decide to have a better care of those more disadvantaged.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Chronic calcineurin inhibitor (CNI) nephrotoxicity is associated with histologic kidney lesions, but the contribution of maintenance-dose CNI use to the decline over time in glomerular filtration rate (GFR) post liver transplantation (OLT) remains unclear. We studied annual changes in estimated GFR>1 year posttransplant among 105 CNI-treated adult OLT patients with a GFR of 60-100 mL/min at 1 year during a mean follow-up of 7 years (20 years in 20 patients). The annual GFR decline>1 year posttransplant was 0.2 mL/min per year (SD 3.8). This decline rate was unaffected by the decade of OLT, follow-up period, or GFR at 1 year, and showed no correlation with CNI blood levels. Of the 13 (12%) patients with a GFR deterioration>3 mL/min per year, 77% presented with hypertension, diabetes, and/or dyslipidemia. The decline in GFR>1 year post-OLT did not exceed the decline of 0.5-0.8 mL/min per year reported in the general population. Declines faster than 3 mL/min per year, which occurred no more frequently among patients than in the general population, seemed attributable to coexistent vascular risk factors.\nQuestion: Long-term renal function deteriorates at a similar rate among liver transplant patients with preserved renal function at 1 year and in the general population: is chronic calcineurin inhibitor nephrotoxicity overrated?",
    "gt": "Among OLT patients with preserved renal function at 1 year posttransplant, our findings challenge the clinical impact of chronic progressive CNI nephrotoxicity and highlight the importance of a tight control of blood pressures, glucose and lipid levels, and other modifiable risk factors in order to preserve long-term renal function.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Childhood-onset schizophrenia (COS) is a severe form of the adult-onset disorder with a high rate of premorbid developmental abnormalities. Early symptoms of pervasive developmental disorder (PDD) have been reported in five independent studies of COS. In this study, we compared evidence for premorbid PDD as a nonspecific manifestation of impaired neurodevelopment seen in schizophrenia, or as an independent risk factor for COS. Diagnosis of past or current autism or PDD was made according to the DSM-IV criteria. COS patients with and without PDD were compared with respect to neuropsychological, clinical, and neurobiological measures. Several candidate genes for autism were examined in the entire COS sample and the subgroup with PDD using the Transmission Disequilibrium Test (TDT) and Quantitative TDT (QTDT). Nineteen (25%) of COS probands had a lifetime diagnosis of PDD: one met criteria for autism, two for Asperger's disorder, and 16 for PDD not otherwise specified. Premorbid social impairment was most common feature for COS-PDD subjects. The PDD group did not differ from the rest of the COS sample with respect to age of onset, IQ, response to medications, and rate of familial schizotypy. Unexpectedly, two siblings of COS-PDD probands met criteria for nuclear autism. There was no difference between PDD and non-PDD groups with respect to initial brain magnetic resonance imaging (MRI) measures. However, rate of gray matter loss was greater for PDD (n = 12) than for the non-PDD (n = 27) subgroup (-19.5 +/- 11.3 mL/year vs. -9.6 +/- 15.3 mL/year; p =.05). None of eight candidate genes for autism were associated with COS or COS-PDD.\nQuestion: Pervasive developmental disorder and childhood-onset schizophrenia: comorbid disorder or a phenotypic variant of a very early onset illness?",
    "gt": "Premorbid PDD in COS is more likely to be a nonspecific marker of severe early abnormal neurodevelopment. However, the occurrence of two siblings of COS-PDD probands (17%) with nuclear autism remains to be understood.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Until recently, liver transplantation (Ltx) was the only available treatment for hereditary transthyretin (TTR) amyloidosis; today, however, several pharmacotherapies are tested. Herein, we present survival data from the largest available database on transplanted hereditary TTR patients to serve as a base for comparison. Liver transplantation was evaluated in a 20-year retrospective analysis of the Familial Amyloidosis Polyneuropathy World Transplant Registry. From April 1990 until December 2010, data were accumulated from 77 liver transplant centers. The Registry contains 1940 patients, and 1379 are alive. Eighty-eight Ltx were performed in combination with a heart and/or kidney transplantation. Overall, 20-year survival after Ltx was 55.3%. Multivariate analysis revealed modified body mass index, early onset of disease (<50 years of age), disease duration before Ltx, and TTR Val30Met versus non-TTR Val30Met mutations as independent significant survival factors. Early-onset patients had an expected mortality rate of 38% that of the late-onset group (P<0.001). Furthermore, Val30Met patients had an expected mortality rate of 61% that of non-TTR Val30Met patients (P<0.001). With each year of duration of disease before Ltx, expected mortality increased by 11% (P<0.001). With each 100-unit increase in modified body mass index at Ltx, the expected mortality decreased to 89% of the expected mortality (P<0.001). Cardiovascular death was markedly more common than that observed in patients undergoing Ltx for end-stage liver disease.\nQuestion: Liver Transplantation for Hereditary Transthyretin Amyloidosis: After 20 Years Still the Best Therapeutic Alternative?",
    "gt": "Long-term survival after Ltx, especially for early-onset TTR Val30Met patients, is excellent. The risk of delaying Ltx by testing alternative treatments, especially in early-onset TTR Val30Met patients, requires consideration.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This is a population-based study for which 1,414 diabetics were recruited. The fundi were photographed using 45-degree 4-field stereoscopic digital photography. The diagnosis of DR was based on Klein's classification of the Early Treatment Diabetic Retinopathy Study scales. The prevalence of DR was 33.3% (95% confidence interval, CI: 26.6-39.9) in known onset of diabetes (≤ 40 years) compared to 15.6% (95% CI: 13.6-17.6) in those with late onset (>40 years; p<0.0001). In the group with age of known onset of diabetes ≤ 40 years, the risk factors, associated with any DR, were poor glycemic control (odds ratio, OR: 1.36 for every g% increase in glycosylated hemoglobin), insulin use (OR: 4.21), increasing known duration of diabetes (OR: 1.10 for increase of every year in known duration of diabetes) and presence of macroalbuminuria (OR: 13.39). In the late onset of diabetes group, besides the above-mentioned risk factors, the presence of microalbuminuria (OR: 2.08), male gender (OR: 1.67), presence of anemia (OR: 1.89) and increased systolic blood pressure (OR: 1.01) were the risk factors for DR.\nQuestion: Is prevalence of retinopathy related to the age of onset of diabetes?",
    "gt": "The prevalence of DR was almost twice more in those subjects who developed diabetes before the age of 40 years than those who developed it later.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Functional MRI (fMRI) of default mode network (DMN) brain activity during resting state is gaining attention as a potential non-invasive biomarker to diagnose incipient Alzheimer's disease. The aim of this study was to identify effects of normal aging on the DMN using different methods of fMRI processing and evaluation. fMRI was acquired in 17 young and 21 old healthy subjects and the data were analyzed with (a) volumes of interest (VOI)-based signal time course and (b) independent component analyses (ICA). In the first approach, the strength of DMN region inter-connectivity (as expressed with correlation coefficients) was of primary interest, the second method provided a measure of the magnitude of DMN co-activation. The older subjects exhibited significantly lower DMN activity in the posterior cingulate (PCC, t-test P<.001) as well as a tendency to lower activity in all other DMN regions in comparison to the younger subjects. We found no significant effect of age on DMN inter-connectivity.\nQuestion: Effects of aging on default mode network activity in resting state fMRI: does the method of analysis matter?",
    "gt": "Effects of normal aging such as loss of PCC co-activity could be detected by ICA, but not by signal time course correlation analyses of DMN inter-connectivity. This either indicates lower sensitivity of inter-connectivity measures to detect subtle DMN changes or indicate that ICA and time course analyses determine different properties of DMN co-activation. Our results, therefore, provide fundamental knowledge for a potential future use of functional MRI as biomarker for neurodegenerative dementias where diminished DMN activity needs to be reliably differentiated from that observed in health aging.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Because of the penetrating ability of the radiation used in nuclear medicine, metallic lead is widely used as radiation shielding. However, this shielding may present an insidious health hazard because of the dust that is readily removed from the surfaces of lead objects. The lead dust may become airborne, contaminate floors and other nearby surfaces, and be inadvertently inhaled or ingested by patients. We determined if the quantity of lead dust encountered within nuclear medicine departments exceeded Environmental Protection Agency (EPA) standards. For lead dust quantification, professional lead test kits were used to sample fifteen 1-ft(2) sections of different surfaces within the department. Four samples were collected once per week from each site. The samples were then submitted to a National Lead Laboratory-accredited program for a total lead measurement. Lead contamination (mug/ft(2)) for each of the 60 samples was compared with the EPA standards for lead dust. Lead contamination was present at 6 of the 15 sites, and of 60 samples, 18 exceeded the EPA standard of 50 mug/ft(2).\nQuestion: Is lead dust within nuclear medicine departments a hazard to pediatric patients?",
    "gt": "Lead contamination is present within nuclear medicine departments, and corrective measures should be considered when dealing with pediatric patients. A larger series needs to be conducted to confirm these findings.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We examined the changes of mean platelet volume (MPV) and platelet distribution width (PDW) in subjects with appendicitis and whether MPV and PDW could be used to predict the development of complication due to appendicitis. The healthy control group, the cases of appendicitis with perforation, and the cases of appendicitis without perforation were compared with regard to MPV and PDW. We determined whether MPV and PDW were independent variables predictive of the development of complication in subjects with appendicitis. This retrospective case-control study included a total of 362 patients (249 of which were male (68.8 %) and 113 were female (31.2 %); median age, 30 [range, 18-84 years]). One hundred and ninety-two subjects (53 %) presented with appendicitis and 170 (47 %) comprised the healthy control group. Sixty-six (18.2 %) of the subjects with appendicitis developed complication. MPVs were lower in subjects of appendicitis without complication compared to the subjects of appendicitis with complication and the control group (MPV, 9.78 ± 0.99 vs. 10.20 ± 1.21 and 10.14 ± 1.03, respectively [p = 0.005]). The PDW levels were not different between the three groups. Independent variables predictive of the presence of complication included increased MPV and time from onset of symptoms to hospital presentation (odds ratio[confidence interval], p-value: 1.507[1.064-2.133], 0.021 and 18.887[5.139-69.410], 0.0001, respectively).\nQuestion: Can platelet indices be used as predictors of complication in subjects with appendicitis?",
    "gt": "Our findings suggested these, MPV values in cases of appendicitis without complication were lower than the cases with complication and healthy control and MPV is a predictor of the development of complication in subjects with appendicitis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Prior studies have shown that age ≥70 years is associated with more aggressive non-endometrioid histology and worse survival in endometrial cancer. The purpose of this study is to assess if age is an independent poor prognostic factor in endometrioid histologies. Under an IRB-approved protocol, we identified patients with surgical stage I to II endometrioid endometrial adenocarcinoma from 1995 to 2008 at two institutions. Patients were divided into two groups based on age at diagnosis: Group A (age 50-69 years) and Group B (age≥70 years). All patients underwent hysterectomy, bilateral salpingoophorectomy, +/-pelvic/aortic lymphadenectomy and adjuvant therapy. Prognostic factors were evaluated by univariate and multivariate analyses. We identified 338 patients with stage IA to IIB endometrioid endometrial adenocarcinoma. The median age in Group A was 59 years (range 50-69) and Group B was 75 years (range 70-92). Patients in Group B were more likely to have hypertension (51% vs. 68%, p=0.006) and coronary artery disease (9% vs. 18%, p=0.03). There were no differences in progression-free or disease-specific survival, however, Group B had a worse overall survival (OS) (50.1 vs. 62.6 months, p=0.03). On univariate analysis, age (p=0.04), grade (p=0.006), and coronary artery disease (p=0.01) were associated with worse OS. After adjusting for grade and coronary artery disease, age was no longer a significant variable for OS (p=0.17).\nQuestion: Is older age a poor prognostic factor in stage I and II endometrioid endometrial adenocarcinoma?",
    "gt": "After adjusting for other poor prognostic factors, age ≥70 years alone may not be a significant variable affecting overall survival in patients with early stage endometrioid endometrial adenocarcinoma.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It would be interesting to the emergency doctor to have at his disposal a helpful diagnostic tool like brain natriuretic peptide (BNP). Such assay is simple, available and reliable. To report our experience on the role of BNP in the etiological diagnosis of acute dyspnea (AD) in emergency room (ER) and to assess the cost-effectiveness ratio of such diagnosis strategy. A prospective study conducted in the ER of Rabta university teaching hospital of Tunis, from March 1st to June 20th 2010, involving 30 consecutive patients presenting to the emergency for AD. All patients underwent echocardiography in their acute phase and benefited from the dosage of BNP during the first 4 hours. The echocardiography parameters were collected by a single operator who was unaware of the results of the BNP dosage. The mean age of patients was 72.8years with a sex ratio of 1.5. AD was of orthopnea type in 9 cases and stage III NYHA dyspnea in the other patients. Clinical and radiological signs of left heart failure were noted in 30% of cases. Ultrasound data have objectified systolic dysfunction in 4 cases, diastolic in 3 cases and systolic plus diastolic in 10 cases. The BNP levels were below 100 pg/ml in 10 cases with pulmonary origin of the AD. A BNP level between 100 and 400 pg/ml was noted in 3 cases. In our study, the clinical probability of AHF prior to performing the test was estimated at 53% and estimated at 100% after the BNP assay. The BNP assay has reduced the length of stay in the emergency department 4 to 5 days and saved nearly 50% of the cost of care per patient.\nQuestion: Is BNP assay useful for the diagnosis of acute dyspnea in emergencies departments?",
    "gt": "The BNP assay, has allowed us to confirm the AHF all cases. Given the prognostic value and economic benefit of this test we recommend its use in ER of our country.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Histology has been identified as an important prognostic factor in Hodgkin's disease (HD) in adults. Information regarding the impact of histology on outcome in childhood HD is scarce. This study determines the effect of histology on the overall survival (OS) or progression-free survival (PFS) in a national series of children treated in a standardized manner. The results of treatment of 331 assessable patients, treated between January 1, 1982 and June 30, 1992, in the United Kingdom Children's Cancer Study Group (UKCCSG) Hodgkin's study I were reviewed to evaluate OS, PFS, and deaths according to stage and histology. Treatment was either involved-field radiation alone (stage IA) or chlorambucil, vinblastine, procarbazine, and prednisolone (ChlVPP) chemotherapy with or without mediastinal radiation. All were clinically staged at diagnosis. Nodular sclerosing (NS) HD was the most common histologic subtype (155 of 331 patients [47%]) and was uniformly distributed through all stages. Lymphocyte-depletion (LD) HD was extremely uncommon (<1%). Mixed-cellularity (MC) HD had the highest relapse rate, but this was only significant (P<.05) in stage I patients who received local irradiation alone. There was no other statistically significant difference in OS and PFS between the various histologic subtypes. Multivariate analysis for PFS and OS confirmed that stage was the most important prognostic factor and that histology did not have an effect after stratification by stage.\nQuestion: Does histology influence outcome in childhood Hodgkin's disease?",
    "gt": "This study demonstrates that with effective multiagent chemotherapy, histologic subtype does not influence outcome. The high relapse rates in stage I MC subtype indicates that MC HD is biologically aggressive and systemic treatment with or without local irradiation may be indicated. The high relapse rate in stage IV patients appeared to be independent of histology.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The relationship between the use of alcohol and aggression is complex and represents major public health issues. Delving into the nature of this association is vital, since various underlying factors may contribute to the expression of aggression. This study examined trait aggression by assessing correlates and, subsequently, the unique contribution of alcohol craving, and dysfunctional impulsivity, by means of correlational and mediational analyses. Forty inpatient detoxified alcohol-dependent patients were recruited. These participants completed the Desire for Alcohol Questionnaire (DAQ), Dickman Impulsivity Inventory (DII), and the Aggression Questionnaire (AQ). The findings indicated that aggression, dysfunctional impulsivity, and alcohol craving were all positively intercorrelated. The association between dysfunctional impulsivity and aggression was robust. The mediational analyses yielded that craving partially mediated this relationship, although not very substantial.\nQuestion: Does alcohol craving mediate the impulsivity-aggression relationship in recently detoxified alcohol-dependent patients?",
    "gt": "It was shown that impulsivity, as a personality characteristic, is strongly associated with aggressive behaviors, whereby the impact of craving on the relationship between impulsivity and trait aggression in alcohol-dependent inpatients was weak.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess whether pleural fluid analysis (PFA) can confidently diagnose tuberculous pleural effusion (TPE). PFA of 548 TPEs was performed between January 1991 and December 2011. The control group consisted of patients with malignant PE (MPE), complicated parapneumonic/empyema (infectious) PE (IPE), miscellaneous PE (MisPE) and transudative PE (TrPE). The PFA of 548 histologically or culture-positive consecutive cases of TPE was compared with that of 158 consecutive cases of MPE, 113 cases of IPE, 37 cases of MisPE and 115 cases of TrPE. Statistically significant differences were noted in pleural fluid glucose, pH, cholesterol, triglycerides, adenosine deaminase (ADA), and total percentages of lymphocytes, neutrophils and macrophages when TPEs were compared to all other groups. Of the TPEs, 99.1% were exudates. Pleural fluid protein ≥ 5.0 g/dl, lymphocytes>80% and ADA>45 U/l were diagnostic of TPE, with a specificity of 100%, a sensitivity of 34.9% and an area under the curve of 0.975.\nQuestion: Can tuberculous pleural effusions be diagnosed by pleural fluid analysis alone?",
    "gt": "PFA alone was diagnostic in one third of the TPE cases, with a high probability in nearly 60%.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was aimed at exploring to what extent populations enrolled in randomized controlled trials (RCTs) of inhalation combination treatment for mild/moderate asthma in adults are fully representative of 'real-life' populations. The following is a retrospective analysis of the clinical records of outpatient subjects with an ascertained diagnosis of asthma. A retrospective analysis was performed. Stable conditions, such as smoking habit and chronic diseases other than asthma, were identified as exclusion criteria for RCTs. The selected criteria were then applied to asthmatic outpatients, yielding a population that was potentially eligible for RCTs. Out of 1,909 subjects, 824 (43.2%) met at least one of the exclusion criteria for RCTs. Cigarette smoking (occurring in 34.3% of the entire population), lung diseases other than asthma (5.0%), anxiety and depression (3.3%), arrhythmias (2.3%), and coronary artery disease (1.2%) would have been the most frequent causes for exclusion from RCTs. The proportion of patients excluded from RCTs appears to increase with age, reaching 57.1% in patients aged>85 years.\nQuestion: Are asthmatics enrolled in randomized trials representative of real-life outpatients?",
    "gt": "In a real-life setting,>40% of subjects with mild/moderate asthma are currently treated by protocols based on the results of RCTs for which they would not have been eligible. This proportion increases in elderly patients with comorbidities. These findings limit the generalizability of RCTs and advocate that complementary pragmatic studies be conducted. © 2015 S. Karger AG, Basel.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study assessed the relationship between stress reactivity (trait 1) and psychosis (trait 2) across genetically related persons (cross-twin, cross-trait design) to examine whether stress reactivity is an uncontaminated and unconfounded familial marker of psychosis risk. Reactivity to stress and subclinical psychotic experiences were assessed in 289 female, general population twin-pairs. Cross-trait, within-twin associations investigating the association between stress reactivity and subclinical psychotic experiences in each person, were calculated. In addition, cross-trait, cross-twin associations were calculated to assess whether stress reactivity in one twin was moderated by subclinical psychotic experiences in the co-twin. Cross-trait, within-twin analyses showed significant associations between stress reactivity and subclinical psychotic experiences in each person. In addition, the cross-trait cross-twin analyses showed that stress reactivity in twin 1 was significantly moderated by subclinical experiences in the co-twin.\nQuestion: Does reactivity to stress cosegregate with subclinical psychosis?",
    "gt": "The results suggest that the psychosis phenotype cosegregates with increased emotional reactivity to stress in daily life.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate on a population basis the suggestion that certain factors naturally alter the odds of having a boy or a girl, and that some women are predisposed towards having children of one particular gender. Routine data analysis. Routinely collected data on singleton infants born in Scotland from 1975 to 1988, linked so that births (live and still) to the same mother could be identified. The analyses relate to 549,048 first to fifth order births occurring to 330,088 women whose records were complete from the first delivery onwards. Gender of infant. Of 549,048 births, 51.4% were male. Apart from random variation, the sex ratio of 1.06 remained constant at all birth orders (P = 0.18). The probability of a male infant appeared unrelated to the genders of the preceding siblings (P>0.20 in second to fifth deliveries), and there was no evidence of variation with maternal age (P = 0.31), maternal height (P = 0.69), paternal social class (P = 0.12), maternal social class (P = 0.57), year of delivery (P = 0.84) or season of birth (P = 0.41). Whilst mothers whose children were all the same gender were more likely to continue childbearing than those with children of different genders, there was no evidence that those with daughters were more likely to continue than those with sons.\nQuestion: Sex ratios: are there natural variations within the human population?",
    "gt": "The suggestion that some women have a natural predisposition towards having children of a particular gender is not supported by these data. On a population basis there is no evidence to suggest that gender determination is anything other than a chance process.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Anterior shoulder instability with bone loss can be treated successfully with the modified Bristow procedure. Opinions vary regarding the role of the soft-tissue sling created by the conjoined tendon after transfer. Therefore, the aim of this study was to determine the effect of the modified Bristow procedure and conjoined tendon transfer on glenohumeral translation and kinematics after creating anterior instability. Eight cadaveric shoulders were tested with a custom shoulder testing system. Range-of-motion, translation, and kinematic testing was performed in 60° of glenohumeral abduction in the scapular and coronal planes under the following conditions: intact joint, Bankart lesion with 20% glenoid bone loss, modified Bristow procedure, and soft tissue-only conjoined tendon transfer. A Bankart lesion with 20% bone loss resulted in significantly increased external rotation and translation compared with the intact condition (P < .05), as well as an anterior shift of the humeral head apex at all points of external rotation. Both the modified Bristow procedure and soft-tissue Bristow procedure maintained the increase in external rotation but resulted in significantly decreased translation (P < .05). There was no difference in translation between the 2 reconstructions.\nQuestion: Biomechanical analysis of the modified Bristow procedure for anterior shoulder instability: is the bone block necessary?",
    "gt": "The increase in external rotation suggests that the modified Bristow procedure does not initially restrict joint motion. Translational stability can be restored in a 20% bone loss model without a bone block, suggesting the importance of the soft-tissue sling.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Cardiac troponin I (CTnI) has been shown to be a marker of myocardial injury. The aim of this prospective, randomized study was to compare intermittent antegrade warm cardioplegia with tepid blood cardioplegia in patients undergoing first elective coronary artery bypass graft, using CTnI release as the criterion for evaluating the adequacy of myocardial protection. Seventy patients were randomly assigned to one of two cardioplegia groups. CTnI concentrations were measured in serial venous blood samples drawn immediately before cardiopulmonary bypass and after aortic unclamping at 6, 9, 12, and 24 hours. Analysis of covariance with repeated measures was performed to test the effect of the type of cardioplegia and time on CTnI concentration. The total amount of CTnI released (8.23 +/- 20.5 microg in the warm group and 3.19 +/- 2.4 microg in the tepid group) was not statistically different (p = 0.23). The CTnI concentration did not differ for any sample in either of the two groups when adjusted on ejection fraction and the number of preoperative myocardial infarctions (p = 0.06). No patient in the tepid group versus 4 patients in the warm group showed CTnI evidence of perioperative myocardial infarction (p = 0.12).\nQuestion: Warm and tepid cardioplegia: do they provide equal myocardial protection?",
    "gt": "Our study showed no preference for warm or tepid cardioplegia in terms of myocardial protection, either for clinical or biological data.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Many studies have suggested that general practitioners fail to detect a substantial minority of their patients who are psychologically distressed, and there is concern about the possible sequelae of this. Individual patients may suffer unresolved problems, and there are potential costs to the health service in consequent recurrent consultations, inappropriate referrals or treatment. Educational interventions based on small groups led by facilitators have been shown to alter the consultation behaviours of general practitioners that are known to be related to accurate detection of psychological distress.AIM: This controlled study aimed to show that, by utilizing a brief self-directed educational intervention focusing on detection of psychological distress, general practitioners can improve their performance significantly. For this purpose, a new educational intervention was designed: the second aim of the study was thus to assess the effectiveness of this specific intervention. An educational intervention was designed which focused on skills relevant to detecting psychological distress, using the principles of reflection on general practitioner performance and consultation skill work. It was designed to be used by individual general practitioners without outside support, using a combination of written background material, feedback on performance and analysis of video material. The effectiveness of the intervention was tested by comparing a trial and control cohort of general practitioners, using detection rates as an outcome measure. The detection rate of the general practitioners who underwent the intervention improved significantly compared with their performance before intervention and with that of the control group.\nQuestion: Detecting psychological distress: can general practitioners improve their own performance?",
    "gt": "General practitioners can improve their ability to detect psychological distress in their patients utilizing this self-directed educational approach.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare efficacy and safety of 5% lidocaine medicated plaster with pregabalin in patients with post-herpetic neuralgia (PHN), and to assess the benefits of combining both drugs in patients not responding to either single agent. This was a two-stage adaptive, randomised, open-label, multicentre, non-inferiority study (NCT 00414349). The subset of patients with PHN is reported here. Patients with an absolute value of>4 on the NRS-3 were randomly assigned to 4-week treatment with 5% lidocaine medicated plaster or twice-daily pregabalin capsules titrated to effect. Subsequently, patients sufficiently treated with monotherapy (patients with NRS-3<or=4 at 4 weeks or a reduction on the NRS-3 from baseline of>or=2 points) continued with monotherapy; patients insufficiently treated with monotherapy received both drugs in combination for 8 weeks. Pain according to SF-MPQ and NPSI, onset of effect, reduction in worst pain on the NRS; allodynia severity; quality of life (QoL) based on EQ-5D, SF-36; PGIC; rescue medication intake; adverse events (AEs) monitoring. At 4 weeks, SF-MPQ total scores improved by -7.6 +/- 6.66 (mean +/- SD) under 5% lidocaine medicated plaster and by -5.3 +/- 7.93 under pregabalin. NPSI total scores declined by -1.6 +/- 1.73 under 5% lidocaine medicated plaster and -1.4 +/- 1.87 under pregabalin. Lidocaine plaster was also effective in reducing worst pain and showed a fast onset of effect. During combination treatment, SF-MPQ and NPSI scores, allodynia, EQ-5D and PGIC improved. Incidences of AEs were in line with previous reports for the two treatments and combination therapy was generally well-tolerated.\nQuestion: Post-herpetic neuralgia: 5% lidocaine medicated plaster, pregabalin, or a combination of both?",
    "gt": "Although this open-label study is lacking a placebo control group, the results suggest that 5% lidocaine medicated plaster is at least as effective as pregabalin for pain relief in PHN, with a favourable safety profile and a resulting positive benefit-risk ratio. In patients unresponsive to either monotherapy, combination therapy provides additional efficacy and is well-tolerated.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To examine the effect of autism spectrum (AS) tendencies and psychosocial job characteristics on health-related quality of life (HRQOL) among factory workers. A questionnaire survey was administered to 376 Japanese factory employees from the same company (response rate: 83.6%) in 2010. Psychosocial job characteristics, including job demand, job control, and social support, were evaluated using the Job Content Questionnaire (JCQ). AS tendencies was assessed using the Autism-Spectrum Quotient (AQ), and HRQOL was assessed using the Medical Outcomes Study Short-Form General Health Survey (SF-8). Associations were investigated using multiple logistic regression analysis adjusted for confounders. In the multivariate analysis, AQ was positively (odds ratio [OR]: 3.94; 95% confidence interval [CI]: 1.70-9.73) and social support in the workplace was inversely (OR: 0.25; 95% CI: 0.10-0.57) associated with poor mental HRQOL. No significant interaction was observed between AQ and JCQ subitems. Only social support was inversely associated with poor physical HRQOL (OR and 95% CI for medium social support: 0.45 and 0.21-0.94), and a significant interaction between AQ and job control was observed (p=0.02), suggesting that high job control was associated with poor physical HRQOL among workers with high AQ, whereas low job control tended to be associated with poor physical HRQOL among others.\nQuestion: Is high job control a risk factor for poor quality of life in workers with high autism spectrum tendencies?",
    "gt": "Our results suggest that AS tendencies have a negative effect on workers' HRQOL and social support is a primary factor in maintaining HRQOL. Moreover, a structured work environment can maintain physical HRQOL in workers with high AS tendencies since higher job control will be stressful.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We performed a prospective, population-based case-control study of 20,248 newborn born in the city of Mainz. A total of 1,451 infants (cases) with and 8,088 without congenital malformations (controls) were analysed. The relative risks of associations between obesity and malformations were calculated as odds ratios (OR) with 95% confidence intervals (CI). The prevalence of malformations in children of obese mothers is 11.1% and thus approximately 4% higher than those of the total study population. There is a significant odds ratio for major malformations (OR 1.3; KI 1.0-1.7). Statistically significant associations were calculated for malformations of the internal urogenital system (OR 1.7; 1.1-2.8), the eyes (OR 5.0; 1.3-20.0) and for orofacial clefts (OR 1.7; 1.1-2.8). Among the specific malformations the highest associations occurred for encephalocele (OR 7.3; 1.1-50.6), common truncus arteriosus (OR 6.3; 1.6-24.8) and Potter sequence (OR 6.3; 1.6-24.8). Adjustment for confounding factors (e.g. maternal diabetes mellitus and age) did not change the odds ratios.\nQuestion: Does maternal obesity increase the risk of fetal abnormalities?",
    "gt": "Our data demonstrate that newborn of obese mothers are at an increased risk for malformations. An adequate prenatal examination of these pregnancies should include ultrasound screening by specially trained ultrasonographers in tertiary units (DEGUM II/DEGUM III) and serum alpha-fetoprotein measurements. Public health campaigns for prevention are advised.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The sensitivity of endocervical curettage (ECC) can be suboptimal because of limited epithelial tissue. The false-negative rate for ECC in patients with cervical intraepithelial neoplasia involving the endocervical canal has been reported to be 45%. ECC samples are transported to pathology in formalin- or saline-filled containers; this fluid is discarded after the specimen has been submitted. We evaluated the utility of performing liquid-based cytological preparations from ECC transport container fluid as a way to increase the sensitivity of ECC specimens. Consecutive ECC specimens received at one of the two participating institutions were selected prospectively. A surgical pathology mesh bag was placed over a ThinPrep(®) CytoLyt(®) solution container, and the specimen was filtered through the bag, collecting the transport fluid in the container. The CytoLyt(®) was processed to obtain a container fluid ThinPrep(®) (CF-TP) liquid-based Papanicolaou (Pap) slide. The CF-TP slides were reviewed and the findings were compared with those from the ECC and follow-up specimens. The cohort included 53 patients. Discrepancies between CF-TP and ECC were seen in 14 of the 53 patients (26%); a more significant lesion was identified in CF-TP relative to ECC in 13 of these cases. CF-TP diagnosis was confirmed in eight of 11 cases with histological follow-up. A positive CF-TP result was confirmed by histology in six of nine cases with negative ECC.\nQuestion: Increasing the sensitivity of endocervical curettings by performing ThinPrep® Pap on transport container fluid: is diagnostic material going down the drain?",
    "gt": "Combining the pathological evaluation of ECC specimens with liquid-based cytology performed on the transport container fluid can increase the diagnostic sensitivity of the ECC procedure for the detection of cervical lesions.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Immunoglobulin A (IgA) anti-endomysium antibodies, the most reliable immunological marker for both the screening and follow-up of coeliac disease, need monkey oesophagus as antigenic substrate; this limits their use because of high costs and the exploitation of endangered species. (1) To compare the diagnostic accuracy of anti-endomysium antibodies detected by indirect immunofluorescence on monkey oesophagus and on human umbilical cord; (2) to evaluate their reliability during follow-up in detecting non-compliant patients. One hundred and four untreated adults with biopsy-proven coeliac disease and 94 controls were investigated. Endomysium antibodies were found in 99 patients (95%) on both substrates, with a specificity, respectively, of 100% and 99% on monkey oesophagus and umbilical cord. One year after gluten withdrawal, out of 47 patients who were investigated, only six presented with complete mucosal recovery: none of these subjects was positive on either substrates, while, among patients with persistent histological alterations, endomysium positivity persisted in only 10 on monkey oesophagus, but in 32 on umbilical cord. Histology (recovery or persistent involvement) was in agreement with endomysium (negative or positive) in 34% on monkey oesophagus, but in 81% on umbilical cord (P<0.0001).\nQuestion: Is human umbilical cord the most suitable substrate for the detection of endomysium antibodies in the screening and follow-up of coeliac disease?",
    "gt": "Human umbilical cord, with its comparable diagnostic efficiency, could replace monkey tissues, with the advantages of saving both money and monkeys. Moreover, it seems the most suitable substrate in the follow-up, as it enables detection of non-compliant patients with persisting mucosal alterations.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To explore whether there exist differences in cognitive development between singletons and twins born after in vitro fertilization (IVF) or intracytoplasmic sperm injection (ICSI). A total of 566 children were recruited for the study, including 388 children (singletons, n=175; twins, n=213) born after IVF and 178 children (singletons, n=87; twins, n=91) born after ICSI. The cognitive development was assessed using the Chinese-Wechsler Intelligence Scale for Children (C-WISC). For all pre-term offspring, all the intelligence quotient (IQ) items between singletons and twins showed no significant differences no matter if they were born after IVF or ICSI. There was a significant difference in the cognitive development of IVF-conceived full-term singletons and twins. The twins born after IVF obtained significantly lower scores than the singletons in verbal IQ (containing information, picture&vocabulary, arithmetic, picture completion, comprehension, and language), performance IQ (containing maze, visual analysis, object assembly, and performance), and full scale IQ (P<0.05). The cognitive development of full-term singletons and twins born after ICSI did not show any significant differences. There was no significant difference between the parents of the singletons and twins in their characteristics where data were collected, including the age of the mothers, the current employment status, the educational backgrounds, and areas of residence. There were also no consistent differences in the duration of pregnancy, sex composition of the children, age, and height between singletons and twins at the time of our study although there existed significant differences between the two groups in the sex composition of the full-term children born after ICSI (P<0.05).\nQuestion: Is there a difference in cognitive development between preschool singletons and twins born after intracytoplasmic sperm injection or in vitro fertilization?",
    "gt": "Compared to the full-term singletons born after IVF, the full-term twins have lower cognitive development. The cognitive development of full-term singletons and twins born after ICSI did not show any significant differences. For all pre-term offspring, singletons and twins born after IVF or ICSI, the results of the cognitive development showed no significant differences.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Partial laryngectomy is used in the treatment of laryngeal cancer. Structural alterations of the upper airway arising from partial laryngectomy can cause obstructive sleep apnea (OSA). To compare the prevalence and severity of OSA in patients submitted to horizontal and vertical partial laryngectomy and assess the role of spirometry for these patients. Cross-sectional clinical study with individuals offered partial laryngectomy. The included patients were assessed through interview, upper airway endoscopy, polysomnography, and spirometry. Fourteen patients were evaluated and 92.3% were found to have OSA. The apnea-hypopnea index was significantly higher among patients submitted to vertical laryngectomy (mean = 36.9) when compared to subjects offered horizontal laryngectomy (mean = 11.2). The mean minimum oxyhemoglobin saturation was 85.9 in the horizontal laryngectomy group and 84.3 in the vertical laryngectomy group. Spirometry identified extrathoracic upper airway obstruction in all patients with OSA.\nQuestion: Obstructive sleep apnea: is there a difference between vertical and horizontal laryngectomy?",
    "gt": "The studied population had a high incidence of obstructive sleep apnea. OSA was more severe in patients offered vertical laryngectomy than in the individuals submitted to horizontal laryngectomy. Spirometry seems to be useful in the detection of cases of suspected OSA, as it suggests the presence of extrathoracic upper airway obstruction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A retrospective comparative study was performed in patients with rectal cancer who achieved an incomplete clinical response after neoadjuvant chemoradiotherapy. Patients with significant tumour downsizing (>30% of the initial tumour size) were compared with controls (<30% reduction of the initial tumour size). During flexible proctoscopy carried out postchemoradiation, biopsies were performed using 3-mm biopsy forceps. The biopsy results were compared with the histopathological findings of the resected specimen. UICC (Union for International Cancer Control) ypTNM classification, tumour differentiation and regression grade were evaluated. The main outcome measures were sensitivity and specificity, negative and positive predictive values, and accuracy of a simple forceps biopsy for predicting pathological response after neoadjuvant chemoradiotherapy. Of the 172 patients, 112 were considered to have had an incomplete clinical response and were included in the study. Thirty-nine patients achieved significant tumour downsizing and underwent postchemoradiation biopsies. Overall, 53 biopsies were carried out. Of the 39 patients who achieved significant tumour downsizing, the biopsy result was positive in 25 and negative in 14. Only three of the patients with a negative biopsy result were found to have had a complete pathological response (giving a negative predictive value of 21%). Considering all biopsies performed, only three of 28 negative biopsies were true negatives, giving a negative predictive value of 11%.\nQuestion: Role of biopsies in patients with residual rectal cancer following neoadjuvant chemoradiation after downsizing: can they rule out persisting cancer?",
    "gt": "In patients with distal rectal cancer undergoing neoadjuvant chemoradiation, post-treatment biopsies are of limited clinical value in ruling out persisting cancer. A negative biopsy result after a near-complete clinical response should not be considered sufficient for avoiding a radical resection.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: According to observations by occupational health physicians, nearly 50 % of the seamen on German vessels will get diseases of the upper respiratory tract. An impact of the air-conditioning systems on these diseases has been suggested. To examine the hygienic quality of indoor air on seagoing vessels, a pilot study was initiated by the See-Berufsgenossenschaft. Air samples were taken on-site at different sampling sites and analysed for the occurrence of microorganisms. Bacteria showed the highest cell numbers and the highest distribution in indoor air on vessels, whereby the maximum level was determined in the air of crew cabins. The identification of bacteria showed that beside common airborne species, pathogens existed.\nQuestion: Does air conditioning impact on hygienic quality of indoor air on seagoing vessels?",
    "gt": "Air-conditioning seems to influence the quality of indoor air on seagoing vessels. Interim results of the study indicate that regular maintenance of air-conditioning systems is essential.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Colorectal cancer (CRC) screening programmes based on faecal immunochemical testing for haemoglobin (FIT) typically use a screening interval of 2 years. We aimed to estimate how alternative FIT strategies that use a lower than usual positivity threshold followed by a longer screening interval compare with conventional strategies. We analysed longitudinal data of 4523 Dutch individuals (50-74 years at baseline) participating in round I of a one-sample FIT screening programme, of which 3427 individuals also participated in round II after 1-3 years. The cohort was followed until 2 years after round II. In both rounds, a cut-off level of ≥50 ng haemoglobin (Hb)/mL buffer (corresponding to 10 µg Hb/g faeces) was used, representing the standard scenario. We determined the cumulative positivity rate (PR) and the numbers of subjects diagnosed with advanced adenomas (N_AdvAd) and early stage CRC (N_earlyCRC) in the cohort over two rounds of screening (standard scenario) and compared it with hypothetical single-round screening with use of a lower cut-off and omission of the second round (alternative scenario). In the standard scenario, the cumulative (ie, round I and II combined) PR, N_AdvAd and N_earlyCRC were 13%, 180% and 26%, respectively. In alternative scenarios using a cut-off level of respectively ≥11 and ≥22 ng/HbmL buffer (corresponding to 2 and 4 µg Hb/g faeces), the PRs were 18% and 13%, the N_AdvAd were 180 and 162 and the N_earlyCRC ranged between 22-27 and 22-26.\nQuestion: Immunochemical faecal occult blood testing to screen for colorectal cancer: can the screening interval be extended?",
    "gt": "The diagnostic yield of FIT screening using a lowered positivity threshold in combination with an extended screening interval (up to 5 years) may be similar to conventional FIT strategies. This justifies and motivates further research steps in this direction.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The primary aim is to explore whether prescription drug expenditures by enrollees changed in Alabama's CHIP program, ALL Kids, after copayment increases in fiscal year 2004. The subsidiary aim is to explore whether non-pharmaceutical expenditures also changed. Data on ALL Kids enrollees between 1999-2007, obtained from claims files and the state's administrative database. We used data on children who were enrolled between one and three years both before and after the changes to the copayment schedule, and estimate regression models with individual-level fixed effects to control for time-invariant heterogeneity at the child level. This allows an accurate estimate of how program expenditures change for the same individual following copayment changes. Primary outcomes of interest are expenditures for prescription drugs by class and brand-name and generic versions. We estimate models for the likelihood of any use of prescription drugs and expenditure level conditional on use. Following the copayment increase, the probability of any expenditure decline by 5.8%, brand name drugs by 6.9%, generic drugs by 7.4%. Conditional on any use, program expenditures decline by 7.9% for all drugs, by 9.6% for brand name drugs, and 6.2% for generic drugs. The largest declines are for antihistamine drugs; the least declines are for Central Nervous System agents. Declines are smaller and statistically weaker for children with chronic health conditions. Concurrent declines are also seen for non-pharmaceutical medical expenditures.\nQuestion: Can increases in CHIP copayments reduce program expenditures on prescription drugs?",
    "gt": "Copayment increases appear to reduce program expenditures on prescription drugs per enrollee and may be a useful tool for controlling program costs.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There has been considerable expansion in the use of flexible cystoscopy (FC) and people who can perform the procedure. Hence, there is a criticism that this procedure is being overused with no management benefit. We audited the use of FC in a district hospital for a period of 1 year. The results of FC for non-standard indications (other than haematuria and check cystoscopy) were analysed for their diagnostic yield. Of the 1,390 FCs performed, 295 were done for non-standard indications. 46.14% of these cystoscopies had positive findings. Cancer detection rate was 6.10%. Cystoscopy altered the management in 14.08% of patients and was supportive to diagnosis and management in 32.06%.\nQuestion: Do we need to perform cystoscopy on all adults attending urology centres as outpatients?",
    "gt": "This procedure is certainly not overused and the ever-increasing requirement of this simple procedure has serious resource implications for the National Health Service.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Retrospective analysis was conducted for 45 patients in a BDSR group and for 149 patients in a PD group. The T-stage (P<0.001), lymph node invasion (P = 0.010) and tumor differentiation (P = 0.005) were significant prognostic factors in the BDSR group. The 3- and 5-year overall survival rates for the BDSR group and PD group were 51.7% and 36.6%, respectively and 46.0% and 38.1%, respectively (P = 0.099). The BDSR group and PD group did not show any significant difference in survival when this was adjusted for the TNM stage. The 3- and 5-year survival rates were: stage Ia [BDSR (100.0% and 100.0%) vs PD (76.9% and 68.4%) (P = 0.226)]; stage Ib [BDSR (55.8% and 32.6%) vs PD (59.3% and 59.3%) (P = 0.942)]; stage IIb [BDSR (19.2% and 19.2%) vs PD (31.9% and 14.2%) (P = 0.669)].\nQuestion: Carcinoma of the middle bile duct: is bile duct segmental resection appropriate?",
    "gt": "BDSR can be justified as an alternative radical operation for patients with middle bile duct in selected patients with no adjacent organ invasion and resection margin is negative.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study provides understanding about the issues that affect nurse retention in a sector where employee attrition is a key challenge, further exacerbated by an ageing workforce. A quantitative study based on a self-completion survey questionnaire completed in 2010. Nurses employed in two UK National Health Service Foundation Trusts were surveyed and assessed using seven work-related constructs and various demographics including age generation. Through correlation, multiple regression and stepwise regression analysis, the potential combined effect of various explanatory variables on continuation intention was assessed, across the entire nursing cohort and in three age-generation groups. Three variables act in combination to explain continuation intention: work-family conflict, work attachment and importance of work to the individual. This combination of significant explanatory variables was consistent across the three generations of nursing employee. Work attachment was identified as the strongest marginal predictor of continuation intention.\nQuestion: Do nurses wish to continue working for the UK National Health Service?",
    "gt": "Work orientation has a greater impact on continuation intention compared with employer-directed interventions such as leader-member exchange, teamwork and autonomy. UK nurses are homogeneous across the three age-generations regarding explanation of continuation intention, with the significant explanatory measures being recognizably narrower in their focus and more greatly concentrated on the individual. This suggests that differentiated approaches to retention should perhaps not be pursued in this sectoral context.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine the prevalence of coeliac disease in an Australian rural community. Retrospective analysis of stored serum samples from 3,011 random subjects from the Busselton Health Study. IgA antiendomysial antibodies (AEA) were detected by indirect immunofluorescence, and subjects testing positive were contacted and offered small-bowel biopsy. Prevalence of AEA positivity and biopsy-proven coeliac disease in the community with reference to the proportion of symptomatic to asymptomatic patients. 10 of 3,011 subjects were AEA positive. One subject had died, one subject could not be traced and one refused small-bowel biopsy. All subjects with detectable AEA who consented to biopsy had pathological changes consistent with coeliac disease. The prevalence of newly diagnosed biopsyproven coeliac disease is 7 in 3,011 (1 in 430). Two further subjects had a diagnosis of coeliac disease before this study. When all AEA-positive patients and those previously diagnosed are included, the prevalence is 12/3,011 (1 in 251). There was a significant clustering of cases in the 30-50-years age range, with 10/12 (83%; 95% CI, 52%-98%) aged between 30 and 50 years, compared with 1,092/3,011 (36%; 95% CI, 35%-38%) of the total population (P<0.03). Of the eight AEA-positive subjects who could be contacted, four had symptoms consistent with coeliac disease and four were asymptomatic. Three subjects were iron-deficient, four subjects had first-degree relatives with coeliac disease and one subject had type 1 diabetes mellitus.\nQuestion: High prevalence of coeliac disease in a population-based study from Western Australia: a case for screening?",
    "gt": "The prevalence of coeliac disease is high in a rural Australian community. Most patients are undiagnosed, and asymptomatic.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study evaluates the agreement in prolapse staging between clinical examination, dynamic magnetic resonance (MR), imaging and perineal ultrasonography. Anatomical landmarks in the anterior, central, and posterior compartment were assessed in relation to three reference lines on dynamic MR imaging and one reference line on dynamic ultrasonography. These measurements were compared to the according POP-Q measurements. Agreement between the three methods was analyzed with Spearman's rank correlation coefficient (r(s)) and Bland and Altman plots. Correlations were good to moderate in the anterior compartment (r(s) range = 0.49; 0.70) and moderate to poor (r(s) range = -0.03; 0.49) in the central and posterior compartment. This finding was independent of the staging method and reference lines used.\nQuestion: POP-Q, dynamic MR imaging, and perineal ultrasonography: do they agree in the quantification of female pelvic organ prolapse?",
    "gt": "Pelvic organ prolapse staging with the use of POP-Q, dynamic MR imaging, and perineal ultrasonography only correlates in the anterior compartment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Pleiotropic effects of recombinant human erythropoietin (EPO) have recently been discovered in many non-renal animal models. The renoprotective effects of EPO and carbamylated-erythropoietin (CEPO), a novel EPO which has a small stimulatory effect on hemoglobin, have never been explored in unilateral ureteral obstruction (UUO), a chronic tubulointerstitial (TI) disease model which is independent of systemic factors. In order to examine the effects of EPO and CEPO treatments on renal TI injury, 36 male Sprague-Dawley rats, weighing 250-320 g, underwent: UUO without treatment (group 1, n = 12), UUO with EPO (groups 2, n = 12), and UUO with CEPO (group 3, n = 12). EPO and CEPO were injected subcutaneously at a dose of 5000 u/kg to each respective rat at 1 day pre-UUO and at day 3, 7 and 10 post-UUO. After days 3, 7, and 14 of UUO, TI injury, collagen, alpha-smooth muscle actin (alpha-SMA) positive cell, ED1-positive cell, terminal deoxynucleotidyl transferase (TdT) mediated nick-end labeling (TUNEL)-positive cell, and transforming growth factor-beta1 (TGF-beta1) messenger ribonucleic acid (mRNA) were determined. Bcl-2 expression was also assessed to verify the mechanism of apoptosis. At day 14 UUO caused severe TI injury with a significant increase in collagen, alpha-SMA, ED1-positive cell, TUNEL-positive cell, and TGF-beta1 mRNA expression. Administration of EPO and CEPO significantly attenuated TI injury, collagen, ED1-positive cells, and TUNEL-positive cells. Only CEPO-treated rats had decreased alpha-SMA positive cells and TGF-beta1 mRNA. The expression of Bcl-2 was demonstrated only in EPO-treated rats. The hematocrit levels in EPO-treated rats were higher than the control and CEPO-treated rats.\nQuestion: Erythropoietin and its non-erythropoietic derivative: do they ameliorate renal tubulointerstitial injury in ureteral obstruction?",
    "gt": "EPO and CEPO can limit 14-day UUO-induced TI injury by reducing inflammation, interstitial fibrosis, and tubular apoptosis.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The independent effect of lipid lowering therapy (LLT) on venous thromboembolism (VTE) risk is uncertain. To test statin and non-statin LLT as potential VTE risk factors. Using Rochester Epidemiology Project resources, we identified all Olmsted County, MN residents with objectively diagnosed incident VTE (cases) over the 13-year period, 1988-2000 (n=1340), and one to two matched controls (n=1538). We reviewed their complete medical records for baseline characteristics previously identified as independent VTE risk factors, and for statin and non-statin LLT. Using conditional logistic regression, we tested the overall effect of LLT on VTE risk and also separately explored the role of statin versus that of non-statin LLT, adjusting for other baseline characteristics. Among cases and controls, 74 and 111 received statin LLT, and 32 and 50 received non-statin LLT, respectively. Univariately, and after individually controlling for other potential VTE risk factors (i.e., BMI, trauma/fracture, leg paresis, hospitalization for surgery or medical illness, nursing home residence, active cancer, central venous catheter, varicose veins, prior superficial vein thrombosis, diabetes, congestive heart failure, angina/myocardial infarction, stroke, peripheral vascular disease, smoking, anticoagulation), LLT was associated with decreased odds of VTE (unadjusted OR=0.73; p=0.03). When considered separately, statin and non-statin LLT were each associated with moderate, non-significant lower odds of VTE. After adjusting for angina/myocardial infarction, each was significantly associated with decreased odds of VTE (OR=0.63, p<0.01 and OR=0.61, p=0.04, respectively).\nQuestion: Is lipid lowering therapy an independent risk factor for venous thromboembolism?",
    "gt": "LLT is associated with decreased VTE risk after adjusting for known risk factors.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The differentiation between cardiac and esophageal causes of retrosternal chest pain is notoriously difficult. Theoretically, cardiac and esophageal causes may coexist. It has also been reported that gastroesophageal reflux and esophageal motor abnormalities may elicit myocardial ischemia and chest pain, a phenomenon called linked angina pectoris. The aim of this study was to assess the incidence of esophageal abnormalities as a cause of retrosternal chest pain in patients with previously documented coronary artery disease. Thirty consecutive patients were studied, all of whom had undergone coronary arteriography. The patients were studied after they were admitted to the coronary care unit with an attack of typical chest pain. On electrocardiograms (ECGs) taken during pain, 15 patients (group I) had new signs of ischemia; the other 15 patients (group II) did not. In none of the patients were cardiac enzymes elevated. As soon as possible, but within 2 hours after admission, combined 24-hour recording of esophageal pressure and pH was performed. During chest pain, 12-lead ECG recording was carried out. In group I, all 15 patients experienced one or more pain episodes during admission, 25 of which were associated with ischemic electrocardiographic changes. The other two episodes were reflux-related. Only one of the 25 ischemia-associated pain episodes was also reflux-related, ie, it was preceded by a reflux episode. In group II, 19 chest pain episodes occurred in 11 patients. None of these was associated with electrocardiographic changes, but 8 were associated with reflux (42%) and 8 with abnormal esophageal motility (42%).\nQuestion: Esophageal dysfunction as a cause of angina pectoris (\"linked angina\"): does it exist?",
    "gt": "Linked angina is a rare phenomenon.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To assess if arylsulfatase A activity (ASA) and sulfatide (SL) concentration in the human endometrium can be predictive of the development of endometrial polyps over the years, since ASA activity reflects the endometrial sensitivity to hormones. ASA activity and SL concentration were determined by biochemical procedures on endometrial samples collected between 1990 and 1994 in non-menopausal women. These women underwent a new endometrial sampling following the clinical indication some years after the first endometrial sampling. The histological assessment of the second endometrial specimens found four patients with normal endometrial pattern and 10 patients with one or more endometrial polyps. ASA activity/years elapsed and SL concentration/years elapsed were compared using two tailed Mann-Whitney test for unpaired data between patients with normal pattern and patients with endometrial polyps. Median ASA activities were 2.62 (normal pattern) versus 1.85 (endometrial polyps) nmol hydrolized substrate/min. Median activity/years elapsed is higher in patients with second endometrial sample presenting normal pattern (p=0.006) and median SL concentration/years elapsed does not differ significantly among groups, even if median SL concentration seems to be higher in patients who subsequently developed polyps (1031 µg/g of fresh tissue versus 341,5 µg/g of fresh tissue).\nQuestion: Can endometrial arylsulfatase A activity predict the onset of endometrial polyps over the years?",
    "gt": "ASA activity can predict the onset of endometrial polyps over the years.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Enteroviruses are seasonally prevalent each year in Southeast Asia. Elevated C-reactive protein (CRP) levels have been noted in minor populations of patients, and antibiotics may be prescribed under the impression of a suspected bacterial infection. This prescription might be inappropriate, resulting in further bacterial resistance and medical expense. The aim of this study was to delineate how effective antibiotics are for children suffering from enterovirus infection complicated with a high CRP level. The medical records of children hospitalized between January 2008 and December 2012 with herpangina or hand, foot and mouth disease were reviewed retrospectively. The children enrolled were divided into three groups, A, B, and C, by CRP level, which were<40, 40-80, and ≥ 80 mg/l, respectively. A case-control study of group C divided into subgroups according to the prescription of antibiotics for at least 24h during the admission was conducted for further analysis. A total 3566 cases were identified; 214 were in group C and 71.0% of them received a prescription for antibiotics. There was a linear trend between a relatively higher CRP level and a higher proportion of antibiotics prescribed in the three groups (p=0.001). In the case-control study, there were no significant differences in age, sex, mean CRP, or febrile days. However, a relatively longer stay of hospitalization was recorded in the subgroup with an antibiotic prescription (p=0.020).\nQuestion: Are antibiotics beneficial to children suffering from enterovirus infection complicated with a high C-reactive protein level?",
    "gt": "The present study indicated that antibiotics might not be beneficial in treating these patients, even those with a high CRP level. Clinicians should be more prudent in antibiotic use when no obvious evidence of bacterial infection is found.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Treatment of anemia is an important issue in the palliative care setting. Blood transfusion is generally used for this purpose in supportive care. However the place of blood transfusion in terminally ill cancer cases is less far established. We aimed to outline the use of transfusions and to find the impact of blood transfusion on survival in patients with advanced cancer and very near to death. Patients dying in 2010-2011 with advanced cancer were included in the study. We retrospectively collected the data including age, type of cancer, the duration of last hospitalisation, ECOG performance status, Hb levels, transfusion history of erythrocytes and platelets, cause and the amount of transfusion. The anaemic patients who had transfusion at admission were compared with the group who were not transfused. Survival was defined as the time between the admission of last hospitalisation period and death. Three hundred and ninety eight people with solid tumours died in 2010-2011 in our clinic. Ninety percent of the patients had anemia at the time of last hospitalisation. One hundred fifty three patients had erythrocyte transfusion at admission during the last hospitalisation period (38.4%). In the anaemic population the duration of last hospitalisation was longer in patients who had erythrocyte transfusion (15 days vs 8 days, p<0.001).\nQuestion: Use of blood transfusion at the end of life: does it have any effects on survival of cancer patients?",
    "gt": "Patients who had blood transfusion at the end of life lived significantly longer than the anaemic patients who were not transfused. This study remarks that blood transfusions should not be withheld from terminal cancer patients in palliative care.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Despite the implementation of a Quebec immunization program against influenza and pneumococcal disease (PQIIP), vaccine coverage has remained low. There have been many studies on personal barriers to vaccination, but few have explored other kinds of barriers. To explore the presence of barriers in relation to the organization of the health care system and to propose recommendations for increasing vaccine coverage. Within a mixed protocol, a phone survey of 996 people in the target population and a case study implicating the follow-up of the PQIIP with all the site and actor categories via 43 semistructured interviews and 4 focus groups were realized. Survey data underwent a descriptive statistical analysis. Qualitative analysis followed the Miles and Huberman approach. The results indicate the presence of barriers with regard to information accessibility. These include access to: the physicians' recommendation, knowledge of the efficacy or the security of vaccines, and admissibility of clients to the PQIIP. Organizational barriers were also found to limit access to vaccination, especially in terms of restricted choices of time and location. Coordination and incentives mechanisms are not optimal. Removal of organizational barriers depends more on strategic rather than structural factors.\nQuestion: Do organizational barriers to pneumococcal and influenza vaccine access exist?",
    "gt": "Addressing organizational barriers should be an important component of strategies aimed at improving vaccine coverage. Public health authorities should focus on strategic management of the information and inter-organizational environment.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Almost half of all children in South Asia are stunted. Although agriculture has the potential to be a strong driver of undernutrition reduction and serves as the main source of livelihood for over half of South Asia's population, its potential to reduce undernutrition is currently not being realized. The Leveraging Agriculture for Nutrition in South Asia (LANSA) research consortium seeks to understand how agriculture and agrifood systems can be better designed to improve nutrition in South Asia. In 2013 and 2014, LANSA carried out interviews with stakeholders influential in, and/or knowledgeable of, agriculture-nutrition policy in India, Pakistan, and Bangladesh, to gain a better understanding of the institutional and political factors surrounding the nutrition sensitivity of agriculture in the region. Semistructured interviews were carried out in India, Bangladesh, and Pakistan with a total of 56 stakeholders representing international organizations, research, government, civil society, donors, and the private sector. The findings point to mixed perspectives on countries' policy sensitivity toward nutrition. There was consensus among stakeholders on the importance of political commitment to nutrition, improving nutrition literacy, strengthening capacities, and improving the use of financial resources.\nQuestion: Is There an Enabling Environment for Nutrition-Sensitive Agriculture in South Asia?",
    "gt": "Although there are different ways in which South Asian agriculture can improve its impact on nutrition, sensitizing key influencers to the importance of nutrition for the health of a country's population appears as a critical issue. This should in turn serve as the premise for political commitment, intersectoral coordination to implement nutrition-relevant policies, adequately resourced nutrition-specific and nutrition-sensitive programs, and sufficient capacities at all levels.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To compare regional body fat distribution and sex hormone status of postmenopausal women with NIDDM with those of age- and BMI-matched normoglycemic women. The regional body fat distribution and sex hormone status of 42 postmenopausal women with NIDDM were compared with those of 42 normoglycemic women matched for age and BMI, who served as control subjects. Body composition was measured by dual-energy X-ray absorptiometry, and sex hormone-binding globulin (SHBG) and testosterone were measured in serum. Although the levels of total body fat were similar between the two groups, the women with NIDDM had significantly less lower-body fat (LBF) (P<0.01) than the control subjects matched for age and BMI. This pattern of fat deposition in women with NIDDM was accompanied by an androgenic hormone profile, with decreased SHBG concentration and an increased free androgen index (P<0.05 and P<0.01, respectively).\nQuestion: Do postmenopausal women with NIDDM have a reduced capacity to deposit and conserve lower-body fat?",
    "gt": "A reduced capacity to deposit and/or conserve LBF may be an independent factor associated with (or may be a marker of) the metabolic manifestations of the insulin resistance syndrome in women with NIDDM. The possibility that the smaller relative accumulation of LBF is a consequence of the androgenic hormonal profile should be investigated in future studies.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We analyzed the impact of immunoglobulin M (IgM) positivity on the relapse-free interval post completed course of cyclophosphamide (CYC) treatment in patients with steroid-dependent nephrotic syndrome (SDNS) and minimal change disease (MCD). This was a retrospective chart review of all children who received CYC for SDNS and MCD between 1988 and 2009. Patients were divided into three groups based on kidney biopsy: MCD without immunoglobulin M (IgM) positivity (IgM-), MCD with IgM-positive immunofluorescence (IF) only (IgM+), and MCD with IgM-positive IF and electron-dense deposits on electron microscopy (IgM++). The relapse-free time interval to the first relapse post-CYC therapy or up to 48 months of follow-up (if no relapse occurred) was used for survival analysis. Forty children aged 1.5-12.3 years (15 were IgM-, 16 were IgM+, 9 were IgM++) received a cumulative CYC dose of 175 ± 30 mg/kg. The overall relapse-free survival time was 75 % at 12 months, 64 % at 24 months, 59 % at 36 months, and 56 % at 48 months, with no significant differences between the IgM groups (p = 0.80).\nQuestion: Is cyclophosphamide effective in patients with IgM-positive minimal change disease?",
    "gt": "Based on our results, we conclude that more than 50% of our SDNS patients with MCD remained relapse-free 4 years post-CYC treatment. No significant difference in the response to CYC was observed between patients with or without IgM positivity.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate whether self reporting of psychological demands and control at work is as valid for psychologically distressed subjects as for subjects with psychological wellbeing. Self reported demands and control (according to the model of Karasek) were compared to expert assessments through direct observations of each subject's work conditions concerning time pressure, hindrances, qualification for work tasks, and possibility of having influence. The comparison was made between respondents reporting and not reporting psychological distress as measured by the general health questionnaire with 12 questions (GHQ-12). The sample consisted of 203 men and women in 85 occupations. No systematic differences between self reported and externally assessed working conditions for respondents reporting different levels of psychological distress were found.\nQuestion: Does psychological distress influence reporting of demands and control at work?",
    "gt": "Over-reporting of work demands or under-reporting of work control is unlikely at the levels of psychological distress studied.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Many researchers have speculated that markers of malnutrition such as albumin, prealbumin, cholesterol, and transferrin are influenced by inflammation. The mechanism of this interaction has not been well understood. This was a prospective cross-sectional study. We evaluated 72 male patients older than 60 years admitted to a geriatric rehabilitation unit. Subjects with severe hepatic or renal diseases were excluded. We measured body mass index, caloric intake, serum albumin, prealbumin, cholesterol, transferrin, hemoglobin, and total lymphocyte count. To detect inflammation, we measured C-reactive protein, Westergren sedimentation rate, fibrinogen, and cytokines including tumor necrosis factor-alpha (TNF-alpha), interleukin-1 beta (IL-1 beta), IL-6, IL-2, and the soluble IL-2 receptor. Soluble IL-2 receptor was negatively associated with albumin (r = -.479, p<.0001), prealbumin (r = -.520, p =<.0001), cholesterol (r = -.487, p = .0001), transferrin (r = -.455, p = .0002), and hemoglobin (r = -.371, p = .002). TNF-alpha, IL-1 beta, IL-6, and IL-2 were not associated with these measures.\nQuestion: Is malnutrition overdiagnosed in older hospitalized patients?",
    "gt": "Inflammation increases the incidence of hypoalbuminemia and hypocholesterolemia, potentially leading to overdiagnosis of malnutrition. We suggest that albumin, cholesterol, prealbumin, and transferrin be used with caution when assessing the nutritional status of older hospitalized patients. In the future, soluble IL-2 receptor levels might be used to correct for the impact of inflammation on these markers of malnutrition.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To study the effectiveness of combined integral somatic and psychiatric treatment in a medical-psychiatric unit (MPU). Retrospective case-note study. The case notes of all patients admitted to the MPU at the VU Medical Center, Amsterdam, in 2011 were analysed. Data on reasons for referral and somatic and psychiatric diagnoses were collected. Using a global clinical assessment scale and the Health of the Nations Outcome Scales (HoNOS), data on psychiatric symptomology and limitations, behavioural problems, social problems and limitations associated with physical health problems were collected on both admission and discharge. In this way the effect of the admission period on various problems was determined. In 2011 there were 139 admissions to the MPU with a wide variation of somatic and psychiatric diagnoses. The average admission period was 9 days. Global clinical evaluation of the treatment goals set for somatic and psychiatric conditions showed that more than 90% and 85% of the treatment goals, respectively, were completely achieved. HoNOS scores showed a reduction in severity of both psychiatric and somatic problems. The total HoNOS-core was significantly reduced by nearly 3.5 points - a large effect size.\nQuestion: A medical-psychiatric unit in a general hospital: effective combined somatic and psychiatric care?",
    "gt": "The MPU has succeeded in its goal to deliver integral care to a very diverse group of patients with somatic and psychiatric co-morbidities. It is able to offer care to a vulnerable patient group in which it can be presumed that treatment on a non-integrated unit could not have been delivered or not delivered adequately, due to the complexity of their somatic and behavioural problems.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine if patients with non-small cell lung carcinoma (NSCLC) and positive supraclavicular nodes (SN+) have a similar outcome to other patients with Stage IIIB NSCLC (SN-) when treated with modern chemoradiotherapy. Using the Radiation Therapy Oncology Group (RTOG) database, data were retrospectively analyzed from five RTOG trials studying chemoradiotherapy for 88-04, 88-08 (chemo-RT arm), 90-15, 91-06, 92-04. Comparisons were made between the SN+ and SN- subgroups with respect to overall survival, progression-free survival (PFS), and metastases-free survival (MFS) using the log rank test. Cox multivariate proportional hazards regression analysis was used to determine the effect of several potential confounding variables, including histology (squamous vs. nonsquamous), age (>60 vs.<or = 60), Karnofsky Performance Status (KPS) (<90 vs.>or = 90), weight loss (>or = 5% vs.<5%), and gender. A total of 256 Stage IIIB patients were identified, of whom 47 had supraclavicular nodes (SN+) and 209 did not (SN-). Statistically significantly more SN+ patients had nonsquamous histology (p = 0.05); otherwise, known prognostic factors were well balanced. The median survival for SN+ patients was 16.2 months, vs. 15.6 months for SN- patients. The 4-year actuarial survival rates were 21% and 16% for SN+ and SN- patients respectively (p = 0.44). There was no statistically significant difference in the 4-year PFS rates (19% vs. 14%, p = 0.48). The Cox analysis did not show the presence or absence of supraclavicular nodal disease to be a prognostic factor for survival, MFS, or PFS. The only statistically significant factor on multivariate analysis was gender, with males having a 40% greater risk of mortality than females (p = 0.03). There were no clinically significant differences in toxicity when comparing SN+ vs. SN- patients. Among the 47 SN+ patients, there were no reported cases of brachial plexopathy or other>or = Grade 2 late neurologic toxicity.\nQuestion: Is prolonged survival possible for patients with supraclavicular node metastases in non-small cell lung cancer treated with chemoradiotherapy?",
    "gt": "When treated with modern chemoradiotherapy, the outcome for patients with supraclavicular metastases appears to be similar to that of other Stage IIIB patients. SN+ patients should continue to be enrolled in trials studying aggressive chemoradiotherapy regimens for locally advanced NSCLC.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Several studies have reported higher prevalence of obesity in patients suffering from bipolar disorder (BD). To study the relation of elevated body mass index (BMI) in patients with BD more closely, we investigated differences in sociodemographic, clinical, and medical characteristics with respect to BMI, with the hypothesis that BMI is related to prognosis and outcome. We measured the BMI of 276 subjects of a tertiary care sample from the Maritime Bipolar Registry. Subjects were 16 to 83 years old, with psychiatric diagnoses of bipolar I disorder (n = 186), bipolar II disorder (n = 85), and BD not otherwise specified (n = 5). The registry included basic demographic data and details of the clinical presentation. We first examined the variables showing a significant association with BMI; subsequently, we modeled the relationship between BMI and psychiatric outcome using structural equation analysis. The prevalence of obesity in our sample was 39.1%. We found higher BMI in subjects with a chronic course (p<0.001) and longer duration of illness (p = 0.02), lower scores on the Global Assessment of Functioning Scale (p = 0.02), and on disability (p = 0.002). Overweight patients had more frequent comorbid subthreshold social (p = 0.02) and generalized anxiety disorders (p = 0.05), diabetes mellitus type II (p<0.001), and hypertension (p = 0.001). Subjects who achieved complete remission of symptoms on lithium showed significantly lower BMI (p = 0.01).\nQuestion: Can body mass index help predict outcome in patients with bipolar disorder?",
    "gt": "Our findings suggest that BMI is associated with the prognosis and outcome of BD. Whether this association is causal remains to be determined.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Depression is a common problem, often being recurrent or becoming chronic. The National Service Framework for Mental Health (published by the Department of Health, 1999) states that people with depression should continue to be predominantly managed in primary care. There is much evidence that the detection and management of depression by GPs could be improved, but little work has focused on GPs' views of their work with depressed patients. This was a qualitative study exploring GP attitudes to the management of patients with depression. Views of GPs in socio-economically deprived areas are compared with those serving more affluent populations. Semi-structured interviews were conducted with two groups of GPs in north-west England. One group of GPs (22) were practising in inner-city areas, and a second group (13) in suburban and semi-rural practices. All were Principals in practices that participated in undergraduate teaching. The interviews were audio-taped and subsequently transcribed verbatim. Analysis was by constant comparison until category saturation of each theme was achieved. Subjects conceptualized depression as an everyday problem of practice, rather than as an objective diagnostic category. Thematic coding of their accounts suggests a tension between three kinds of views of depressed people: (i) That depression is a common and normal response to life events or change and that it reflects the medicalization of these conditions; (ii) That the label or diagnosis of depression offers a degree of secondary gain to both patients and doctors, particularly to those GPs practising in inner-city areas and (iii) That inner-city GPs experienced on-going management of depressed people as an interactional problem, in contrast to those GPs serving a less deprived population who saw depression as a treatable illness and as rewarding work for the GP.\nQuestion: Managing depression in primary care: another example of the inverse care law?",
    "gt": "Depression is commonly presented to GPs who feel that the diagnosis often involves the separation of a normal reaction to environment and true illness. For those patients living in socio-economically deprived environments, the problems, and therefore the depression, are seen to be insoluble. This has an important implication for the construction of educational interventions around improving the recognition and treatment of depression in primary care: some doctors may be reluctant to recognize and respond to such patients in depth because of the much wider structural and social factors that we have suggested in this paper. That it is the doctors working with deprived populations who express these views, means that the 'Inverse care law' [Tudor Hart J. The inverse care Law. Lancet 1971; 1(7696): 405-412] operates in the management of depression.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We assessed the outcome of vesicoureteral reflux after augmentation cystoplasty in patients with neurogenic bladder. Since May 1992, 112 male and 18 female patients with neurogenic bladder have undergone augmentation cystoplasty with a generous detubularized segment of bowel and no effort to correct existing reflux. Patients were treated conservatively at the beginning but the response was unsatisfactory. All patients had various degrees of vesicoureteral reflux (197 refluxing units). Mean age at operation was 21.6 years (range 1.5 to 57). Preoperatively assessment included urinalysis, urine culture, kidney function tests, voiding cystourethrography, urodynamic evaluation, ultrasonography or excretory urography and cystoscopy when indicated. The status of vesicoureteral reflux, renal hydronephrosis and clinical pyelonephritis were studied during an average followup of 44.5 months. Of the 130 patients 111 (85.4%) no longer had reflux, 14 (10.8%) had improvement, 4 (3%) had no change and 1 (0.8%) had worsening reflux. All refluxing units with grades I to III, 105 of 120 with grade IV (87.5%) and 8 of 13 with grade V (61.5%) showed complete cessation of reflux. Renal hydronephrosis improved in 127 renal units (97.7%). In 8 individuals (6.2%) without reflux after cystoplasty episodes of clinical pyelonephritis occurred.\nQuestion: Is ureteral reimplantation necessary during augmentation cystoplasty in patients with neurogenic bladder and vesicoureteral reflux?",
    "gt": "Augmentation cystoplasty without ureteral reimplantation is effective and adequate treatment for high pressure, noncompliant neurogenic bladder when conservative management fails.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The increasing incidence of hip fractures in our aging population challenges orthopedic surgeons and hospital administrators to effectively care for these patients. Many patients present to regional hospitals and are transferred to tertiary care centres for surgical management, resulting in long delays to surgery. Providing timely care may improve outcomes, as delay carries an increased risk of morbidity and mortality. We retrospectively reviewed the cases of all patients with hip fractures treated in a single Level 1 trauma centre in Canada between 2005 and 2012. We compared quality indicators and outcomes between patients transferred from a peripheral hospital and those directly admitted to the trauma centre. Of the 1191 patients retrospectively reviewed, 890 met our inclusion criteria: 175 who were transferred and 715 admitted directly to the trauma centre. Transfer patients' median delay from admission to operation was 93 hours, whereas nontransfer patients waited 44 hours (p<0.001). The delay predominantly occurred before transfer, as the patients had to wait for a bed to become available at the trauma centre. The median length of stay in hospital was 20 days for transfer patients compared with 13 days for nontransfer patients (p<0.001). Regional policy changes enacted in 2011 decreased the median transfer delay from regional hospital to tertiary care centre from 47 to 27 hours (p = 0.005).\nQuestion: A comparison of surgical delays in directly admitted versus transferred patients with hip fractures: opportunities for improvement?",
    "gt": "Policy changes can have a significant impact on patient care. Prioritizing patients and expediting transfer will decrease overall mortality, reduce hospital stay and reduce the cost of hip fracture care.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The optimal management of patients with ureteric obstruction in advanced pelvic malignancy is unclear. Effective judgment is required to decide which patients would benefit most from decompression of the urinary tract. The objective of our study was to assess survival and complication rates post-percutaneous nephrostomy (PCN) in patients with ureteric obstruction due to advanced pelvic malignancy. A detailed retrospective case review of all patients who underwent PCN for ureteric obstruction due to pelvic malignancy in one calendar year was conducted to assess indication, survival time, length of stay post-procedure and complications. Thirty-six nephrostomies were performed on 22 patients with prostate cancer being the commonest primary (55 %). Renal failure was the commonest mode of presentation (56 %). Eight patients (36 %) presented without a prior diagnosis of cancer. All PCNs except one were initially technically successful, and 56 % of renal units were able to be antegradely stented and rendered free of nephrostomy. Median survival post-nephrostomy was 78 days (range 4-1,137), with the subset of bladder cancer patients having the poorest survival. Dislodgement of the nephrostomy tube was the most common troublesome complication which led to the greatest morbidity, sometimes requiring repeat nephrostomy insertion. Patients stayed for a median of 23 (range 3-89) days in hospital, which amounted to 29 % of their remaining lifetime spent in hospital.\nQuestion: Percutaneous nephrostomy for ureteric obstruction due to advanced pelvic malignancy: have we got the balance right?",
    "gt": "Although effective in improving renal function, PCN is a procedure not without associated morbidity and does not always prolong survival. Therefore, the decision to decompress an obstructed kidney with advanced pelvic malignancy should not be taken lightly. We recommend that such cases be discussed in a multidisciplinary setting, and a decision is taken only after a full informed discussion involving patients and their relatives.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To evaluate the time course of major vessel recanalization under IV thrombolysis in relation to functional outcome in acute ischemic stroke. A total of 99 patients with an acute anterior circulation vessel occlusion who underwent IV thrombolysis were included. All patients had a standardized admission and follow-up procedure. Color-coded duplex sonography was performed on admission, 30 minutes after thrombolysis, and at 6 and 24 hours after onset of symptoms. Recanalization was classified as complete, partial, and absent. Functional outcome was rated with the modified Rankin Scale on day 30. Complete recanalization occurred significantly more frequently in patients with multiple branch occlusions compared to those with mainstem occlusion (OR 5.33; 95% CI, 2.18 to 13.05; p<0.0001) and was associated with lower NIH Stroke Scale (NIHSS) scores (p<0.001). Not the specific time point of recanalization at 6 or 24 hours after stroke onset, but recanalization per se within 24 hours (OR 7.8; 95% CI 2.2 to 28.2; p = 0.002) was significantly associated with a favorable outcome. Multivariate analysis revealed recanalization at any time within 24 hours and NIHSS scores on days 1 and 7 together explaining 75% of the functional outcome variance 30 days after stroke.\nQuestion: Recanalization after intravenous thrombolysis: does a recanalization time window exist?",
    "gt": "Complete recanalization up to 24 hours after stroke onset is significantly associated with the short-term clinical course and functional outcome 30 days after acute stroke.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The right ventricle (RV) supports the systemic circulation in patients who have had an intraatrial repair of transposition of the great arteries or have congenitally corrected transposition. There is concern about the ability of a systemic RV to support the additional volume load of pregnancy, and previous studies have reported deterioration in RV function following pregnancy. However, conditions with a systemic RV are also associated with progressive RV dysfunction over time. To date, no study has examined whether the deterioration associated with pregnancy is due to the physiological changes of pregnancy itself, or is part of the known deterioration that occurs with time in these patients. Women who had undergone pregnancy under the care of the Adult Congenital Heart Disease Unit at the Queen Elizabeth Hospital were retrospectively identified and matched to separate male and nulliparous female controls. Functional status (New York Health Association [NYHA]), RV function, and systemic atrioventricular valve regurgitation were recorded for each group at baseline, postpregnancy (or at 1 year for control groups) and at latest follow-up. Eighteen women had 31 pregnancies (range 1-4) resulting in 32 live births. There were no maternal but one neonatal death. At baseline, there was no significant difference in NYHA class or RV function between pregnancy and control groups. In postpregnancy, there was a significant deterioration in the pregnant group alone for both NYHA class (P = 0.004) and RV function (P = 0.02). At latest follow-up, there was a significant deterioration in RV function in all three groups. There was still a reduction from baseline in NYHA of women who had undergone pregnancy (P = 0.014), which again was not seen in the controls groups.\nQuestion: Long-term outcome following pregnancy in women with a systemic right ventricle: is the deterioration due to pregnancy or a consequence of time?",
    "gt": "This study suggests that pregnancy is associated with a premature deterioration in RV function in women with a systemic RV. These women are also more symptomatic, with a greater reduction in functional class compared with patients with a systemic RV who do not undergo pregnancy. This study will allow this cohort of women to be more accurately counseled as to the potential long-term risks of pregnancy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Non traumatic epistaxis seems to be clustering in different periods. This paper tries to find out if there is any relationship between incidence of epistaxis and the year season, month, week, day, hour and/or lunar phase. We have retrospectively studied 754 episodes seen between May 2001 and April 2002 in our Hospital. The following parameters were registered in each patient: age, sex, number of episodes, season, month, week, day, hour and lunar phase. Epistaxis represented 12.1% of the total otolaryngological emergencies. That means an incidence of 0.1% of non traumatic epistaxis which needed hospital specialized attention. We found statistical differences (p = 0.003) in the number of epistaxis per day and the different months (greater in june and november). No differences were found in the remaining periods studied.\nQuestion: Does clustering exist in non-traumatic epistaxis?",
    "gt": "This paper shows monthly clustering of epistaxis episodes.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To investigate the discrepancies between outcomes for competence (can do) and actual performance (do do) in activities of daily living (ADLs). Baseline measurements of a population-based follow-up study. Leiden 85-Plus Study, the Netherlands. Five hundred and ninety-nine persons, age 85. The response rate was 86%. Face-to-face interviews. Measurements of competence and actual performance were based on the Groningen Activity Restriction Scale. Help received was assessed for several domains. Prevalence rates for disability were assessed according to the concepts of both competence and actual performance. Analysis was performed separately for basic activities of daily living (BADLs) and instrumental activities of daily living (IADLs). Seventy-seven percent of the oldest old were competent to perform all the BADLs and performed them regularly. Fifteen percent were not competent to perform certain BADLs independently but performed them regularly with help from others. The prevalence of disability defined as inability in one or more BADLs was 22% for women and 10% for men. The prevalence of disability defined as inactivity in one or more BADLs was 16% for women and 17% for men. Only 5% of the oldest old were competent to perform all IADLs and performed them regularly. In spite of being competent, 70% did not perform certain IADLs regularly. The prevalence of disability defined as inability in one or more IADLs was 64% for women and 55% for men. The prevalence of disability defined as inactivity in one or more IADLs was 92% for women and 98% for men.\nQuestion: Disability in the oldest old: \"can do\" or \"do do\"?",
    "gt": "The structural discrepancies between the outcomes of competence and actual performance have important consequences when estimating disability in old people. Promoting actual performance in IADLs may reduce disability.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Prior research has suggested that patients who travel out of their neighborhood for elective care from specialized medical centers may have better outcomes than local patients with the same illnesses who are treated at the same centers. We hypothesized that this phenomenon, often called \"referral bias\" or \"distance bias,\" may also be evident in curative-intent cancer trials at specialized cancer centers. We evaluated associations between overall survival and progression-free survival and the distance from the patient residence to the treating institution for 110 patients treated on one of four phase II curative-intent chemoradiotherapy protocols for locoregionally advanced squamous cell cancer of the head and neck conducted at the University of Chicago over 7 years. Using Cox regression that adjusted for standard patient-level disease and demographic factors and neighborhood-level economic factors, we found a positive association between the distance patients traveled from their residence to the treatment center and survival. Patients who lived more than 15 miles from the treating institution had only one-third the hazard of death of those living closer (hazard ratio [HR]= 0.32, 95% confidence interval [CI] = 0.12 to 0.84). Moreover, with every 10 miles that a patient traveled for care, the hazard of death decreased by 3.2% (HR = 0.97, 95% CI = 0.94 to 0.99). Similar results were obtained for progression-free survival.\nQuestion: Is patient travel distance associated with survival on phase II clinical trials in oncology?",
    "gt": "Results of phase II curative-intent clinical trials in oncology that are conducted at specialized cancer centers may be confounded by patient travel distance, which captures prognostic significance beyond cancer stage, performance status, and wealth. More work is needed to determine what unmeasured factors travel distance is mediating.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We compare the performance of a wrist blood pressure oscillometer with the mercury standard in the triage process of an emergency department (ED) and evaluate the impact of wrist blood pressure measurement on triage decision. Blood pressure was successively measured with the standard mercury sphygmomanometer and with the OMRON-RX-I wrist oscillometer in a convenience sample of 2,493 adult patients presenting to the ED with non-life-threatening emergencies. Wrist and mercury measures were compared using criteria of the Association for the Advancement of Medical Instrumentation (AAMI) and the British Hypertension Society (BHS). The impact on triage decisions was evaluated by estimating the rate of changes in triage decisions attributable to blood pressure results obtained with the wrist device. Wrist oscillometer failed to meet the minimal requirements for recommendation by underestimating diastolic and systolic blood pressure. Mean (+/-SD) differences between mercury and wrist devices were 8.0 mm Hg (+/-14.7) for systolic and 4.2 mm Hg (+/-12.0) for diastolic measures. The cumulative percentage of blood pressure readings within 5, 10, and 15 mm Hg of the mercury standard was 32%, 58%, and 72% for systolic, and 40%, 67%, and 83% for diastolic measures, respectively. Using the wrist device would have erroneously influenced the triage decision in 7.6% of the situations. The acuity level would have been overestimated in 2.2% and underestimated in 5.4% of the triage situations.\nQuestion: Can wrist blood pressure oscillometer be used for triage in an adult emergency department?",
    "gt": "The performance of the OMRON-RX-I wrist oscillometer does not fulfill the minimum criteria of AAMI and BHS compared with mercury standard in the ED triage setting.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: There have been no definite indications for additional surgical resection after endoscopic submucosal dissection (ESD) of submucosal invasive colorectal cancer (SICC). The aims of this study were to evaluate the feasibility of ESD for nonpedunculated SICC and to determine the need for subsequent surgery after ESD. A total of 150 patients with nonpedunculated SICC in resected specimens after ESD were analyzed. Among them, 75 patients underwent subsequent surgery after ESD. Clinical outcomes of ESD and histopathological risk factors for lymph node (LN) metastasis were evaluated. The en-bloc resection and complete resection (R0) rates of ESD were 98% (147/150) and 95.3% (143/150), respectively. None of the patients had delayed bleeding after ESD. Perforations occurred in seven patients (4.7%), which were successfully treated by endoscopic clipping. After subsequent surgery for 75 patients, LN metastases were found in 10 cases (13.3%). The incidence of LN metastasis was significantly higher in tumors featuring submucosal invasion of at least 1500 μm, lymphovascular invasion, and tumor budding. Multivariate analysis showed that lymphovascular invasion (P=0.034) and tumor budding (P=0.015) were significantly associated with LN metastasis. Among the 150 patients, no local recurrence or distant metastasis was detected, except one patient with risk factors and who refused subsequent surgery, during the overall median follow-up of 34 months (range, 5-63 months).\nQuestion: Endoscopic submucosal dissection for nonpedunculated submucosal invasive colorectal cancer: is it feasible?",
    "gt": "ESD is feasible and may be considered as an alternative treatment option for carefully selected cases of nonpedunculated SICC, provided that the appropriate histopathological curative criteria are fulfilled in completely resectable ESD specimens.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether women are proportionately underselected at the level of the annual residency match. Data were obtained from the Royal College of Physicians and Surgeons of Canada and the Canadian Residency Matching Service. The odds of men being rejected from their top choice of surgical discipline were compared with the corresponding odds for women for the surgical specialties of general surgery, orthopedic surgery, neurosurgery, otolaryngology, urology, cardiac surgery and plastic surgery. Women continue to be underrepresented among surgery residents and surgeons in practice; however, the number of women has increased. Neither sex was overselected among the surgical specialties examined.\nQuestion: Does sex affect residency application to surgery?",
    "gt": "There was no evidence of overselection of either sex at the level of the annual resident selection committee.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: We sought to study the individual and integrative role of amino-terminal pro-brain natriuretic peptide (NT-proBNP) and parameters of renal function for prognosis in heart failure. Amino-terminal pro-BNP and renal impairment both predict death in patients with heart failure. Worsening of renal function in heart failure even defines the \"cardiorenal syndrome.\" Seven hundred twenty subjects presenting with acute heart failure from 4 university-affiliated medical centers were dichotomized according to NT-proBNP concentration and baseline glomerular filtration rate. In addition, patients were divided according to changes in renal function. The primary end point was 60-day mortality. The combination of a glomerular filtration rate (GFR)<60 ml/min/1.73 m2 with an NT-proBNP>4,647 pg/ml was the best predictor of 60-day mortality (odds ratio 3.46; 95% confidence interval 2.13 to 5.63). Among subjects with an NT-proBNP above the median, those with a GFR<60 ml/min/1.73 m2 or a creatinine rise>or =0.3 mg/dl had the worst prognosis, whereas in subjects with a NT-proBNP below the median, prognosis was not influenced by either impaired renal function at presentation or the development of renal impairment during admission.\nQuestion: Amino-terminal pro-brain natriuretic Peptide, renal function, and outcomes in acute heart failure: redefining the cardiorenal interaction?",
    "gt": "The combination of NT-proBNP with measures of renal function better predicts short-term outcome in acute heart failure than either parameter alone. Among heart failure patients, the objective parameter of NT-proBNP seems more useful to delineate the \"cardiorenal syndrome\" than the previous criteria of a clinical diagnosis of heart failure.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It would be important to better identify heart failure (HF) patients most likely to respond to cardiac resynchronization therapy (CRT). Because endothelial progenitor cells (EPCs) play a crucial role in the maintenance of vascular endothelium integrity, we hypothesize that patients who have higher circulating EPCs levels have greater neovascularization potential and are more prone to be responders to CRT. Prospective study of 30 consecutive patients, scheduled for CRT. Echocardiographic evaluation was performed before implant and 6 months after. Responders to CRT were defined as patients who were still alive, have not been hospitalized for HF management, and demonstrated ≥15% reduction in left ventricular end-systolic volume (LVESV) at the 6-month follow-up. EPCs were quantified before CRT, from peripheral blood, by flow cytometry using five different conjugated antibodies: anti-CD34, anti-KDR, anti-CD133, anti-CD45, and anti-CXCR4. We quantified five different populations of angiogenic cells: CD133(+) /CD34(+) cells, CD133(+) /KDR(+) cells, CD133(+) /CD34(+) /KDR(+) cells, CD45(dim) CD34(+) /KDR(+) cells, and CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells. The proportion of responders to CRT at the 6-month follow-up was 46.7%. Responders to CRT presented higher baseline EPCs levels than nonresponders (0.0003 ± 0.0006% vs 0.0001 ± 0.0002%, P = 0.04, for CD34(+) /CD133(+) /KDR(+) and 0.0006 ± 0.0005% vs 0.0003 ± 0.0003%, P = 0.009, for CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells). In addition, baseline levels of CD45(dim) CD34(+) /KDR(+) /CXCR4(+) cells were positively correlated with the reduction of LVESV verified 6 months after CRT (r = 0.497, P = 0.008).\nQuestion: Circulating endothelial progenitor cells as a predictor of response to cardiac resynchronization therapy: the missing piece of the puzzle?",
    "gt": "High circulating EPCs levels may identify the subset of HF patients who are more likely to undergo reverse remodeling and benefit from CRT. Addition of EPCs levels assessment to current selection criteria may improve the ability to predict CRT response.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: It has been shown previously that mortality from acute chronic obstructive pulmonary disease (COPD) is higher at small hospitals than at large teaching hospitals. To examine mortality at this acute stage and referral for further treatment by specialities in Finland, and trends in these between the 1990s and 2000s. Data on all periods of treatment for patients over 44 years of age with a principal or subsidiary diagnosis of COPD beginning and ending in 1995-2004 were extracted from the Finnish hospital discharge register. Particular attention was paid to acute-stage treatment periods managed by a general practitioner, pulmonary specialist, or specialist in internal medicine that had begun as emergency admissions and had a principal diagnosis of COPD, and to any further treatment immediately following these. General practitioners referred 5.1% of their acute-stage patients to a specialist in secondary care in 1995-2004. Of the total of 77,445 acute-stage treatment periods, 3% (2328) ended in the death of the patient, implying the loss of 8.3% of the patients involved. The age- and sex-adjusted risk of death attached to treatment periods managed by a general practitioner relative to those managed by a pulmonary specialist was 0.83 (95% CI 0.75-0.91).\nQuestion: Does place of treatment affect prognosis for chronic obstructive pulmonary disease (COPD)?",
    "gt": "It is quite possible to treat acute exacerbations of COPD efficiently and safely in a health centre hospital ward. New treatment modalities and health service structures seem to have led to a decrease in acute exacerbations of COPD since the year 2000, even though the number of patients with this disease has increased as a consequence of ageing of the population. Further research is required on the efficacy of treatment by a general practitioner, e.g., with data on re-hospitalization.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: A severe degree of ureteral obstruction is viewed as a predictor of poor outcome in shockwave lithotripsy (SWL). Impacted stones are often considered a contraindication to in-situ SWL. Impaction in our study was defined as failure to visualize the ureter distal to the calculus with proximal hold-up of contrast for as long as 3 hours on an intravenous urogram (IVU). We evaluated 30 patients with impacted ureteral calculi, who were compared with a second unimpacted group matched for stone size and stone location. The calculi were reorganized into<or =10-mm and>10-mm groups. The results were compared in terms of clearance rates, number of shockwaves, number of sessions, and number of days between the start of SWL and clearance. Between January 1998 and December 2001, 30 impacted stones were treated with lithotripsy. Complete clearance rates in the impacted as well as the non-impacted group were 76.7%. There was no statistical difference in the number of shockwaves, sessions, or time to clearance. The results were poorer in lower-ureteral than upper-ureteral calculi, but this difference did not reach statistical significance. However, the differences between the<or =10-mm and>10-mm stones were statistically significant.\nQuestion: Does failure to visualize the ureter distal to an impacted calculus constitute an impediment to successful lithotripsy?",
    "gt": "Impaction on an IVU does not affect the results of lithotripsy.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Thyroid surgery is done in Germany in a considerable numbers of operations (about 110,000 per year). To perform thyroid operations by so called \"generalists\" or \"specialists\" have been discussed intensively, however, this issue have not been analyzed in detail. Study material comprised 16,500 consecutive thyroid operations with 30,000 operated sites that have been prospectively documented in the German Thyroid Multicenter Study performed 1998 through 2001. Quality of surgery were analyzed by calculating the inverse relationship between volume and outcome (complication rate). To achieve complication rates (permanent unilateral recurrent laryngeal nerve paralysis and hypocalcemia) of<1 % (primary surgery) or<3 % (redo surgery) the minimum number of thyroid operations of lower level of experience (e. g. benign nodular goiter) per year was n=30. The minimum number of operations with higher level of experience was significantly lower (n=3-12) due to the higher level of experience of operating surgeons. In contrast to the rates of postoperative hypocalcemia the rates of postoperative recurrent laryngeal nerve paralysis was clearly related to the number of thyroid operations performed.\nQuestion: Thyroid surgery: generalist or specialist?",
    "gt": "The high number of thyroid operations in Germany with about 20 % of operations of high level experience are requiring surgical curricula and hospital structures that offer as well generalists as specialists to treat the broad spectrum of thyroid diseases accordingly. To lower the complication rate especially of difficult thyroid operations the level of specialization in Germany have to be increased.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: To determine whether the frequency of soft sonographic aneuploidy markers varies by fetal sex. We identified all singleton fetuses with known sex undergoing genetic sonography at 17 weeks' to 21 weeks 6 days' gestation in a single perinatal center from January 1, 2000, to December 31, 2003. Markers studied were biparietal diameter/femur length, transcerebellar diameter, ear length, echogenic bowel, femur length, humerus length, absent middle fifth phalanx, nuchal fold, renal pelvis dilatation, echogenic cardiac focus, and choroid plexus cysts. Additional information extracted from the prospectively ascertained database included maternal age, referral indications, and chromosomal analyses. Multiple gestations and fetuses with structural or chromosomal abnormalities were excluded. The study received exempt review status by the Institutional Review Board. Dichotomous variables were compared by the chi(2) or Fisher exact test; continuous variables were compared by the unpaired t test. In total, 4057 eligible fetuses, 2103 male and 1954 female, were examined at 18.9 +/- 0.9 weeks (mean +/- SD). Referral indications included maternal age of 35 years or older (n = 2983), abnormal second-trimester serum screen results (n = 610), soft marker on sonography (n = 583), prior aneuploid offspring (n = 24), and other (n = 125). More than 1 referral indication was possible for a given fetus. Overall, male fetuses exhibited echogenic fetal bowel (odds ratio, 1.76; 95% confidence interval [CI], 1.14-2.72; P = .009) and renal pelvis dilatation (odds ratio, 2.00; 95% CI, 1.30-3.09; P = .001) significantly more often than female fetuses. However, when fetuses were evaluated for single isolated markers, only male predominance of renal pelvis dilatation persisted (odds ratio, 2.32; 95% CI, 1.32-4.09; P = .003). No markers had increased frequency in female offspring.\nQuestion: Does the frequency of soft sonographic aneuploidy markers vary by fetal sex?",
    "gt": "Male fetuses exhibit a significantly increased frequency of renal pelvis dilatation compared with female fetuses. Sex-specific adjustment of sonographically derived aneuploidy risk does not appear to be indicated. However, a larger series of fetuses with trisomy 21 and pyelectasis is required to assess sex-specific risk adjustment for this marker.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: The feasibility of a side-to-side jejunoileal anastomosis (SJA) to control type 2 diabetes mellitus (T2DM) was studied in non-obese diabetic Goto-Kakizaki (GK) rats. Seventeen 14-week-old male GK rats were divided into three groups: SJA bypassing 60% of the small bowel length, sham-operated jejunoileal bypass (Sham group), and control animals. Rats were observed for 10 weeks after surgery. Fasting blood glucose (FBG) levels and oral glucose tolerance test (OGTT) were measured before and after the procedure. Animals with SJA exhibited normalization of FBG levels from the 1st and up to the 10th postoperative week when the experiment terminated. OGTT compared with sham-operated and control groups was also significantly better at 3 and 8 weeks postoperatively.\nQuestion: Is a Simple Food-Diverting Operation the Solution for Type 2 Diabetes Treatment?",
    "gt": "A simple SJA, diverting the food and biliopancreatic secretion to the distal small bowel, was able to normalize both FBG levels and OGTT in a non-obese diabetic rat model.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: This study was undertaken to evaluate the efficacy of metformin in women with anovulation who do not have evidence for hyperandrogenism and classic polycystic ovary syndrome. A randomized trial of metformin (1500 mg daily) and placebo in 24 anovulatory women was undertaken for 3 months. Assessments of changes in hormone levels and insulin sensitivity were carried out. Abnormal hormonal values were defined by levels exceeding the range in normal ovulatory controls. Anovulatory women had normal androgen levels and luteinizing hormone but had higher serum insulin and lower insulin sensitivity compared with controls. Over 3 months, there were 16 ovulatory cycles with metformin and only 4 with placebo ( P<.05). Success of ovulation did not correlate with changes in androgen, insulin, or insulin sensitivity parameters.\nQuestion: Does metformin induce ovulation in normoandrogenic anovulatory women?",
    "gt": "Metformin may be useful for inducing ovulation in anovulatory women who do not have hyperandrogenism. This effect may be independent of a lowering of androgen or insulin levels.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  },
  {
    "query": "Answer the question based on the following context: Standard electrophysiologic techniques generally allow discrimination among mechanisms of paroxysmal supraventricular tachycardia. The purpose of this study was to determine whether the response of paroxysmal supraventricular tachycardia to atrial and ventricular overdrive pacing can help determine the tachycardia mechanism. Fifty-three patients with paroxysmal supraventricular tachycardia were studied. Twenty-two patients had the typical form of atrioventricular (AV) junctional (nodal) reentry, 18 patients had orthodromic AV reentrant tachycardia, 10 patients had atrial tachycardia, and 3 patients had the atypical form of AV nodal reentrant tachycardia. After paroxysmal supraventricular tachycardia was induced, 15-beat trains were introduced in the high right atrium and right ventricular apex sequentially with cycle lengths beginning 10 msec shorter than the spontaneous tachycardia cycle length. The pacing cycle length was shortened in successive trains until a cycle of 200 msec was reached or until tachycardia was terminated. Several responses of paroxysmal supraventricular tachycardia to overdrive pacing were useful in distinguishing atrial tachycardia from other mechanisms of paroxysmal supraventricular tachycardia. During decremental atrial overdrive pacing, the curve relating the pacing cycle length to the VA interval on the first beat following the cessation of atrial pacing was flat or upsloping in patients with AV junctional reentry or AV reentrant tachycardia, but variable in patients with atrial tachycardia. AV reentry and AV junctional reentry could always be terminated by overdrive ventricular pacing whereas atrial tachycardia was terminated in only one of ten patients (P<0.001). The curve relating the ventricular pacing cycle length to the VA interval on the first postpacing beat was flat or upsloping in patients with AV junctional reentry and AV reentry, but variable in patients with atrial tachycardia. The typical form of AV junctional reentry could occasionally be distinguished from other forms of paroxysmal supraventricular tachycardia by the shortening of the AH interval following tachycardia termination during constant rate atrial pacing.\nQuestion: The response of paroxysmal supraventricular tachycardia to overdrive atrial and ventricular pacing: can it help determine the tachycardia mechanism?",
    "gt": "Atrial and ventricular overdrive pacing can rapidly and reliably distinguish atrial tachycardia from other mechanisms of paroxysmal supraventricular tachycardia and occasionally assist in the diagnosis of other tachycardia mechanisms. In particular, the ability to exclude atrial tachycardia as a potential mechanism for paroxysmal supraventricular tachycardia has important implications for the use of catheter ablation techniques to cure paroxysmal supraventricular tachycardia.",
    "tag": [
      "PubMedQA",
      "medical"
    ],
    "source": "PubMedQA"
  }
]